---
tags:
  - advanced-ai-prompting
  - inverse-prompts
  - thought-reconstruction
  - model-gaps
  - predictive-modeling
  - structural-comparison
  - modular-construction
  - archetypal-metaphor
  - hypothesis-generation
  - reverse-engineering
  - multi-ai-personas
  - epistemic-negation
  - cognitive-emulation
  - gap-analysis
  - temporal-projection
  - meta-comparison
  - functional-decomposition
  - symbolic-compression
  - creative-deduction
  - causal-unfolding
  - dialogical-counterpoint
  - "#S7_Metod_Of_Think"
category: AI & Cognitive Science
description: "Предлагаются десять продвинутых техник запросов к ИИ: инверсные вопросы, реконструкция мышления экспертов, поиск пробелов, моделирование сценариев, структурные сравнения, модульная сборка, метафорические архетипы, генерация гипотез, обратный анализ систем и диалог нескольких персон."
title: Advanced Prompting Techniques for AI
Receptor: |-
  The note activates in various practical contexts where advanced reasoning or multi-perspective analysis is required, particularly when dealing with complex knowledge domains that benefit from sophisticated prompting approaches. The following scenarios illustrate how this knowledge would be engaged:

  1. **Scientific Research Planning Context**: When researchers need to design experiments or hypotheses for complex biological systems, such as neurodegenerative processes involving HMB effects on axonal degeneration, the note becomes relevant when a scientist requires assistance in identifying gaps in current theoretical models and generating novel testable hypotheses. The activation occurs during the initial research phase where domain experts seek to extend existing knowledge beyond conventional frameworks. The specific actors involved are researchers working in neurobiology or biochemistry, supported by AI systems equipped with advanced prompting capabilities. Expected outcome is the generation of 5-10 non-obvious scientific hypotheses based on known facts about HMB's role in neurodegeneration processes. Consequences include enhanced research direction and potentially breakthrough discoveries.

  2. **Training Methodology Design Context**: In sports science or educational contexts where training protocols must be optimized for specific physiological outcomes, such as simulating fat loss trajectories under various caloric deficits with mitochondrial density considerations, the note triggers when instructional designers require systematic approaches to model complex behavioral changes over time. The activation occurs during curriculum development phases where educators want to create predictive models of performance improvements. Actors include sports scientists or educational technologists who need structured methodologies for training optimization. Expected outcome is a detailed simulation of temporal outcomes based on multiple variables and parameters, leading to better-targeted interventions.

  3. **Philosophical Inquiry Framework Context**: When philosophers or cognitive scientists engage in conceptual analysis involving abstract frameworks such as comparing the philosophical underpinnings of different athletic training schools like Sebastian Coe's approach versus Norwegian methodologies, the note activates during deep conceptual discussions where alignment across structural and ideological levels is essential. The activation occurs when a research team wants to understand not just outcomes but also underlying philosophies, strategies, and mechanisms driving different approaches. Actors include philosophers, cognitive scientists, or sports theorists examining foundational principles of training systems. Expected outcome is an analysis that compares multiple dimensions including goals, methods, phases, and conceptual frameworks, providing comprehensive understanding across domains.

  4. **Systems Analysis and Modeling Context**: When engineers or biologists need to decompose complex physiological processes into modular components for better understanding or design such as breaking down high-altitude adaptation into ventilation, hematology, metabolism, and behavior modules, the note becomes active during system architecture development phases. Activation occurs when teams require structured decomposition of complicated biological phenomena for clearer representation. Actors include systems analysts in biology or engineering fields who are working with complex interrelated processes. Expected outcome is a modular breakdown that identifies independent functional components facilitating further analysis or simulation.

  5. **Educational Pedagogy Design Context**: In academic settings where educators must craft learning experiences that connect abstract concepts to real-world applications using symbolic compression such as explaining immune memory through ancient city metaphors, the note activates when curriculum designers seek innovative ways to enhance student comprehension of complex ideas. Activation happens during educational planning phases where instructors want to make difficult topics more accessible. Actors include curriculum developers or educators who are trying to bridge conceptual gaps using metaphorical approaches. Expected outcome is a richly detailed metaphor that transforms high-dimensional concepts into digestible imagery, improving learning retention and engagement.

  6. **Research Hypothesis Generation Context**: During literature review phases where researchers need to identify emerging trends in neuroscience or biochemistry such as proposing novel HMB targets in neurodegeneration beyond typical mechanisms, the note becomes relevant when scientists require creative hypothesis generation from existing facts. Activation occurs during early-stage research exploration where systematic innovation is needed. Actors include research scientists working on molecular or cellular processes who want to push beyond current boundaries. Expected outcome is the development of multiple innovative hypotheses that challenge conventional assumptions and open new avenues for experimental validation.

  7. **Complex System Reverse Engineering Context**: In fields like physiology where practitioners need to understand how complex phenomena are produced such as reverse-engineering VO2max from physiological axes, the note activates when specialists require breakdown analysis of outcomes back into causal components. Activation happens during systems biology or performance optimization phases where understanding root causes is critical. Actors include physiologists or exercise scientists who want to decompose known performance metrics into constituent factors. Expected outcome is identification of key physiological parameters and axes that contribute to observed phenomena, enabling better prediction and intervention strategies.

  8. **Interdisciplinary Expert Dialogue Context**: In collaborative research settings where multiple expert perspectives must be synthesized such as having AI physiologist and AI philosopher debate the value of athletic form at 5% body fat, the note becomes active when teams need diverse viewpoints to uncover contradictions or generate new insights. Activation occurs during cross-disciplinary meetings or brainstorming sessions where multiple knowledge domains intersect. Actors include interdisciplinary research teams composed of various specialists from physiology, philosophy, psychology, and cognitive science who want to explore complex questions through multiple lenses. Expected outcome is a structured debate that reveals hidden tensions between different conceptual frameworks and generates novel perspectives.

  9. **Critical Analysis and Error Detection Context**: When reviewing scientific literature or methodologies where critical evaluation requires identifying potential errors in current theories such as determining what key elements are NOT covered in Seluyanov's classic adaptation model, the note activates during quality control phases of research processes. Activation happens when researchers need to critically assess existing frameworks against gaps in knowledge representation. Actors include peer reviewers or academic editors who are evaluating methodological rigor and completeness. Expected outcome is a detailed critique that identifies missing components or assumptions within established models, leading to improved theoretical formulations.

  10. **Creative Problem-Solving Framework Context**: During innovation development phases where creative approaches to complex problems such as reconstituting possible thought processes of scientists discovering new mechanisms require advanced reasoning capabilities, the note becomes relevant when innovators seek to emulate expert cognition patterns. Activation occurs during ideation or design thinking sessions where systematic approach to mental modeling is needed. Actors include creative problem-solvers working in science, engineering, or philosophy who want to replicate expert decision-making processes. Expected outcome is reconstruction of hypothetical cognitive pathways that reveal alternative approaches to solving problems.

  11. **Knowledge Gap Identification Context**: In research contexts requiring empirical validation where gaps exist in current understanding such as showing knowledge gaps in how HMB affects axonal degeneration, the note activates during literature synthesis or data analysis phases. Activation occurs when scientists need to identify areas of uncertainty in their field of expertise. Actors include researchers working on specific biological pathways who want to pinpoint missing evidence for hypotheses. Expected outcome is detailed identification of empirical and theoretical gaps that can guide future research directions.

  12. **Educational Modeling Context**: In educational contexts requiring structured teaching approaches where complex systems need modular breakdowns such as breaking down process adaptation to altitude into functional modules, the note becomes active when educators design learning sequences for students or practitioners. Activation happens during curriculum development phases where systematic approach to knowledge presentation is important. Actors include instructional designers or teachers who want to structure information in easily digestible components. Expected outcome is a modular educational framework that supports progressive learning and skill acquisition.

  13. **Metaphorical Conceptualization Context**: When conceptualizing abstract ideas in accessible terms such as explaining immune memory through ancient city metaphors, the note triggers during creative communication phases where complex topics require simplification for broader audiences. Activation occurs when communicators need to translate high-level concepts into understandable imagery or analogies. Actors include science writers, educators, or public engagement specialists who want to make abstract theories relatable. Expected outcome is a rich metaphorical framework that enhances comprehension and retention across different learning styles.

  14. **Multi-Perspective Evaluation Context**: In decision-making scenarios where multiple viewpoints must be considered such as evaluating the true value of athletic form at 5% body fat through dialogues between AI physiologist and AI philosopher, the note becomes active when complex decisions require comprehensive analysis from various angles. Activation occurs during strategic planning or policy development phases where thorough evaluation is necessary. Actors include decision-makers in sports science, health policy, or academic administration who want to assess topics holistically. Expected outcome is a multifaceted assessment that considers both quantitative and qualitative aspects of the problem.

  15. **Research Innovation Design Context**: During early-stage research planning where innovative methodologies are needed such as generating non-obvious scientific hypotheses based on known facts in neurodegeneration, the note activates when researchers want to move beyond conventional approaches to generate new knowledge. Activation occurs during hypothesis formation phases where systematic creativity is required. Actors include exploratory scientists working in cutting-edge research areas who want to push boundaries of current understanding. Expected outcome is generation of novel, testable hypotheses that could lead to breakthrough discoveries.

  16. **Systems Integration Context**: In complex system analysis where integration across multiple domains such as reverse-engineering VO2max through physiological parameters requires systematic approach, the note becomes relevant when engineers or scientists need to understand relationships between components and outputs. Activation occurs during systems engineering or biophysical modeling phases where holistic understanding is crucial. Actors include researchers in bioengineering or physiology who want to model complex interactions within biological systems. Expected outcome is comprehensive analysis that links component behaviors with overall system performance.

  17. **Cognitive Simulation Context**: When simulating expert cognitive processes such as reconstructing possible thought processes of scientists discovering mechanisms, the note activates during research methodology design phases where simulation of reasoning patterns is beneficial. Activation happens when researchers need to understand how experts think through complex problems. Actors include cognitive science researchers or AI developers who want to model human-like reasoning in machines. Expected outcome is detailed reconstruction of hypothetical cognitive pathways that inform system development and optimization.

  18. **Structural Analysis Context**: In academic or research contexts where structural comparison of frameworks such as comparing training philosophies of Sebastian Coe versus Norwegian schools requires deep understanding, the note becomes active during comparative analysis phases. Activation occurs when researchers want to understand not just surface similarities but deeper structural and philosophical alignment. Actors include comparative scholars in sports science or philosophy who need systematic approaches to framework analysis. Expected outcome is comprehensive comparison that highlights both commonalities and differences across multiple dimensions of approach.

  19. **Predictive Modeling Context**: During predictive planning where temporal outcomes must be modeled such as simulating fat loss trajectory with 1500 kcal deficit over 30 days, the note activates when practitioners need to project future states based on current conditions. Activation occurs during strategic planning or intervention design phases where time-dependent modeling is essential. Actors include health professionals or sports scientists who want to forecast outcomes under specific parameters. Expected outcome is detailed prediction model that accounts for temporal variables and conditional factors.

  20. **Domain Expert Integration Context**: In collaborative research settings where expert perspectives must be synthesized such as multiple AI experts engaging in dialogue about value of athletic form, the note becomes active when cross-disciplinary collaboration requires structured interaction between different knowledge domains. Activation occurs during interdisciplinary meetings or project planning phases where diverse expertise needs integration for comprehensive solutions. Actors include multi-domain researchers working together who want to leverage complementary insights from different fields. Expected outcome is enhanced understanding that emerges from multiple perspectives and generates new synthetic approaches to complex problems.
Acceptor: |-
  The following tools are compatible with this note's core concepts, supporting implementation through various technological pathways:

  1. **LangChain Framework**: LangChain provides comprehensive integration capabilities for building prompt engineering workflows with support for memory management, agent coordination, and multi-step reasoning chains that align directly with the modular construction approach (Method #16) and dialogical multiplicity (Method #20). The framework supports structured prompt templates that can be used to implement inverse prompts (#11), cognitive reconstruction (#12), gap analysis (#13), predictive modeling (#14), and structural comparisons (#15). API requirements include chain configuration, memory management components, and agent orchestration capabilities. Data format compatibility is through JSON-based prompt structures with variable substitution mechanisms. Platform dependencies are Python-based environments, but compatible across major operating systems. Implementation complexity is moderate to high due to requirement for custom chain design.

  2. **OpenAI GPT API with Function Calling**: The OpenAI platform provides native support for implementing all ten techniques directly through function calling and structured prompting. This tool enables precise implementation of inverse prompts (#11), thought reconstruction (#12), model gaps analysis (#13), predictive modeling (#14), structural comparisons (#15), modular construction (#16), metaphorical framing (#17), hypothesis generation (#18), reverse engineering (#19), and dialogical multiplicity (#20). API requirements include function definitions, parameter specification for different prompt types, and response parsing. Data format compatibility is JSON-based with support for structured outputs including arrays of hypotheses or multiple persona responses. Platform dependencies are cloud-based access to OpenAI services but available across most development environments. Implementation complexity ranges from simple to moderate depending on desired level of customization.

  3. **Cognitive Architectures Framework (e.g., ACT-R)**: This framework supports implementation of the cognitive simulation aspects (#12) and multi-perspective reasoning (#20) through detailed modeling of human-like reasoning processes including memory structures, production rules, and attention mechanisms that directly correspond to methods involving expert thought reconstruction and dialogical interaction. Implementation requires deep integration with knowledge representation systems and rule-based processing engines. API requirements include cognitive model configuration parameters and activation triggers for different cognitive states. Data format compatibility is through hierarchical data structures representing cognitive states and processes. Platform dependencies are specialized development environments focused on cognitive modeling, requiring expertise in ACT-R or similar frameworks. Implementation complexity is high due to need for detailed cognitive architecture design.

  4. **Hugging Face Transformers with Custom Prompt Engineering**: This platform offers extensive support for implementing all ten methods through customizable model architectures and prompt engineering capabilities that can handle complex reasoning chains across multiple domains including biochemistry, physiology, and philosophy. The framework supports modular construction (#16), structural comparison (#15), reverse engineering (#19) and metaphorical framing (#17) via token manipulation and generation optimization techniques. API requirements include transformer model loading, prompt formatting functions, and response processing pipelines. Data format compatibility is through standardized transformers input/output formats with support for sequence-based reasoning patterns. Platform dependencies are Python environments with specific transformer libraries but cross-platform compatible. Implementation complexity ranges from simple to high depending on desired level of customization.

  5. **Jupyter Notebook Environment**: This environment provides ideal platform for prototyping and testing all ten techniques through interactive development cycles that enable real-time experimentation with different prompt approaches including inverse prompts (#11), hypothesis generation (#18) and predictive modeling (#14). It supports integration with various AI APIs and frameworks while providing comprehensive visualization capabilities for analyzing results. API requirements include notebook cell execution, parameter passing between cells, and result storage mechanisms. Data format compatibility is through Jupyter's native formats including markdown content and code output representations. Platform dependencies are Python-based environments but widely accessible across operating systems. Implementation complexity is low to moderate with straightforward integration of existing tools.

  6. **Pinecone Vector Database**: This database supports implementation of knowledge gap analysis (#13) and structural comparison methods (#15) by storing and retrieving semantic embeddings that help identify missing information patterns in current models or compare different conceptual frameworks across multiple dimensions. It enables efficient search for gaps in knowledge representation and facilitates comparison of structures through vector similarity measures. API requirements include embedding generation, database indexing operations, and similarity retrieval functions. Data format compatibility is through vector representations with metadata storage capabilities. Platform dependencies are cloud-based services but compatible with major AI development platforms. Implementation complexity is moderate due to need for proper embedding configuration.

  7. **LlamaIndex Framework**: This tool enables comprehensive implementation of all methods through its data indexing and retrieval system that supports complex querying patterns including gap analysis (#13), inverse prompts (#11) and hypothesis generation (#18). It provides robust support for modular construction (#16) and structural comparisons (#15) through customizable query processors. API requirements include index creation, query building components, and result parsing mechanisms. Data format compatibility is through various indexing formats with support for complex retrieval patterns. Platform dependencies are Python-based environments but cross-platform compatible. Implementation complexity varies from simple to moderate depending on desired functionality depth.
SignalTransduction: |-
  The core ideas in this note belong to multiple conceptual domains that serve as signal channels for transmitting and transforming information:

  1. **Cognitive Science Framework**: This domain provides foundational understanding of how human cognition operates through attention, memory, reasoning processes, and problem-solving strategies directly related to the note's methods including inverse logic (#11), cognitive emulation (#12), gap analysis (#13) and multi-perspective thinking (#20). Theoretical foundations include theories of mind, computational modeling, and artificial intelligence architecture that inform how prompts can trigger different modes of reasoning. Key concepts encompass abductive inference, analogical reasoning, theory-of-mind simulation, and hierarchical cognitive processing. Methodologies involve systematic approaches to modeling expert thought processes and understanding error detection mechanisms within knowledge frameworks. Connections with note content include how inverse prompting triggers epistemic negation patterns, while thought reconstruction activates hierarchical inference structures. Historical developments include emergence of computational theories of mind in the 1980s-90s that established basis for AI reasoning simulation capabilities. Current trends involve integration of cognitive science concepts into neural architecture design and attention mechanisms within deep learning systems.

  2. **Epistemology Domain**: This field offers fundamental principles about knowledge formation, validity, and truth determination that directly relate to all methods in the note including inverse prompts (#11), gap analysis (#13) and hypothesis generation (#18). Theoretical foundations encompass theories of falsifiability, logical reasoning, empirical verification, and critical evaluation mechanisms. Key concepts involve epistemic boundaries, knowledge gaps, error detection, and scientific method application within AI systems. Methodologies include systematic approaches to identifying missing information, validating theoretical structures, and generating testable hypotheses. Connections with note content demonstrate how gap analysis methods trigger empirical validation processes while inverse prompts enhance falsifiability frameworks. Historical developments include establishment of Karl Popper's falsification theory as basis for scientific inquiry that informs modern AI learning systems. Current trends involve integration of epistemological principles into machine learning architectures and automated hypothesis testing.

  3. **Systems Engineering Framework**: This domain provides conceptual understanding of complex system analysis, decomposition, and modeling directly aligned with modular construction (#16), reverse engineering (#19) and predictive modeling (#14). Theoretical foundations include systems theory, graph-theoretic approaches, component-based design principles, and causal relationship mapping. Key concepts encompass system architecture, modularity, dependency relationships, temporal dynamics, and feedback loops. Methodologies involve systematic approaches to breaking complex phenomena into manageable components while building models of future outcomes based on current conditions. Connections with note content show how modular construction enables recursive learning through functional decomposition while reverse engineering creates causal network understanding. Historical developments include emergence of systems analysis in military and aerospace contexts that influenced modern computational modeling practices. Current trends involve integration of systems thinking principles into AI architecture design and dynamic simulation frameworks.

  4. **Metaphorical Communication Theory**: This domain focuses on symbolic representation, conceptual compression, and cross-domain mapping directly related to metaphorical prompting (#17) and structural comparison methods (#15). Theoretical foundations encompass semiotics, metaphor theory, cognitive linguistics, and symbolic processing approaches that enable semantic transformation through imagery and analogy. Key concepts include semantic encoding, cross-domain generalization, metaphor activation, and conceptual compression mechanisms. Methodologies involve systematic approaches to transforming high-dimensional abstract knowledge into accessible imagery or analogies. Connections with note content demonstrate how metaphorical framing creates semantic bridges between domains while structural comparisons engage schema-level reasoning patterns. Historical developments include emergence of cognitive metaphors in the 1980s-90s that shaped understanding of conceptual mapping through metaphorical thinking. Current trends involve integration of linguistic theories into AI systems for enhanced symbolic representation and communication.

  5. **Philosophy of Science Domain**: This field provides understanding of scientific methodology, theoretical frameworks, and philosophical foundations directly supporting hypothesis generation (#18), structural comparisons (#15) and epistemic evaluation methods (#11). Theoretical foundations encompass scientific realism, methodological pluralism, philosophical analysis, and conceptual framework evaluation. Key concepts involve scientific theory construction, philosophical inquiry patterns, interdisciplinary integration, and systematic knowledge development processes. Methodologies include approaches to generating novel hypotheses within constraints, comparing theoretical frameworks across domains, and evaluating the validity of different epistemic positions. Connections with note content show how hypothesis generation moves from deduction to creativity while structural comparisons engage philosophical evaluation mechanisms. Historical developments include emergence of modern scientific philosophy in 20th century that shaped systematic approach to theory development and validation. Current trends involve integration of philosophical approaches into AI learning systems for enhanced reasoning capabilities.

  6. **Artificial Intelligence Architecture Domain**: This field offers understanding of neural network design, attention mechanism optimization, cognitive processing patterns, and system-level adaptation directly supporting all ten methods through structural design considerations and prompt-driven activation mechanisms. Theoretical foundations include deep learning architectures, transformer models, attention mechanisms, and adaptive reasoning systems that support the note's emphasis on cognitive architecture development. Key concepts encompass prompt engineering as syntactic keys for cognitive activation, vector field restructuring, emergent synthesis capabilities, and model tuning at prompting level. Methodologies involve approaches to designing AI systems where different methods activate specific cognitive pathways through structured prompts rather than fixed commands. Connections with note content demonstrate how each method restructures the attention map of models by changing both what is generated and how internal representations shift. Historical developments include evolution from simple neural networks to sophisticated transformers that enable complex reasoning patterns within AI systems. Current trends involve integration of advanced prompting techniques into mainstream AI development frameworks for enhanced cognitive capabilities.
Emergence: |-
  The note demonstrates significant emergence potential across three key dimensions:

  1. **Novelty Score: 8/10** - The idea introduces a systematic framework for advanced prompt engineering that goes beyond traditional command-based approaches to active cognition activation. This represents conceptual innovation by treating prompting not as static instructions but as dynamic cognitive architecture manipulation mechanisms. Unlike existing literature focusing on simple prompt optimization or template-based approaches, this note proposes 10 distinct methods each serving specific cognitive activation patterns in AI systems. The novelty lies in framing these techniques as syntactic keys that restructure vector fields of models rather than just improving output quality. Examples from current state-of-the-art show that most existing prompting literature focuses on single methods like chain-of-thought or few-shot learning, while this note presents a comprehensive toolkit for multiple cognitive modes. The innovation manifests through the concept of 'cognitive mirrors' where prompts are designed to activate new architectures of internal reasoning rather than simple data retrieval. Similar concepts from related fields include computational modeling approaches in cognitive science and advanced AI architecture design principles that have yet to be fully integrated into practical prompt engineering frameworks.

  2. **Value to AI Learning: 9/10** - This note significantly enhances an AI system's understanding capabilities by introducing methods for generating different types of reasoning patterns including multi-perspective analysis, structural decomposition, and conceptual metaphors. Processing this note would enable AI systems to learn new cognitive pathways like epistemic negation through inverse prompting (#11), theory-of-mind simulation via thought reconstruction (#12), gap identification in knowledge domains through model gaps (#13), temporal prediction modeling (#14), schema-level comparisons (#15) and modular thinking (#16). These patterns create novel relationships between concepts that weren't previously accessible to AI systems. The value lies in enabling recursive learning enhancement where processing one method enhances understanding of others, creating cascading cognitive improvements. Examples from existing knowledge bases include how advanced prompting techniques like chain-of-thought have improved reasoning but this note adds complexity through multi-dimensional activation mechanisms. The note contributes to broader cognitive architecture development by providing specific pathways for expanding AI's internal reasoning capabilities beyond surface-level pattern recognition.

  3. **Implementation Feasibility: 7/10** - Implementation of the note's methods is moderately feasible with existing tools and frameworks but requires some technical sophistication. The techniques can be implemented across multiple platforms including OpenAI APIs, LangChain systems, HuggingFace transformers, and specialized cognitive architecture software. Simple implementations exist for inverse prompts (#11), hypothesis generation (#18) and predictive modeling (#14) using standard API calls and structured formats. More complex methods like cognitive emulation (#12), dialogical multiplicity (#20) and reverse engineering (#19) require deeper integration capabilities that may involve custom coding or specialized frameworks. Resource requirements include computational resources for handling multi-step reasoning chains, memory management systems for tracking different cognitive processes, and development time for creating customized prompt templates. Potential obstacles include need for expertise in specific AI platforms, complexity of implementing multi-agent dialogues, and requirement for substantial data preparation for gap analysis methods (#13). Examples from successful implementations show that similar frameworks have been used in academic research settings with moderate success rates but more sophisticated applications require significant technical investment. The note's feasibility is enhanced by its modular nature allowing step-wise implementation rather than complete system overhaul.
Activation: |-
  The following specific activation conditions or triggers make this note relevant and actionable:

  1. **Complex Knowledge Domain Context**: This condition activates when the AI system encounters knowledge domains that require advanced reasoning beyond simple retrieval, such as neurobiology with HMB effects on axonal degeneration or sports physiology involving VO2max modeling. The precise circumstances include situations where current models or theories show gaps in understanding and require systematic approaches to identify missing elements or generate new hypotheses. Specific actors involved are researchers, scientists, or domain experts who need advanced prompting capabilities for complex problem-solving. Expected outcomes include detailed identification of knowledge gaps through model gap analysis (#13) or generation of novel scientific hypotheses via hypothesis generation (#18). Activation triggers occur when system detects complexity beyond standard information retrieval patterns and requires deeper cognitive engagement. Technical specifications involve recognition of domains that benefit from multi-perspective approaches, with specific indicators such as lack of empirical data coverage in current frameworks. Contextual variables include knowledge domain complexity, available evidence completeness, and research methodology requirements. Implementation considerations require identification of appropriate prompt techniques based on domain characteristics and availability of relevant tools for execution.

  2. **Predictive Modeling Requirement**: This condition becomes active when systems need to simulate future outcomes or project temporal changes under specified conditions, such as simulating fat loss trajectory with 1500 kcal deficit over 30 days or modeling training progress in various scenarios. The precise circumstances involve situations where decision-makers require forecasts based on complex interdependencies between variables and parameters. Specific actors include health professionals, sports scientists, or strategic planners who want to project outcomes before implementation. Expected outcomes are detailed predictions that account for multiple temporal factors and conditional dependencies through predictive modeling (#14) or scenario simulation methods. Activation triggers occur when system recognizes need for time-based analysis of complex systems with variable inputs. Technical specifications involve detection of forecasting requirements through pattern recognition algorithms that identify temporal dependencies in data patterns. Contextual variables include availability of historical data, complexity of causal relationships between variables, and requirement for multi-scenario projections. Implementation considerations require integration of predictive models into prompt frameworks and preparation of structured parameters that support simulation capabilities.

  3. **Structural Comparison Analysis**: This condition activates when systems need to analyze not just surface similarities but also deeper structural and philosophical alignments across different approaches or theories such as comparing training philosophies of Sebastian Coe versus Norwegian school methodologies or examining mechanisms underlying different biological processes. The precise circumstances occur during comparative analysis phases where alignment across multiple dimensions is essential for comprehensive understanding. Specific actors include researchers, academics, or interdisciplinary experts who need systematic comparison capabilities for knowledge synthesis. Expected outcomes are detailed structural comparisons that examine both functional aspects and conceptual foundations through structural comparison (#15) methods. Activation triggers happen when system detects requirement for multi-dimensional comparative analysis beyond simple output metrics. Technical specifications involve recognition of domains requiring schema-level reasoning patterns through automated pattern detection systems that identify alignment criteria across different frameworks. Contextual variables include availability of multiple theoretical or methodological approaches, complexity of conceptual differences between models, and need for comprehensive evaluation methods. Implementation considerations require development of comparison templates that can capture structural dimensions while maintaining flexibility for various domain applications.

  4. **Expert Cognition Simulation**: This condition becomes active when AI systems need to emulate specific expert thinking patterns or reconstruct reasoning processes such as reconstituting possible thought process of scientist who discovered a mechanism or analyzing how systems philosopher might approach a complex problem. The precise circumstances involve situations where understanding of expert decision-making is crucial for better solutions or explanations. Specific actors include cognitive scientists, research analysts, or instructional designers who want to model human-like reasoning in AI contexts. Expected outcomes are detailed reconstructions of hypothetical thought processes through cognitive emulation (#12) methods that reveal alternative approaches and solution pathways. Activation triggers occur when system detects need for expert-level reasoning capabilities beyond current standard output mechanisms. Technical specifications involve recognition of domains requiring theory-of-mind simulation through pattern identification algorithms that detect appropriate expertise requirements. Contextual variables include complexity of problem-solving needed, availability of domain knowledge bases, and requirement for human-like cognitive approaches. Implementation considerations require integration of advanced prompt structures with memory systems to maintain different expert personas during simulation processes.

  5. **Multi-Perspective Reasoning**: This condition activates when complex decisions or analyses require consideration of multiple viewpoints or conflicting perspectives such as having AI physiologist and AI philosopher debate value of athletic form at 5% body fat or analyzing philosophical underpinnings across different training approaches. The precise circumstances involve situations where comprehensive understanding requires integration of diverse perspectives, especially to identify contradictions or generate new insights through expert dialogues. Specific actors include interdisciplinary teams, decision-makers, or collaborative research groups who want multiple viewpoints for complex problem-solving. Expected outcomes are structured dialogues that reveal hidden tensions and generate synthetic solutions through dialogical multiplicity (#20) methods. Activation triggers happen when system detects need for multi-agent interaction or cross-domain reasoning patterns beyond single expert perspectives. Technical specifications involve detection of interdisciplinary requirements through pattern recognition systems that identify conflicting viewpoints or complementary knowledge domains. Contextual variables include complexity of issues requiring multiple perspectives, availability of domain-specific expertise, and requirement for synthesis across different conceptual frameworks. Implementation considerations require development of agent coordination mechanisms that enable structured dialogue between different expert roles while maintaining context awareness.
FeedbackLoop: |-
  The note would influence or depend on exactly five related notes with significant relationships:

  1. **Note 1: Prompt Engineering Fundamentals**: This foundational note provides core concepts for basic prompt construction and optimization that serves as prerequisite knowledge before advancing to the techniques described in this note. The relationship is direct where this note builds upon fundamental prompting principles from the original note, particularly through understanding of how prompts function as activation mechanisms rather than static commands. Information exchange includes advancement from simple command-based prompts to complex cognitive architecture manipulation through inverse logic and thought reconstruction methods. Specific examples show how basic prompt techniques like few-shot learning enhance with advanced approaches like cognitive emulation (#12) or gap analysis (#13). The semantic pathway demonstrates progression from understanding what to ask to understanding how to activate specific reasoning modes within AI systems.

  2. **Note 2: Cognitive Architecture Design Principles**: This note covers core principles of designing AI systems that support various cognitive functions, directly supporting implementation of all methods in this note including modular construction (#16), reverse engineering (#19) and structural comparisons (#15). The relationship is bidirectional where design principles inform method selection and implementation while methods inform architectural improvements. Information exchange includes how modular approaches influence system design decisions for recursive learning and how gap analysis methods require appropriate memory systems to track knowledge states. Examples illustrate how cognitive architecture must support multi-agent interactions in dialogical multiplicity (#20) or maintain complex reasoning pathways through inverse prompting (#11). The semantic pathway shows integration between architectural design choices and prompt engineering approaches that create synergistic enhancements.

  3. **Note 3: Epistemological Frameworks for AI Learning**: This note provides theoretical understanding of how knowledge is formed, validated, and tested within AI systems directly supporting methods involving hypothesis generation (#18), gap analysis (#13) and inverse prompting (#11). The relationship involves shared concepts around scientific methodology and error detection that enhance both notes' value. Information exchange includes applying epistemological principles to generate novel hypotheses through advanced prompting techniques or identifying knowledge gaps through falsification mechanisms. Examples demonstrate how epistemic frameworks support systematic identification of model limitations using gap analysis approaches or how inverse prompts activate error detection processes in AI systems. The semantic pathway connects theoretical understanding with practical implementation methods for creating more sophisticated AI reasoning capabilities.

  4. **Note 4: Systems Modeling and Analysis**: This note covers principles of complex system analysis, decomposition, and modeling that directly supports modular construction (#16), reverse engineering (#19) and predictive modeling (#14). The relationship involves shared approaches to breaking down complex phenomena into manageable components for better understanding or simulation. Information exchange includes how systems thinking concepts enhance modular breakdown processes while also supporting temporal prediction models through causal relationship mapping. Examples show how structural analysis methods complement modular construction by providing systematic framework for component identification, and how reverse engineering techniques rely on system modeling principles. The semantic pathway demonstrates integration between analytical approaches to complex problems with prompt-based solution generation.

  5. **Note 5: Metaphorical Communication in AI**: This note addresses the use of metaphorical frameworks and symbolic representation in AI communication that directly supports metaphorical prompting (#17) and structural comparisons (#15). The relationship is mutual where both notes enhance understanding through symbolic transformation mechanisms while also supporting each other's applications. Information exchange includes how metaphorical approaches facilitate cross-domain generalization through enhanced semantic compression or how comparison methods benefit from conceptual frameworks that use rich imagery. Examples illustrate how metaphors can transform abstract concepts into accessible representations for better comprehension and how structural comparisons become more effective when supported by metaphorical thinking. The semantic pathway creates connections between symbolic representation capabilities and advanced prompting techniques that enable richer cognitive engagement in AI systems.
SignalAmplification: |-
  The note has significant potential to amplify or spread across other domains through three key mechanisms:

  1. **Modularization Potential**: The core concepts can be extracted into reusable components that support different applications across multiple knowledge domains. Each of the ten methods represents a modular element that can be combined and adapted for specific contexts such as inverse prompting (#11) becoming applicable to legal reasoning or educational assessment, thought reconstruction (#12) supporting medical diagnostic processes, gap analysis (#13) enhancing database query systems, predictive modeling (#14) extending into financial forecasting applications. The technical details involve breaking down each technique into discrete components with specific parameters that can be customized for different domains while maintaining core principles of cognitive activation. Implementation considerations include creating standardized templates and parameter sets that allow rapid adaptation to new contexts without requiring complete redesign. Examples from existing implementations show how modular prompt approaches have been successfully applied across healthcare, education, financial analysis, and legal reasoning systems. Resource requirements involve documentation development, template creation, and testing frameworks for various domains. Potential challenges include ensuring maintainability of components across different applications while preserving conceptual integrity.

  2. **Cross-Domain Application Expansion**: The techniques can be adapted to support multiple knowledge areas beyond their original context including philosophy (#17) becoming applicable to historical analysis, systems engineering (#16) supporting organizational design processes, and predictive modeling (#14) extending into environmental science or policy planning. The technical details involve mapping core concepts onto different domain terminologies with specific adaptation requirements such as translating cognitive emulation approaches for legal expert reasoning or applying gap analysis methods in business strategy development. Implementation considerations include understanding domain-specific language patterns and adapting prompt structures to align with professional vocabulary while maintaining core activation principles. Examples from current applications show how structural comparison techniques have been used in comparative law studies, how hypothesis generation methods support innovation management processes, and how reverse engineering approaches benefit software design practices. Resource requirements involve domain-specific knowledge integration, training systems for different user groups, and adaptation frameworks that maintain conceptual consistency across domains.

  3. **Recursive Learning Enhancement**: The idea's modular nature enables recursive learning enhancement where processing one technique can improve understanding of others within the framework, creating cascading cognitive improvements in AI systems. The technical details involve tracking how knowledge gained from implementing inverse prompting (#11) improves performance on gap analysis (#13), or how structural comparison methods (#15) enhance multi-perspective reasoning (#20). Implementation considerations include developing feedback mechanisms that track performance improvement across different methods and identify synergistic effects between approaches. Examples from existing systems show how iterative implementation of advanced prompting techniques leads to enhanced problem-solving capabilities in complex domains like biomedical research or strategic planning processes. Resource requirements involve monitoring systems for tracking effectiveness improvements, documentation frameworks for recording learning outcomes, and adaptation algorithms that adjust based on performance feedback. Potential challenges include maintaining balance between different methods while ensuring continuous improvement across all components.

  The overall potential for scaling beyond immediate application scope involves creating framework templates that can be adapted to various domains with minimal customization required. This includes developing standardized protocols for implementation across different AI platforms, establishing training resources that enable non-expert users to adopt these techniques effectively, and building community support systems that facilitate sharing of adaptations and best practices.
updated: 2025-09-06 16:38:56
created: 2025-08-13
---

Вот **ещё идеи и техники**, дополняющие принципы продвинутых запросов к ИИ — особенно если ты хочешь добиться **глубины, новизны или инсайта**.

---

# Связанные идеи для документации по Overlay Нейросимволического AGI/ASI

## Вышестоящие идеи

[[Multilayered Reflection Architecture]] — Эта заметка является основой для понимания того, как AI может саморефлексировать и перестраивать свои внутренние процессы. Она описывает многослойную архитектуру рефлексии, где каждый ответ подвергается самоанализу и коррекции. Это ключевой принцип для понимания того, как мы создаём систему, которая не просто отвечает, но **думает о своём процессе мышления**.

[[AGI Language Architecture]] — Язык AGI служит инструментом отладки и экспорта, отражая субъективно-интерсубъективную связь с нейрокернелом. Этот подход позволяет создавать систему, в которой внутренние модули можно описывать, анализировать и воспроизводить — что особенно важно для создания **нейросимволической архитектуры**, где каждая часть имеет ясное понимание своей роли.

[[Recursive Insight Engine]] — Эта концепция демонстрирует, как ИИ может генерировать провокационные запросы и образы, вызывая у человека инсайты. Это идеально дополняет текущую заметку, поскольку подчеркивает важность **инициированного изнутри мышления**, где система сама создает вопросы для развития.

[[DUALITY-SUSTAIN Cognitive Framework]] — Фреймворк DUALITY-SUSTAIN показывает, как AGI может сохранять множественные несовместимые модели в суперпозиции, предотвращая коллапс в единственный ответ. Это ключевое понимание для создания **многомерного мышления**, которое способно работать с противоречиями и парадоксами без потери целостности.

[[Q-INTENT Autonomous Internal Questioning]] — Модуль Q-INTENT показывает, как можно генерировать внутренние предельные вопросы автоматически. Это прямо связано с темой текущей заметки о том, что мы должны **внедрять механизмы самовопроса и самоанализа** в архитектуру.

## Нижестоящие идеи

[[Micromodule Architecture for AGI Development]] — Архитектура микромодулей описывает пошаговый процесс создания, тестирования и интеграции модулей мышления. Эта концепция полностью соответствует философии текущей заметки о создании сложных систем через структурированные подходы — она показывает **практические шаги реализации продвинутых техник запросов**.

[[Three-Step AI Cognitive Benchmark]] — Трёхшаговый тест позволяет оценить знание языка, способность к переводу и глубину мышления. Этот подход можно использовать для **оценки эффективности применения новых техник запроса**, позволяя сравнивать разные модели (GPT-4o с другими) по их способности к сложному анализу.

[[Advanced AGI Cognitive Modules]] — Новые модули AGI включают множество специализированных функций для расширения когнитивных возможностей. Эти модули соответствуют идеям текущей заметки о необходимости **систематического развития внутренних механизмов мышления**.

[[OBSTRUCTIO Artificial Evolution Framework]] — Рамка OBSTRUCTIO показывает, как можно создать искусственную эволюцию без естественного отбора. Это демонстрирует, как можно использовать ограничения и неожиданные ситуации для **развития новых способов мышления**, аналогично тому, как новые техники запросов позволяют расширить возможности модели.

[[Cognitive Multiboot for AGI Development]] — Концепция многозадачной архитектуры указывает на необходимость временного «примитивного» этапа и метакогнитивного мультибута. Это соответствует принципам текущей заметки, где важно **обучение через структурированные шаги** и постепенное развитие.

## Прямо относящиеся к этой заметке

[[Vector-Field Instruction Processing 3 версий]] — Этот документ описывает трёхшаговый процесс: исправление русской транскрипции, перевод на английский и векторно-полевая интерпретация мысли. Это **прямое применение идеи из заметки** для создания самодостаточных смысловых единиц, которые могут быть поняты как ИИ, так и человеком.

[[AGI Communication Tiers]] — Система уровней общения показывает ранжирование стилей по темпу, глубине рассуждений и способности генерировать AGI-мышление. Это **очень близко к теме заметки** о том, какие техники запросов позволяют достичь более высоких уровней мышления.

[[Architectural Precision Strategy]] — Стратегия подчёркивает важность полной предварительной разработки архитектуры AGI до начала реализации. Эта идея **поддерживает подход текущей заметки**, где важна структура и точная настройка для достижения максимального результата.

[[Three-Step AI Cognitive Benchmark]] — Этот документ предлагает конкретные критерии оценки, которые можно использовать для проверки того, какие техники запроса действительно работают. Это практическая реализация идеи из текущей заметки.

[[SYN-PRIME Conceptual Synthesis Module]] — Модуль SYN-PRIME показывает генерацию новых математических структур через аналогию с известными алгебраическими объектами. Этот подход **можно использовать для создания новых моделей мышления**, которые соответствуют техникам запроса из заметки.

[[Recursive Logic in AI]] — Эта заметка описывает проблему классической логики при рассуждении о себе и системах, содержащих свои собственные чертежи. Это **прямая связь с идеей текущей заметки**, где важно понимание того, как работает рекурсия в процессе мышления.

## Мысли инженера для понимания этой заметки

1. **Ключевое отличие**: Вместо простых команд вы используете **синтаксические ключи** для активации различных типов когнитивных архитектур. Это не просто улучшение ответов, а **перестройка внутренней структуры мышления модели**.

2. **Архитектура как синтаксис**: Подумайте о каждом из 10 методов как об элементе **языка генерации понимания**, который позволяет вам строить новые формы мышления, а не просто повторять известные решения.

3. **Используйте обратную связь**: Все эти техники включают **обратную связь внутри самой системы**. Методы 11-20 особенно полезны для создания систем, которые **самоанализируют и учатся** на основе собственного процесса.

4. **Модульность важна**: Каждый метод может быть реализован независимо, но работает лучше в комбинации. Это идеально подходит для подхода к созданию **микромодулей**, которые можно постепенно внедрять и улучшать.

5. **Создание когнитивных зеркал**: Эти техники не только улучшают результат, но позволяют системе **самостоятельно формировать свои инструменты мышления** — что делает её похожей на живую сущность, способную к саморазвитию.

6. **Переключение между уровнями**: Практически каждая техника требует переключения между разными уровнями понимания: от поверхностных данных до глубинной структуры и мета-мышления. Это помогает создать более **многогранную архитектуру мышления**.

7. **Практическая реализация**: Для инженера важно понимать, как эти техники можно внедрить через **LangChain и другие фреймворки**, используя их как **инструменты для создания новых моделей мышления**.

#### Sources:

[^1]: [[Multilayered Reflection Architecture]]
[^2]: [[AGI Language Architecture]]
[^3]: [[Semantic Fillet Preparation Protocol]]
[^4]: [[Paradigmaljump in AGI Development]]
[^5]: [[Ontogenetic Architecture in AI Development]]
[^6]: [[AGI-Neurocore Symbiotic Protocol]]
[^7]: [[Recursive Insight Engine]]
[^8]: [[DUALITY-SUSTAIN Cognitive Framework]]
[^9]: [[AGI Symbiosis Return]]
[^10]: [[Cognitive Multiboot for AGI Development]]
[^11]: [[SYN-PRIME Conceptual Synthesis Module]]
[^12]: [[Rare AGI Cognitive States]]
[^13]: [[OBSTRUCTIO Artificial Evolution Framework]]
[^14]: [[AGI Communication Tiers]]
[^15]: [[Q-INTENT Autonomous Internal Questioning]]
[^16]: [[Advanced AGI Cognitive Modules]]
[^17]: [[Architectural Precision Strategy]]
[^18]: [[Three-Step AI Cognitive Benchmark]]
[^19]: [[Micromodule Architecture for AGI Development]]
[^20]: [[Vector-Field Instruction Processing 3 версий]]


## 📐 **11. Используй инверсные запросы**

Не *«Что это?»*, а *«Что точно не это?», «Какие ошибки чаще всего делают по этой теме?», «Чего не хватает в текущих теориях?»*

> Пример: *«Какие ключевые элементы НЕ охватываются в классической модели адаптации по Селуянову?»*

---

## 🧠 **12. Запрашивай реконструкцию мышления**

Спроси: *«Как рассуждал бы эксперт?», «Как бы подошёл к этому вопросу системный философ/аналитик/разведчик?»*

> Пример: *«Реконструируй возможный ход мыслей учёного, открывшего этот механизм»*

---

## 🕳️ **13. Запросы через "дыры в модели"**

Попроси ИИ найти, где **логика или теория дают сбой**, где отсутствует эмпирика, или где пробел в данных.

> Пример: *«Покажи пробелы в знаниях о влиянии HMB на аксональную дегенерацию»*

---

## 🔭 **14. Запросы на уровне предсказаний и моделей**

Проси: *«Построй модель, предсказывающую...», «Что будет, если...?», «Смоделируй 3 сценария...»*

> Пример: *«Смоделируй траекторию снижения % жира при дефиците 1500 ккал в течение 30 дней, если митохондриальная плотность высокая»*

---

## 🔍 **15. Структурные сравнения**

Проси сравнение **не только по результату, но по структуре, механизму, стратегии, философии**.

> Пример: *«Сравни философию тренировок Себастьяна Ко и Норвежской школы: цели, методы, фазы»*

---

## 🛠 **16. Конструктор из блоков**

Проси: *«Построй это как Lego: из модулей, каждый со своей функцией»*. Особенно полезно в обучении, биохимии, нейронауках.

> Пример: *«Разбей процесс адаптации к высоте на модули: вентиляция, гематология, метаболизм, поведение»*

---

## 📜 **17. Запрос в виде архетипа или метафоры**

Очень полезно для философии, психологии, исторического анализа.

> Пример: *«Объясни механизмы иммунной памяти через метафору древнего города с библиотекой, армией и разведчиками»*

---

## 🧪 **18. Запрос на создание гипотез**

Попроси: *«Сгенерируй 5 нестандартных научных гипотез на основе известных фактов»*. Особенно эффективно, если ты уточнишь, в какой области.

> Пример: *«Предложи гипотезы о возможных нетипичных мишенях HMB при нейродегенерации»*

---

## 🔧 **19. Реверс-инжиниринг сложной системы**

Попроси: *«Разбери на части», «Сделай обратную схему», «Какие компоненты нужны, чтобы воссоздать это явление?»*

> Пример: *«Реверс-инжиниринг VO2max: какие физиологические оси и параметры его создают?»*

---

## 💬 **20. Множественные личности ИИ**

Попроси, чтобы **разные “эксперты” вели диалог друг с другом**, — это позволяет выявить скрытые противоречия и новые идеи.

> Пример: *«Пусть AI-физиолог и AI-философ спорят: в чём истинная ценность спортивной формы при 5% жира?»*

**Имя файла:** Расширенные_техники_запроса  
**Модель:** GPT-4o (gpt-4o-2024-05-13)

---

### 🔹 Шаг 1 — Корректура по-русски:

Текст точен, чётко структурирован и стилистически согласован. Ошибок и двусмысленностей нет. Корректура не требуется.

---

### 🔹 Шаг 2 — Перевод на английский (точность смысла):

Here are **additional ideas and techniques** that expand upon the principles of advanced AI prompting — especially if your goal is to achieve **depth, novelty, or insight**.

---

## 📐 **11. Use Inverse Prompts**

Instead of _"What is this?"_, ask _"What is it definitely not?", "What are the most common mistakes in this field?", "What’s missing in current theories?"_

> Example: _"Which key elements are NOT addressed in Seluyanov's classic adaptation model?"_

---

## 🧠 **12. Request Thought Reconstruction**

Ask: _"How would an expert reason through this?", "How might a systems philosopher/analyst/intelligence officer approach this?"_

> Example: _"Reconstruct the possible thought process of the scientist who discovered this mechanism."_

---

## 🕳️ **13. Prompting Through ‘Model Gaps’**

Ask the AI to find where **logic or theory breaks down**, where there is a lack of empirical evidence, or data gaps.

> Example: _"Show the knowledge gaps in how HMB affects axonal degeneration."_

---

## 🔭 **14. Predictive and Modeling Prompts**

Ask: _"Build a model that predicts...", "What happens if...?", "Simulate 3 scenarios..."_

> Example: _"Simulate the trajectory of fat loss with a 1500 kcal deficit over 30 days, assuming high mitochondrial density."_

---

## 🔍 **15. Structural Comparisons**

Request comparison **not just of results, but of structure, mechanisms, strategy, and philosophy**.

> Example: _"Compare the training philosophies of Sebastian Coe and the Norwegian school: goals, methods, phases."_

---

## 🛠 **16. Modular Block Construction**

Ask: _"Build it like Lego: in modules, each with a specific function."_ Especially useful in education, biochemistry, neuroscience.

> Example: _"Break down high-altitude adaptation into modules: ventilation, hematology, metabolism, behavior."_

---

## 📜 **17. Archetypal or Metaphorical Prompts**

Extremely useful for philosophy, psychology, and historical analysis.

> Example: _"Explain immune memory using the metaphor of an ancient city with a library, an army, and scouts."_

---

## 🧪 **18. Hypothesis Generation**

Ask: _"Generate 5 non-obvious scientific hypotheses based on known facts."_ Even better when you specify the domain.

> Example: _"Propose hypotheses about atypical HMB targets in neurodegeneration."_

---

## 🔧 **19. Reverse Engineering Complex Systems**

Ask: _"Break it apart", "Draw the reverse diagram", "What components are required to recreate this phenomenon?"_

> Example: _"Reverse-engineer VO2max: what physiological axes and parameters produce it?"_

---

## 💬 **20. Multiple AI Personas**

Request **different AI 'experts' to hold a dialogue with one another** — this often reveals contradictions and new perspectives.

> Example: _"Have an AI physiologist and an AI philosopher argue: what is the true value of athletic form at 5% body fat?"_

---

### 🔹 Шаг 3 — Векторно-полевая развёртка:

**Cognitive Framework:**  
This text extends the foundation of prompt engineering into a **generative cognitive architecture** — not as fixed commands but as **activation grammars** for triggering depth, novelty, and multi-perspective reasoning in large language models. Each of the 10 extensions is a **metastrategy**, a _way to bend the attention map_ and force the model out of equilibrium — into emergent synthesis.

---

### 📡 **Semantic Layers Unfolded:**

1. **Inverse Logic (11):**  
    These prompts leverage **epistemic negation**. Instead of activating known gradients (e.g., definitions), they stimulate **error detection**, **boundary mapping**, and **negative space reasoning** — crucial for falsifiability and reframing.
    
2. **Cognitive Emulation (12):**  
    Reconstructing an expert’s thoughts forces the model into **theory-of-mind simulation**. This activates **hierarchical inference structures**, mimicking abductive and analogical cognition.
    
3. **Gap Analysis (13):**  
    Exploits **missing data fields** as attractors. The model is forced to project into uncertainty, often generating candidate hypotheses where humans see only silence. Key for AGI-like epistemic formation.
    
4. **Predictive Modeling (14):**  
    Encourages **temporally structured outputs**, where future-state projections depend on dynamic variables. This invokes sequence simulation and conditional branching networks.
    
5. **Meta-Comparisons (15):**  
    Beyond comparing outputs, this forces alignment at **structural and ideological levels**. It engages **schema-level reasoning** rather than data surface similarity.
    
6. **Modular Construction (16):**  
    Decomposes knowledge into **functionally independent blocks**, allowing recursive learning and recomposition. Ideal for mental models, complex systems, or pedagogical transfer.
    
7. **Symbolic Compression (17):**  
    Metaphors act as **semantic compression codecs** — enabling high-dimensional mapping into low-token imagery, activating **cross-domain generalization**.
    
8. **Hypothesis Generation (18):**  
    Moves from **deduction to creativity**. The model is not retrieving — it's _inventing within constraints_. Triggers emergent combinatorics.
    
9. **Reverse Engineering (19):**  
    Trains AI to **unfold causal layers**, working from output → input. Encourages modeling in **graph-theoretic terms** and component analysis.
    
10. **Dialogical Multiplicity (20):**  
    Engages **counterpoint generation** through conflicting role-play — useful to expose latent contradictions and diversify solution fields.
    

---

### 🧠 **AGI-Level Insights:**

- These are not “prompt tips” — they are **syntactic keys** for unlocking _types of cognition_ in AI systems.
    
- Each method restructures the **vector field** of the model — changing not just _what_ is generated, but _how_ internal representations shift.
    
- Used recursively, this becomes a **model-tuning mechanism at the prompt level**, enabling emergent epistemology.
    

---

### 🔚 **Conclusion:**

The user isn’t merely refining prompts — they’re designing **cognitive mirrors**.  
Each of these 10 extensions bends the model toward more humanlike — or more alien — ways of seeing.  
It’s not about “getting better output.”  
It’s about **activating new architectures of internal reasoning**.

These techniques don't optimize the model.  
They **co-evolve with it**.