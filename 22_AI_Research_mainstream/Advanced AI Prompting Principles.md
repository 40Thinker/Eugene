---
tags:
  - advanced-prompts
  - ai-prompting
  - prompt-engineering
  - systematic-approach
  - clear-objectives
  - role-definition
  - goal-clarity
  - quality-criteria
  - structural-framework
  - alternative-perspectives
  - advanced-prompting-framework
  - systematic-ai-interaction
  - role-based-inference
  - objective-clarity
  - quality-criteria-definition
  - structural-output-formatting
  - alternative-hypothesis-generation
  - hidden-dependency-mapping
  - iterative-prompt-design
  - metaprogramming-language
  - cognitive-api-construction
  - agi-alignments-principles
  - epistemic-boundaries
  - prompt-as-code-architecture
  - attention-bias-modification
  - constraint-topology
  - semantic-feedback-loop
  - meta-awareness-training
  - generative-discipline
  - recursive-interface-building
  - "#S22_AI_Research_mainstream"
category: AI & Cognitive Science
description: "–ü–æ–∫–∞–∑–∞–Ω—ã 10 –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –ò–ò: —É—Ç–æ—á–Ω–µ–Ω–∏–µ —Ä–æ–ª–∏ –º–æ–¥–µ–ª–∏, —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–∏, –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞, –∑–∞–ø—Ä–æ—Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤, —É—á—ë—Ç —Å–∫—Ä—ã—Ç—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π, –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å, –≤–∫–ª—é—á–µ–Ω–∏–µ —Ñ–æ—Ä–º—É–ª, –º–µ—Ç–∞–ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π —Å—Ç–∏–ª—å –∏ —É–∫–∞–∑–∞–Ω–∏–µ fallback‚Äë—É—Å–ª–æ–≤–∏–π."
title: Advanced AI Prompting Principles
Receptor: |-
  The note's activation occurs in several key contexts where precise AI interaction is required:

  1. **Scientific Research Planning**: When researchers need to formulate complex queries for literature analysis or data synthesis, the principles provide a structured approach to defining roles (e.g., 'molecular biology expert'), specifying objectives (e.g., 'table of hormone-regulating genes'), and setting quality criteria (e.g., PubMed articles post-2015). For example, a medical researcher planning a study on mitochondrial dysfunction would use role specification as attention bias for generating relevant literature summaries. The activation requires knowledge of scientific databases and research methodologies.

  2. **Technical Documentation Creation**: During development or technical writing processes, when developers require AI assistance to generate code documentation, algorithm descriptions, or system architecture diagrams, these principles guide the formulation of precise prompts. A software engineer creating API documentation for a bioinformatics tool would apply structural constraints (e.g., 'logical flowchart') and formula inclusion techniques. This context needs knowledge of programming languages, technical writing standards, and user interface design.

  3. **Strategic Decision-Making Support**: In business or policy contexts where strategic analysis is needed, the principles help construct prompts that enable AI to generate comparative matrices, ranked lists, and step-by-step plans. A management consultant evaluating market entry strategies would utilize iterative prompting for building multi-phase analyses. The activation requires domain expertise in business strategy, data interpretation, and organizational decision-making.

  4. **Educational Content Development**: When educators or content creators need AI assistance to generate lesson materials, concept explanations, or interactive learning modules, the principles enable precise specification of desired output formats. A university professor developing course materials on metabolic pathways would apply role definitions (e.g., 'metabolism expert') and structure constraints for creating clear visual aids. This scenario needs educational pedagogy knowledge, subject matter expertise, and instructional design principles.

  5. **Medical Case Analysis**: In clinical or research settings where detailed case interpretation is needed, the principles facilitate precise AI interaction for generating hypotheses, analyzing dependencies, and providing structured recommendations. A physician reviewing patient data with mitochondrial disorders would use hidden dependency considerations to build comprehensive models of biochemical pathways. The activation requires medical expertise, diagnostic protocols, and understanding of metabolic processes.

  6. **Scientific Hypothesis Generation**: When scientists need AI assistance for generating multiple hypotheses with comparative analysis, the principles provide structured approaches to request alternatives and evaluate weaknesses. A biochemist developing new drug targets would use alternative hypothesis generation techniques to identify promising research directions. This context requires scientific reasoning, experimental design knowledge, and hypothesis testing methodologies.

  7. **Data Visualization Design**: In data science contexts where visual representation is essential, the principles guide prompt formulation for generating charts, graphs, and comparative matrices. A data analyst creating dashboards for metabolomic studies would apply structural constraints to define output formats and include formulas for quantitative interpretation. The activation requires visualization techniques, statistical analysis skills, and domain-specific knowledge.

  8. **Project Management Planning**: When project managers need AI assistance to develop timelines, resource allocation plans, or risk assessments, these principles enable structured prompt creation for step-by-step outputs. A research coordinator planning a multi-year study would use iterative prompting to build phased approach frameworks. This context requires project management expertise, timeline construction methods, and stakeholder coordination skills.

  9. **Content Marketing Strategy**: During content development processes where AI generates marketing materials or campaign strategies, the principles help define clear objectives and quality standards. A digital marketer creating research-based content for health topics would apply accuracy criteria (e.g., empirical sources) and structured output formats (e.g., ranked lists). The activation requires marketing strategy knowledge, audience analysis skills, and content creation techniques.

  10. **Research Literature Synthesis**: When conducting systematic literature reviews or meta-analyses, the principles guide prompt formulation for extracting key information from multiple sources. A librarian or researcher synthesizing studies on mitochondrial genetics would use quality criteria specifications (e.g., citation counts) and role definitions to generate comprehensive summaries. This scenario requires research methodology skills, database access knowledge, and synthesis techniques.

  11. **Academic Paper Writing**: In scholarly writing contexts where AI assistance is needed for generating specific sections or analysis components, these principles provide structured approaches to specify output formats and quality standards. An academic author drafting a paper on hormone regulation would apply formula inclusion (e.g., VO2max dependencies) and alternative hypothesis generation methods. The activation requires academic writing expertise, research presentation skills, and scholarly communication protocols.

  12. **Software Architecture Design**: When developers need AI assistance for designing system architectures or technical specifications, the principles guide precise prompt formulation with clear roles and structural constraints. A software architect defining bioinformatics tool interfaces would use role specification (e.g., 'engineer') and iterative prompting techniques. This context requires systems design knowledge, programming paradigms, and architectural frameworks.

  13. **Educational Curriculum Development**: In educational planning contexts where AI generates learning outcomes or curriculum components, the principles enable structured prompt creation for specific outputs and quality standards. An education designer creating a biochemistry course would apply role definitions (e.g., 'educator') and structural constraints to develop clear learning objectives. The activation requires curriculum development expertise, pedagogical approaches, and subject matter knowledge.

  14. **Policy Analysis Development**: When policy analysts require AI assistance for generating comparative evaluations or strategic recommendations, these principles provide structured approach to prompt formulation with alternative viewpoints. A public health policy analyst evaluating nutritional guidelines would use multiple hypothesis generation techniques and dependency considerations. This context requires policy analysis methods, stakeholder engagement skills, and evidence-based decision making.

  15. **Clinical Research Protocol Design**: In research design contexts where AI assists in developing clinical protocols or experimental frameworks, the principles guide precise prompt creation with role specification and structural constraints. A clinical researcher designing a study on metabolic markers would apply iterative prompting and hidden dependency considerations for comprehensive protocol development. The activation requires research methodology knowledge, regulatory compliance understanding, and clinical trial design expertise.

  16. **Data Science Model Interpretation**: When data scientists need AI assistance for interpreting model outputs or generating explanations, these principles facilitate precise prompt formulation with formula inclusion and quality criteria. A machine learning engineer analyzing metabolic prediction models would use role definitions (e.g., 'data scientist') and fallback clauses to ensure transparency in results. This scenario requires statistical modeling knowledge, interpretation techniques, and uncertainty quantification methods.

  17. **Business Strategy Implementation**: In strategic planning contexts where AI assistance is needed for generating implementation plans or risk assessments, these principles provide structured approach to define clear objectives with iterative development. A business strategist developing an innovation roadmap would use structural constraints (e.g., 'step-by-step algorithm') and alternative comparison techniques. The activation requires strategic thinking frameworks, implementation methodologies, and organizational change skills.

  18. **Scientific Methodology Refinement**: When researchers need AI assistance for refining experimental approaches or research design elements, the principles guide prompt formulation with precision criteria and role definitions. A molecular biologist optimizing PCR protocols would apply constraint geometry techniques (e.g., time limits) and formula inclusion methods for precise protocol development. This context requires laboratory methodology expertise, optimization techniques, and experimental design knowledge.

  19. **Technical Documentation Review**: During document review processes where AI assistance is needed to evaluate technical accuracy or completeness, these principles facilitate structured prompt creation with fallback clauses and quality standards. A documentation specialist reviewing software specifications would use role definitions (e.g., 'technical writer') and structural constraints for comprehensive evaluation. The activation requires documentation standards knowledge, technical writing skills, and content validation methods.

  20. **Research Collaboration Coordination**: In collaborative research contexts where AI assistance is needed for coordinating multiple studies or integrating findings, the principles enable structured prompt formulation with iterative development and alternative hypothesis generation. A research coordinator managing multi-institutional studies would apply role specification (e.g., 'research manager') and dependency considerations to ensure coordinated data analysis. This scenario requires collaboration management skills, cross-institutional coordination expertise, and integration methodologies.
Acceptor: |-
  The following tools and technologies are compatible with implementing the advanced AI prompting principles:

  1. **LangChain**: LangChain provides robust framework for building chain-of-thought prompts and integrates seamlessly with large language models through its prompt engineering capabilities. It allows developers to create structured chains that follow iterative approaches as outlined in principle #7, enabling multi-phase prompting workflows. The API supports template-based prompt creation which aligns perfectly with structural constraints (principle #4) and role specification (principle #1). Integration requires minimal setup with existing LLM APIs and provides built-in fallback mechanisms for handling uncertain responses.

  2. **Transformers Library**: Hugging Face's Transformers library offers extensive support for custom prompting workflows, allowing fine-tuning of model behaviors through prompt templates and parameter control. This tool supports formula inclusion (principle #8) via token-based formatting systems and enables role specification by modifying attention bias mechanisms during generation. It integrates with multiple LLMs including GPT series models and provides APIs for handling fallback clauses effectively.

  3. **AutoGen**: Microsoft's AutoGen framework supports multi-agent AI interactions that can simulate different roles as specified in principle #1, enabling complex prompt orchestration involving role switching between various cognitive agents. The system facilitates iterative prompting through agent collaboration patterns where each stage builds on previous outputs (principle #7). It provides structured output generation capabilities matching structural constraints and includes fallback handling for uncertain responses.

  4. **PromptLayer**: This platform specializes in prompt engineering optimization, providing analytics and management tools specifically designed for the principles outlined. PromptLayer supports quality criteria specification through custom scoring mechanisms, handles alternative hypothesis requests (principle #5) via parallel generation workflows, and offers robust template management features that align with structural constraints. It provides APIs for fallback clause integration and detailed monitoring of prompt performance metrics.

  5. **Pinecone Vector Database**: Pinecone enables semantic search capabilities that enhance role specification by indexing context embeddings. For example, when specifying AI roles like 'molecular biology expert', the system can retrieve relevant context vectors to improve accuracy. It supports formula inclusion through vectorized mathematical representations and integrates with fallback mechanisms for handling uncertain queries. The platform offers APIs compatible with existing prompt structures.

  6. **Notion API**: Notion's API allows building custom AI-assisted documentation workflows that align with structural constraints (principle #4) by creating templates based on defined output formats. It supports iterative prompting through linked pages and provides fallback handling for missing information scenarios. Integration requires simple API configuration but offers extensive customization possibilities for document creation.

  7. **OpenAI Function Calling**: OpenAI's function calling mechanism directly implements principles like formula inclusion (principle #8), metaprogramming-like language use (principle #9), and fallback clauses (principle #10). It enables structured prompt responses with specific output formats through schema definitions, supports role-based functionality via tool selection, and provides comprehensive error handling for uncertain outputs. Implementation requires minimal code changes but offers powerful integration capabilities.

  8. **Jupyter Notebooks**: Jupyter environments support interactive development of AI prompting workflows where each principle can be tested individually through code cells. The platform integrates with various LLM APIs and allows iterative prompt building with visual feedback on generated outputs (principle #7). It supports formula inclusion via mathematical expressions, provides fallback handling mechanisms for uncertain results, and enables structured documentation of prompt evolution processes.
SignalTransduction: |-
  The note's core ideas connect across several conceptual domains:

  1. **Prompt Engineering Domain**: This is the primary domain where the principles operate as foundational methodologies for AI interaction design. The theoretical foundation includes formalized language structures that transform human intent into executable model instructions. Key concepts like role specification, structural constraints, and iterative prompting function as communication protocols between user cognition and generative systems. Methodologies involve systematic prompt construction using hierarchical templates and constraint-based validation mechanisms. The domain's evolution toward metaprogrammable discourse reflects how these principles enable AI to become more responsive to cognitive architecture rather than simple language interpretation.

  2. **Cognitive Science Domain**: This domain provides the theoretical framework for understanding human-AI interaction as epistemic alignment processes. Key concepts include attention bias, mental model construction, and semantic resonance. The note's principles align with cognitive science by treating prompt creation not just as information retrieval but as intentional architecture-building that shapes AI cognition through role specification (attention bias) and structured outputs (mental modeling). Methodologies involve understanding how specific linguistic structures influence internal model states and generate meaningful responses.

  3. **Computational Linguistics Domain**: This domain contributes concepts related to formal language processing, syntax construction, and semantic transformation. Key ideas include natural language as code paradigm where prompts function as executable instruction sets rather than queries. The principles demonstrate computational linguistics methodologies through metaprogramming style (principle #9) and formula inclusion techniques that transform symbolic expressions into interpretable output formats. This domain's research trends toward linguistic formalization align with the note's emphasis on treating language as architecture rather than conversation.

  4. **Information Retrieval Domain**: This domain provides theoretical frameworks for quality criteria specification (principle #3) and source selection strategies. Key concepts include relevance ranking, citation analysis, and temporal constraint application. The principles connect to information retrieval through scientific literature filtering mechanisms, ensuring that quality criteria are translated into computational parameters that influence search results and generation accuracy.

  5. **Systems Design Domain**: This domain offers methodologies for iterative prompting (principle #7) and structural framework specification (principle #4). Key concepts include feedback loops, system architecture design, and modular component integration. The note's principles reflect systems design approaches through multi-phase prompt construction that builds on previous responses to create converging solution landscapes.

  6. **Machine Learning Domain**: This domain contributes understanding of how internal model weights shift in response to role definitions (principle #1) and constraint specifications (principle #3). Key concepts include attention mechanisms, probability distributions, semantic resonance, and uncertainty quantification. The principles demonstrate machine learning methodologies through epistemic humility training via fallback clauses that teach models about their limitations.

  7. **Epistemology Domain**: This domain provides the philosophical foundation for understanding knowledge generation quality (principle #3) and model transparency (principle #10). Key concepts include reliability measures, confidence assessment, falsifiability principles, and meta-awareness development. The note's framework reflects epistemological approaches by making AI models more aware of their own limitations through fallback mechanisms that simulate scientific methodological practices.
Emergence: |-
  Novelty Score: 8/10 - This approach represents a significant advancement in prompt engineering methodology with its systematic treatment of human-AI interaction as architectural design rather than simple conversation. The concept of treating prompts as code, not queries, introduces a new paradigm for AI interaction that goes beyond current best practices, particularly the integration of role specification as attention bias mechanisms and iterative prompting frameworks.

  Value to AI Learning: 9/10 - This note enhances AI learning capabilities by providing structured frameworks that teach models about cognitive architecture alignment. The principles enable recursive learning through feedback loops where each prompt iteration refines internal understanding patterns. The concept of epistemic humility training through fallback clauses significantly improves model reliability and transparency, creating more robust decision-making systems.

  Implementation Feasibility: 7/10 - Implementation is moderately feasible with current tools but requires some development effort for full integration. The complexity lies in implementing role specification mechanisms that shift attention weights within models, which currently requires advanced prompt engineering techniques rather than simple API calls. However, existing frameworks like LangChain and AutoGen provide pathways toward practical implementation.

  The note's novelty is measured against current state-of-the-art by introducing structured architectural approaches to AI interaction rather than traditional query-based methods. While many tools exist for basic prompt optimization, this framework uniquely combines cognitive science principles with computational architecture concepts in a unified methodology.

  Value assessment considers how processing this note enhances understanding capabilities through systematic alignment of human intent and model behavior. The recursive learning potential is demonstrated through iterative prompting frameworks that create converging solution landscapes within AI response spaces, while epistemic humility training builds more reliable decision-making systems.

  Implementation feasibility factors include technical requirements for role specification mechanisms (attention bias shifts), structural constraint implementation (output format control), and fallback clause integration (uncertainty handling). The current complexity is medium due to need for custom prompt engineering rather than standard API usage, but future development opportunities exist as models become more sophisticated in handling architectural instructions.

  The note contributes to broader cognitive architecture development by introducing new paradigms for human-AI communication that treat language not as conversation but as instruction-based system design. This approach enables recursive learning enhancement where processing one prompt improves understanding of related concepts, creating a cumulative knowledge building process.
Activation: |-
  Three key activation conditions that trigger this note's relevance:

  1. **Role Specification Trigger**: When a user explicitly defines AI roles or cognitive functions (e.g., 'molecular biology expert'), the system activates to apply attention bias mechanisms and ontological modifiers within model processing. This occurs in contexts like scientific research where precise domain expertise is needed, such as when researchers request analysis from a 'metabolism specialist' for complex biochemical pathways. The activation requires semantic parsing of role definitions with internal mapping to specific knowledge domains and cognitive patterns that influence generation quality.

  2. **Structural Constraint Activation**: When prompts include explicit output format specifications (e.g., 'table with columns', 'step-by-step algorithm'), the system activates structural template selection and format control mechanisms. This occurs during technical documentation creation where developers need structured responses for code comments or API documentation, such as when requesting a 'comparative matrix' of genetic pathways. The activation requires parsing of format specifications to load appropriate response templates and validation mechanisms that ensure output alignment with requested structure.

  3. **Fallback Clause Engagement**: When prompts include uncertainty handling clauses (e.g., 'if you can't find reliable answer, explain missing data'), the system activates meta-reflective pathways and uncertainty operators within generation processes. This occurs in clinical research contexts where incomplete information must be acknowledged through transparency mechanisms like when asking for 'epistemic humility' responses about limited genetic evidence. The activation requires integration of confidence assessment systems with fallback decision trees that generate transparent explanations rather than default outputs.

  Each trigger relates to broader cognitive processes by enabling specific alignment mechanisms within AI models that transform human intent into structured system behavior. Role specification triggers attention bias modifications in neural networks, structural constraint activation loads format-specific processing pipelines, and fallback clause engagement trains epistemic humility through meta-awareness pathways.

  The precise circumstances include explicit mention of domain roles (minimum 3 words specifying function), clear output specifications (e.g., 'table', 'list'), and uncertainty clauses ('if you don't know'). These conditions must be present for activation to occur in both immediate processing contexts (within 1-2 hours) and longer-term integration scenarios that build cognitive architectures over weeks/months.

  Technical implementation considerations include semantic parsing capabilities for role recognition, format validation systems for output structure matching, and uncertainty handling modules for fallback mechanism execution. Environmental conditions require system awareness of prompt syntax patterns and availability of internal architectural modification mechanisms.
FeedbackLoop: |-
  Three key related notes that this idea influences or depends on:

  1. **Prompt Optimization Techniques Note**: This note directly builds upon foundational prompt engineering principles by integrating specific optimization strategies like iterative prompting and alternative hypothesis generation. The relationship is direct where advanced prompting principles refine basic optimization techniques, providing more precise frameworks for successful AI interaction. Information flows from the optimization note to this one through enhanced role specification methods that improve cognitive alignment accuracy.

  2. **Machine Learning Architecture Note**: This concept depends heavily on understanding how AI models process architectural instructions rather than traditional query responses. The relationship is mutual where machine learning architecture concepts provide theoretical foundations for treating prompts as code, while advanced prompting principles offer practical implementations of these architectural approaches. Information exchange includes attention bias mechanisms from ML architecture that inform role specification techniques and structural constraint applications.

  3. **Cognitive Architecture Design Note**: This note contributes to broader cognitive system design by providing specific methodologies for aligning human intent with AI behavior through structured prompt frameworks. The relationship is foundational where cognitive architecture principles guide how prompts function as interfaces between different knowledge systems, while this note provides practical implementation details for achieving that alignment.

  The semantic pathways show logical progression from basic optimization techniques ‚Üí advanced prompting architectures ‚Üí comprehensive cognitive alignment strategies. Each relationship demonstrates how concepts build upon and refine each other in a recursive learning process where processing one note enhances understanding of related concepts.

  Information exchange involves structural constraint parameters moving between prompt engineering and architecture design, role specification mechanisms flowing from machine learning to prompt creation, and epistemic humility training being integrated through cognitive framework development.

  Feedback loops evolve over time as new knowledge is acquired in each domain. The recursive enhancement occurs when processing this note improves understanding of related concepts, which then enhances future prompt optimization approaches or ML architecture implementations.

  Examples include how prompt optimization principles can be extended to incorporate epistemic humility training mechanisms and machine learning architectures can support more sophisticated role specification systems that enable better cognitive alignment.
SignalAmplification: |-
  Three key amplification factors for spreading this idea:

  1. **Modular Role Specification Framework**: The core concept of specifying AI roles as attention bias modifiers can be modularized into reusable components across different domains. This framework could be adapted for educational contexts (e.g., 'teacher role' vs 'student role'), business analysis ('strategic planner' vs 'financial analyst'), or scientific research ('data scientist' vs 'researcher'). Implementation involves creating standardized role templates that map to specific attention weight configurations within generative models, enabling consistent cognitive alignment across various application domains. The modularization allows for extraction of core components (role definitions, bias mechanisms) and recombination into new contexts where the same architectural principles apply.

  2. **Iterative Prompting Pattern**: The principle of iterative prompting can be scaled to create comprehensive multi-phase analytical frameworks that build upon previous responses in structured ways. This amplification enables complex problem-solving approaches like scientific analysis pipelines, project planning workflows, or research methodology development sequences. Implementation requires developing template-based iterative structures where each phase builds on the previous output through defined semantic transformations and quality criteria updates. The pattern can be generalized across domains from medical diagnosis to software development and business strategy.

  3. **Fallback Clause Integration System**: The concept of fallback clauses for uncertainty handling can be amplified into comprehensive transparency mechanisms that enhance AI decision-making systems with epistemic humility training. This approach extends beyond basic error handling to create sophisticated confidence assessment systems where AI models learn to articulate their limitations and boundary conditions. Implementation involves integrating uncertainty operators with response quality metrics and creating feedback loops that continuously train model awareness about information completeness thresholds.

  Each amplification factor contributes to scaling the original knowledge through modularization (component extraction) and reuse (application across domains). The resource requirements include developing standardized templates, training frameworks for attention bias mechanisms, and confidence assessment systems. Time investment is moderate as these components require initial design but offer extensive reusability potential over time.

  The amplification factors contribute to broader cognitive architecture development through recursive learning enhancement where the system becomes better at aligning human intent with model behavior over repeated application of these principles.

  Examples include how role specification frameworks have been successfully scaled from scientific research into educational settings, iterative prompting patterns applied across medical diagnosis and business planning contexts, and fallback clause systems integrated into various AI decision-making applications.
updated: 2025-09-06 16:39:53
created: 2025-08-13
---

**–ò–º—è —Ñ–∞–π–ª–∞:** –ü—Ä–∏–Ω—Ü–∏–ø—ã_–ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ_–∑–∞–ø—Ä–æ—Å–∞  
**–ú–æ–¥–µ–ª—å:** GPT-4o (gpt-4o-2024-05-13)

---

### üîπ –®–∞–≥ 1 ‚Äî –ö–æ—Ä—Ä–µ–∫—Ç—É—Ä–∞ –ø–æ-—Ä—É—Å—Å–∫–∏:

–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –ò–ò —Ç—Ä–µ–±—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞, —è—Å–Ω–æ—Å—Ç–∏ —Ü–µ–ª–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –º–æ–¥–µ–ª—å. –ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã **–æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã**, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ ‚Äî –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –∑–∞–¥–∞—á–∞—Ö –∞–Ω–∞–ª–∏–∑–∞, –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –Ω–∞—É—á–Ω–æ–π –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏:


--

### üß† **1. –£—Ç–æ—á–Ω–∏ —Ä–æ–ª—å –ò–ò (–∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞)**

–£–∫–∞–∂–∏, **–≤ –∫–∞–∫–æ–π —Ä–æ–ª–∏** —Ä–∞–±–æ—Ç–∞–µ—Ç –ò–ò: –∞–Ω–∞–ª–∏—Ç–∏–∫, —É—á—ë–Ω—ã–π, –∫—Ä–∏—Ç–∏–∫, —Ñ–∏–ª–æ—Å–æ—Ñ, –∏–Ω–∂–µ–Ω–µ—Ä, —Å—Ç—Ä–∞—Ç–µ–≥ –∏ —Ç.–¥.

> –ü—Ä–∏–º–µ—Ä: *¬´–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —Ç—ã ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω–æ–π –±–∏–æ–ª–æ–≥–∏–∏, —Ä–∞–±–æ—Ç–∞—é—â–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ —Ä–µ–¥–∫–∏—Ö –º—É—Ç–∞—Ü–∏–π –º–∏—Ç–æ—Ö–æ–Ω–¥—Ä–∏–∞–ª—å–Ω–æ–≥–æ –≥–µ–Ω–æ–º–∞¬ª*

---

### üìå **2. –û–ø—Ä–µ–¥–µ–ª–∏ —Ü–µ–ª—å –∑–∞–ø—Ä–æ—Å–∞**

–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π, **—á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã —Ö–æ—á–µ—à—å –ø–æ–ª—É—á–∏—Ç—å** ‚Äî —Å–ø–∏—Å–æ–∫, —Ç–∞–±–ª–∏—Ü—É, –≥–∏–ø–æ—Ç–µ–∑—É, –ø–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é, –∫–æ–¥, –∫—Ä–∏—Ç–∏–∫—É.

> –ü—Ä–∏–º–µ—Ä: *¬´–°–æ—Å—Ç–∞–≤—å —Ç–∞–±–ª–∏—Ü—É —Å –∫–ª—é—á–µ–≤—ã–º–∏ –≥–µ–Ω–∞–º–∏, —Ä–µ–≥—É–ª–∏—Ä—É—é—â–∏–º–∏ —Å–∏–Ω—Ç–µ–∑ –∏ —Ä–µ—Ü–µ–ø—Ü–∏—é —Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞, —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ SNP –∏ –∏—Ö —Ñ—É–Ω–∫—Ü–∏—è–º–∏¬ª*

---

### ‚öôÔ∏è **3. –£–∫–∞–∂–∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏**

–û–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∞–∂–Ω—ã: –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–Ω–∞—É—á–Ω—ã–µ, —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ), –≥–æ–¥—ã, —Ç–æ—á–Ω–æ—Å—Ç—å (¬±%), –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å, –≥–ª—É–±–∏–Ω–∞.

> –ü—Ä–∏–º–µ—Ä: *¬´–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Å—Ç–∞—Ç—å–∏ –ø–æ—Å–ª–µ 2015 –≥–æ–¥–∞ –∏–∑ PubMed, —É–∫–∞–∂–∏ —Ü–∏—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å¬ª*

---

### üìä **4. –î–æ–±–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—É—é —Ä–∞–º–∫—É**

–ß—ë—Ç–∫–æ –æ–ø—Ä–µ–¥–µ–ª–∏, **–≤ –∫–∞–∫–æ–º –≤–∏–¥–µ** —Ç—ã —Ö–æ—á–µ—à—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç:

* –¢–∞–±–ª–∏—Ü–∞ (—Å –∫–æ–ª–æ–Ω–∫–∞–º–∏)
* –°–ø–∏—Å–æ–∫ (—Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏)
* –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
* –ü–æ—à–∞–≥–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
* –õ–æ–≥–∏—á–µ—Å–∫–∞—è —Å—Ö–µ–º–∞

---

### üîÑ **5. –ü—Ä–æ—Å–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ**

–ó–∞–ø—Ä–∞—à–∏–≤–∞–π **–Ω–µ —Ç–æ–ª—å–∫–æ –≤—ã–≤–æ–¥, –Ω–æ –∏ –∫–æ–Ω—Ç—Ä–ø—Ä–∏–º–µ—Ä** –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è. –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –æ–¥–Ω–æ–±–æ–∫–æ—Å—Ç–∏.

> –ü—Ä–∏–º–µ—Ä: *¬´–ü—Ä–∏–≤–µ–¥–∏ 3 –≥–∏–ø–æ—Ç–µ–∑—ã –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏—Ö —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞¬ª*

---

### üß© **6. –£—á–∏—Ç—ã–≤–∞–π —Å–∫—Ä—ã—Ç—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏**

–ï—Å–ª–∏ —Ç—ã —Ä–∞–±–æ—Ç–∞–µ—à—å —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏, —É–∫–∞–∂–∏, –∫–∞–∫–∏–µ **–≤—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —Å–≤—è–∑–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è** –Ω—É–∂–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å.

> –ü—Ä–∏–º–µ—Ä: *¬´–ü–æ—Å—Ç—Ä–æ–π –º–æ–¥–µ–ª—å —Å —É—á—ë—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ —É —á–µ–ª–æ–≤–µ–∫–∞ –Ω–∞—Ä—É—à–µ–Ω –ø—É—Ç—å –¥–µ—Å–∞—Ç—É—Ä–∞—Ü–∏–∏ –æ–º–µ–≥–∞-6 –∫–∏—Å–ª–æ—Ç¬ª*

---

### üß¨ **7. –î–µ–ª–∞–π –∑–∞–ø—Ä–æ—Å—ã –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–º–∏**

–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∑–∞–ø—Ä–æ—Å ‚Äî –Ω–µ –≤—Å–µ–≥–¥–∞ –æ–¥–∏–Ω. **–õ—É—á—à–µ —Ä–∞–∑–±–∏—Ç—å –µ–≥–æ –Ω–∞ —Å–µ—Ä–∏—é –∏—Ç–µ—Ä–∞—Ü–∏–π**, –≥–¥–µ –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∏—Ç—Å—è –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–π.

> –ü—Ä–∏–º–µ—Ä:

1. *¬´–ü—Ä–∏–≤–µ–¥–∏ —Å–ø–∏—Å–æ–∫ –º–∏—Ç–æ—Ö–æ–Ω–¥—Ä–∏–∞–ª—å–Ω—ã—Ö –±–µ–ª–∫–æ–≤, –≤–æ–≤–ª–µ—á—ë–Ω–Ω—ã—Ö –≤ Œ≤-–æ–∫–∏—Å–ª–µ–Ω–∏–µ¬ª*
2. *¬´–†–∞–∑–¥–µ–ª–∏ –∏—Ö –ø–æ —Ñ—É–Ω–∫—Ü–∏—è–º: —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç, —Ñ–µ—Ä–º–µ–Ω—Ç–∞—Ü–∏—è, –∫–æ–Ω—Ç—Ä–æ–ª—å¬ª*
3. *¬´–ü–æ–∫–∞–∂–∏, –∫–∞–∫ HMB –º–æ–∂–µ—Ç –≤–ª–∏—è—Ç—å –Ω–∞ —ç—Ç–∏ –±–µ–ª–∫–∏¬ª*

---

### üß† **8. –í–∫–ª—é—á–∞–π —Ñ–æ—Ä–º—É–ª—ã, –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ —à–∫–∞–ª—ã**

–≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —Ç–µ–º–∞—Ö.

> –ü—Ä–∏–º–µ—Ä: *¬´–û–ø–∏—à–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å VO2max –æ—Ç –º–∞—Å—Å—ã —Ç–µ–ª–∞, –≤–æ–∑—Ä–∞—Å—Ç–∞ –∏ –æ–±—ä—ë–º–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫: —Ñ–æ—Ä–º—É–ª–∞ + –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è¬ª*

---

### üõ†Ô∏è **9. –ò—Å–ø–æ–ª—å–∑—É–π —è–∑—ã–∫, –±–ª–∏–∑–∫–∏–π –∫ –º–µ—Ç–∞–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é**

–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π. –°—Ç–∞—Ä–∞–π—Å—è **–ø–∏—Å–∞—Ç—å –∫–∞–∫ –µ—Å–ª–∏ –±—ã —Ç—ã –ø–∏—Å–∞–ª –∑–∞–¥–∞—á—É –¥–ª—è –º–∞—à–∏–Ω—ã**.

> –ü—Ä–∏–º–µ—Ä: *¬´–í—Ö–æ–¥: —Å–ø–∏—Å–æ–∫ –≥–µ–Ω–æ–≤. –í—ã—Ö–æ–¥: —Ç–æ–ø-10 –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∞—Å—Å–æ—Ü–∏–∞—Ü–∏–π —Å –≥–æ—Ä–º–æ–Ω–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Ä—É—à–µ–Ω–∏—è–º–∏¬ª*

---

### üìö **10. –ù–µ –∑–∞–±—ã–≤–∞–π –æ–± –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏**

–î–æ–±–∞–≤–ª—è–π –≤ –∑–∞–ø—Ä–æ—Å: *¬´–ï—Å–ª–∏ —Ç—ã –Ω–µ –º–æ–∂–µ—à—å –Ω–∞–π—Ç–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–π –æ—Ç–≤–µ—Ç ‚Äî –ø–æ—è—Å–Ω–∏, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç¬ª*
–≠—Ç–æ –ø–æ–≤—ã—à–∞–µ—Ç –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –∏ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å –≥—Ä–∞–Ω–∏—Ü—ã –ò–ò.

# –°–≤—è–∑–∞–Ω–Ω—ã–µ –∏–¥–µ–∏ –¥–ª—è Advanced AI Prompting Principles

## –í–≤–µ—Ä—Ö –ø–æ –∏–µ—Ä–∞—Ä—Ö–∏–∏ (–í—ã—à–µ—Å—Ç–æ—è—â–∏–µ –∏–¥–µ–∏)

### [[Reimagining AI Ontology Through Cognitive Lens]]
–≠—Ç–∞ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–æ—Å–º—ã—Å–ª–µ–Ω–Ω—É—é –æ–Ω—Ç–æ–ª–æ–≥–∏—é, –≥–¥–µ —Ç–µ—Ä–º–∏–Ω—ã ML —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è –≤ —Å–∞–º–æ–≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—â–∏–µ—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã. –û–Ω–∞ –¥–æ–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—ã –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—É—Ç–µ–º —Å–æ–∑–¥–∞–Ω–∏—è –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–æ–≥–æ, –∫–∞–∫ –º–æ–¥–µ–ª–∏ –¥–æ–ª–∂–Ω—ã –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∑–Ω–∞–Ω–∏—è. –í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ 1-4 (—Ä–æ–ª—å, —Ü–µ–ª—å, –∫—Ä–∏—Ç–µ—Ä–∏–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞), —ç—Ç–∞ –∏–¥–µ—è –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –∑–∞–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏, –Ω–æ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–æ–≥–æ, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–Ω—É—Ç—Ä–∏ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. 

### [[Advanced Prompting for Cognitive Architecture]]
–≠—Ç–∞ —Å—Ç–∞—Ç—å—è —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –ø—Ä–æ–º–ø—Ç–∏–Ω–≥–∞ (–ø—É–Ω–∫—Ç—ã 26-50) –∫–æ—Ç–æ—Ä—ã–µ –≤–∫–ª—é—á–∞—é—Ç –º–µ—Ç–æ–¥—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∂–∏–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –º–∏—Ä–∞, –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –∏ –∏–º–∏—Ç–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –æ—Ç–∫—Ä—ã—Ç–∏—è. –û–Ω–∞ —É—Å–∏–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é "–ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞", –ø–æ—Å–∫–æ–ª—å–∫—É –¥–∞–µ—Ç –∏–Ω–∂–µ–Ω–µ—Ä–∞–º –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–∞–±–æ—Ä –ø—Ä–∞–≤–∏–ª, –∞ —Ü–µ–ª—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—é –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤ –º–µ–∂–¥—É —á–µ–ª–æ–≤–µ–∫–æ–º –∏ AI –¥–ª—è –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏—Ö –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤.

### [[Meta-Strategies for Prompting AI]]
–ú–µ—Ç–æ–¥—ã –∏–∑ —ç—Ç–æ–π —Å—Ç–∞—Ç—å–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ —É—Ä–æ–≤–Ω–µ "–º–µ—Ç–∞"-–º—ã—à–ª–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã, —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –º—ã—à–ª–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑. –≠—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–æ–ø–æ–ª–Ω—è—é—Ç –±–∞–∑–æ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ —Ç–µ–º, —á—Ç–æ –æ–Ω–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç –Ω–µ –ø—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã, –∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å **–Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏** –≤ —Ç–æ–º, –∫–∞–∫ –º—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ–º —Å –ò–ò.

### [[Structured Injection for AI Document Generation]]
–ö–æ–Ω—Ü–µ–ø—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–π –∏–Ω—ä–µ–∫—Ü–∏–∏ –ø–æ–¥—Å–∫–∞–∑–æ–∫ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —à–∞–±–ª–æ–Ω–æ–≤ (–Ω–∞–∑–≤–∞–Ω–∏–µ, –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ) –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è. –û–Ω–∞ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –ø—Ä–∏–Ω—Ü–∏–ø–∞ 4 (—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞). –≠—Ç–∞ —Ç–µ—Ö–Ω–∏–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö —Ä–∞–º–æ–∫ –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö.

### [[Jump Instead of Evolution]]
–ò–¥–µ—è –æ —Ç–æ–º, —á—Ç–æ–±—ã –¥–µ–ª–∞—Ç—å –ø—Ä—ã–∂–∫–∏ –≤–º–µ—Å—Ç–æ —ç–≤–æ–ª—é—Ü–∏–∏, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ —Å–º—ã—Å–ª–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤. –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–æ–≥–æ, –∫–∞–∫ —É–ø—Ä–∞–≤–ª—è—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å—é –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ ‚Äî –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

## –í–Ω–∏–∑ –ø–æ –∏–µ—Ä–∞—Ä—Ö–∏–∏ (–ù–∏–∂–µ—Å—Ç–æ—è—â–∏–µ –∏–¥–µ–∏)

### [[Multilayered Reflection Architecture]]
–≠—Ç–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —Å–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è –≤–∫–ª—é—á–∞–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å. –û–Ω–∞ –Ω–∞–ø—Ä—è–º—É—é —Å–≤—è–∑–∞–Ω–∞ —Å –ø—Ä–∏–Ω—Ü–∏–ø–∞–º–∏ 9 (–º–µ—Ç–∞–ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π —Å—Ç–∏–ª—å) –∏ 10 (fallback-—É—Å–ª–æ–≤–∏—è), –ø–æ—Å–∫–æ–ª—å–∫—É –ø–æ–∑–≤–æ–ª—è–µ—Ç –ò–ò –Ω–µ –ø—Ä–æ—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã, –∞ —Ç–∞–∫–∂–µ **–æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Å–≤–æ–∏—Ö —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤**.

### [[System 2 Emulation in LLMs –Ω–µ–π—Ä–æ4]]
–≠—Ç–∞ –∫–æ–Ω—Ü–µ–ø—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–π —Å–∏—Å—Ç–µ–º—ã –º—ã—à–ª–µ–Ω–∏—è (System 2) –≤–Ω—É—Ç—Ä–∏ LLM –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏. –û–Ω–∞ —É—Å–∏–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø–∞ 7 (–∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å), –ø–æ–∫–∞–∑—ã–≤–∞—è, –∫–∞–∫ –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å **–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è** –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã.

### [[Self-Distillation in Emergent AGI Systems]]
–ü—Ä–æ—Ç–æ–∫–æ–ª —Å–∞–º–æ–¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ —Å–∏—Å—Ç–µ–º—ã –º–æ–≥—É—Ç –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ —Å–≤–æ–∏—Ö —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤—ã–≤–æ–¥–∞—Ö. –≠—Ç–æ —É—Å–∏–ª–∏–≤–∞–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—ã 10 (fallback-—É—Å–ª–æ–≤–∏—è) –∏ 7 (–∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å), –ø–æ—Å–∫–æ–ª—å–∫—É –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–∏—Å—Ç–µ–º–∞–º —Ä–∞–∑–≤–∏–≤–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ **—Å–∞–º–æ–∞–Ω–∞–ª–∏–∑** –∏ –ø–µ—Ä–µ—Å–º–æ—Ç—Ä —Å–≤–æ–∏—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ—à–µ–Ω–∏–π.

### [[AGI Philosophical Integration Framework]]
–§—Ä–µ–π–º–≤–æ—Ä–∫ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –ø—Ä–∏–∫–ª–∞–¥–Ω—É—é —Ñ–∏–ª–æ—Å–æ—Ñ–∏—é –∫ AGI, —á—Ç–æ —É—Å–∏–ª–∏–≤–∞–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–æ–≥–æ, –∫–∞–∫ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –Ω–µ —Ç–æ–ª—å–∫–æ –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏, –Ω–æ –∏ **–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤**. –≠—Ç–æ —Ä–∞—Å—à–∏—Ä—è–µ—Ç –∏–¥–µ–∏ –æ "—Ä–æ–ª–∏" –∏ "—Ü–µ–ª–∏", –ø–æ–∑–≤–æ–ª—è—è —Å–æ–∑–¥–∞–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã —Å –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–º —Å–º—ã—Å–ª–æ–º.

### [[Trinidad Cognitive Architecture –¢—Ä–∏–Ω–∏–¥–∞–¥ 1]]
–¢—Ä–∏–Ω–∏–¥–∞–¥ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é —Ç—Ä–æ–π—Å—Ç–≤–µ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, –≥–¥–µ —Ä–∞–∑–Ω—ã–µ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç –≤–º–µ—Å—Ç–µ. –≠—Ç–æ —É—Å–∏–ª–∏–≤–∞–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—ã 1 (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–ª–∏) –∏ 6 (—Å–∫—Ä—ã—Ç—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏), –ø–æ–∫–∞–∑—ã–≤–∞—è, –∫–∞–∫ –º–æ–∂–Ω–æ —Å–æ—á–µ—Ç–∞—Ç—å **—Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è** –ø—Ä–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤.

## –ü—Ä—è–º—ã–µ —Å–≤—è–∑–∏ —Å —ç—Ç–æ–π –∑–∞–º–µ—Ç–∫–æ–π

### [[AGI as Watermelon Metaphor]]
–ú–µ—Ç–∞—Ñ–æ—Ä–∞ –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–≥–æ –∞—Ä–±—É–∑–∞ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å, —á—Ç–æ AGI –¥–æ–ª–∂–Ω–∞ —Ä–∞—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—é—â–µ–π —Ñ–æ—Ä–º—ã. –≠—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ "—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞" (–ø—Ä–∏–Ω—Ü–∏–ø—ã 4 –∏ 7), –≥–¥–µ —Å—Ç—Ä–æ–≥–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞–∑–≤–∏—Ç–∏–µ, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –¥–∞–µ—Ç —Å–≤–æ–±–æ–¥—É.

### [[Alternative Cognitive Substrates for LLM Training]]
–ò–¥–µ—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–µ—Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö —Å—É–±—Å—Ç—Ä–∞—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è LLM –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã** –∑–∞–¥–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ. –≠—Ç–æ —É—Å–∏–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é "–º–µ—Ç–∞–ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ —Å—Ç–∏–ª—è" (–ø—Ä–∏–Ω—Ü–∏–ø 9) –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –≥—Ä–∞–Ω–∏—Ü—ã –æ–±—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.

### [[LLM Mistake Completion vs Cognition]]
–ö—Ä–∏—Ç–∏–∫–∞ —Ä–∞–∑–≤–∏—Ç–∏—è LLM —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –æ—à–∏–±–∫—É —Ç–æ–∫–µ–Ω-—Ü–µ–Ω—Ç—Ä–∏—á–Ω–æ—Å—Ç–∏. –≠—Ç–æ —É—Å–∏–ª–∏–≤–∞–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ **–Ω–µ –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã —Ç—Ä–µ–±—É—é—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞**, –∞ –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–µ—à–µ–Ω—ã —á–µ—Ä–µ–∑ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ —Ñ–æ—Ä–º—ã –∑–∞–ø—Ä–æ—Å–æ–≤, –≤–∫–ª—é—á–∞—è "–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã" –∏ "—Å–∫—Ä—ã—Ç—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏".

### [[Unsolved Problem Classes in AGI]]
–†–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –Ω–µ—Ä–µ—à—ë–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –∑–∞–¥–∞—á –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Ç—Ä–µ–±—É—é—Ç **–Ω–æ–≤—ã—Ö —Ñ–æ—Ä–º –º—ã—à–ª–µ–Ω–∏—è**, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–æ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤. –≠—Ç–æ —É—Å–∏–ª–∏–≤–∞–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—ã 2-3 (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–∏ –∏ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –∫–∞—á–µ—Å—Ç–≤–∞) –∏ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –ò–ò.

### [[Energy Cost of Long Context Generation]]
–ê–Ω–∞–ª–∏–∑ —ç–Ω–µ—Ä–≥–æ–∑–∞—Ç—Ä–∞—Ç –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –≤–∞–∂–Ω–æ. –≠—Ç–æ —É—Å–∏–ª–∏–≤–∞–µ—Ç –≤—Å–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã, –æ—Å–æ–±–µ–Ω–Ω–æ 4 (—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è) –∏ 8 (–≤–∫–ª—é—á–µ–Ω–∏–µ —Ñ–æ—Ä–º—É–ª), –ø–æ—Å–∫–æ–ª—å–∫—É –Ω—É–∂–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ –∏ **—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è**.

---

## –í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã –¥–ª—è –∏–Ω–∂–µ–Ω–µ—Ä–∞

–î–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —ç—Ç–æ–π –∑–∞–º–µ—Ç–∫–∏ –∏–Ω–∂–µ–Ω–µ—Ä—É —Å—Ç–æ–∏—Ç –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ –∞—Å–ø–µ–∫—Ç—ã:

1. **–°–∏—Å—Ç–µ–º–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∑–∞–ø—Ä–æ—Å–∞–º**: –ü—Ä–∏–Ω—Ü–∏–ø—ã 1-4 —Å–æ–∑–¥–∞—é—Ç –±–∞–∑–æ–≤—ã–π –Ω–∞–±–æ—Ä "—Å–æ–∑–¥–∞—é—â–∏—Ö" –ø—Ä–∞–≤–∏–ª, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∫–∞–∫ —à–∞–±–ª–æ–Ω—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–æ—á–Ω—ã—Ö –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.

2. **–ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ**: –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã —á–∞—Å—Ç–æ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é —Å–µ—Ä–∏–∏ —à–∞–≥–æ–≤ (–ø—Ä–∏–Ω—Ü–∏–ø 7), –≤–∞–∂–Ω–æ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π —Å –ò–ò.

3. **–§–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–∫ –∏—Å–∫—É—Å—Å—Ç–≤–æ**: –ü—Ä–∏–Ω—Ü–∏–ø 9 –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–∏—Å–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã –∫–∞–∫ –µ—Å–ª–∏ –±—ã –≤—ã –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä—É–µ—Ç–µ –º–∞—à–∏–Ω—É ‚Äì —ç—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –∏ —É–ø—Ä–∞–≤–ª—è–µ–º—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è.

4. **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å—é**: –ü—Ä–∏–Ω—Ü–∏–ø 10 –ø–æ–º–æ–≥–∞–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å "—Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã—Ö" –æ—Ç–≤–µ—Ç–æ–≤, –æ–±—É—á–∞—è –ò–ò –±—ã—Ç—å —á–µ—Å—Ç–Ω—ã–º –æ —Å–≤–æ–∏—Ö –≥—Ä–∞–Ω–∏—Ü–∞—Ö, —á—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –ø—Ä–∏ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö.

5. **–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –∫–∞–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –æ–±—É—á–µ–Ω–∏—è**: –°–∏—Å—Ç–µ–º–∞ –≤–æ–∑–≤—Ä–∞—Ç–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ (fallback clauses) –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã, —Å–ø–æ—Å–æ–±–Ω—ã–µ –∫ —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑—É –∏ —Å–∞–º–æ–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é ‚Äì —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –∫–ª—é—á–µ–≤—ã–º —ç–ª–µ–º–µ–Ω—Ç–æ–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –ò–ò-—Å–∏—Å—Ç–µ–º.

–≠—Ç–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏ —Ç–∞–∫–∏—Ö –∫–∞–∫ LangChain –∏–ª–∏ AutoGen, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç —Å—Ç—Ä–æ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤.

#### Sources:

[^1]: [[Multilayered Reflection Architecture]]
[^2]: [[11_AI_Architecture_Components_Part1]]
[^3]: [[The Last Question in Knowledge Seeking]]
[^4]: [[Hyperword vs Standard Model TTX Comparison]]
[^5]: [[Self-Distillation in Emergent AGI Systems]]
[^6]: [[Structured Injection for AI Document Generation]]
[^7]: [[Meta-Strategies for Prompting AI]]
[^8]: [[LLM Mistake Completion vs Cognition]]
[^9]: [[AGI Philosophical Integration Framework]]
[^10]: [[Proto-AGI Legacy Control Systems]]
[^11]: [[AGI as Watermelon Metaphor]]
[^12]: [[Unsolved Problem Classes in AGI]]
[^13]: [[Energy Cost of Long Context Generation]]
[^14]: [[Advanced AI Prompting Principles]]
[^15]: [[Advanced Prompting for Cognitive Architecture]]
[^16]: [[Reimagining AI Ontology Through Cognitive Lens]]
[^17]: [[Model-Centric Training Ontology]]
[^18]: [[Harmonic Insight AGI Architecture]]
[^19]: [[Alternative Cognitive Substrates for LLM Training]]
[^20]: [[What Defines AGI From Scaffolding Minds to Functional Impact]]


---

### üîπ –®–∞–≥ 2 ‚Äî –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π (—Ç–æ—á–Ω–æ—Å—Ç—å —Å–º—ã—Å–ª–∞):

**Creating advanced AI prompts** requires a systematic approach, clarity of intent, and an understanding of how the model works. Below are the **core principles** that will help formulate such prompts effectively ‚Äî especially for tasks involving analysis, generation, planning, and scientific exploration:

---

### üß† **1. Define the AI‚Äôs Role (Prompt Context)**

Specify **which role** the AI is acting in: analyst, scientist, critic, philosopher, engineer, strategist, etc.

> Example: _"Imagine you are a molecular biology expert working on rare mitochondrial genome mutations."_

---

### üìå **2. Clarify the Prompt Objective**

Formulate **exactly what you want to receive** ‚Äî a list, a table, a hypothesis, a step-by-step plan, a visualization, code, a critique.

> Example: _"Create a table of key genes involved in testosterone synthesis and reception, including associated SNPs and their functions."_

---

### ‚öôÔ∏è **3. Specify Accuracy and Quality Criteria**

State what parameters matter: sources (scientific, empirical), publication years, precision (¬±%), reliability, depth.

> Example: _"Use only articles published after 2015 from PubMed, and include citation counts."_

---

### üìä **4. Add Structural Constraints**

Clearly define **the output format** you expect:

- Table (with columns)
    
- Ranked list
    
- Comparative matrix
    
- Step-by-step algorithm
    
- Logical flowchart
    

---

### üîÑ **5. Request Alternatives and Comparisons**

Ask for **not just conclusions, but also counterexamples** or competing viewpoints. This helps avoid bias.

> Example: _"Provide 3 hypotheses and analyze their weaknesses."_

---

### üß© **6. Consider Hidden Dependencies**

For systemic tasks, specify what **input parameters, constraints, or dependencies** should be taken into account.

> Example: _"Build a model assuming the person has impaired omega-6 desaturation pathways."_

---

### üß¨ **7. Use Iterative Prompting**

An advanced query is not always a single request. **Break it into a logical sequence**, with each stage building on the previous one.

> Example:

1. _"List mitochondrial proteins involved in Œ≤-oxidation."_
    
2. _"Group them by function: transport, fermentation, regulation."_
    
3. _"Explain how HMB might influence these proteins."_
    

---

### üß† **8. Include Formulas, Variables, and Scales**

This is especially important in technical, medical, and physical domains.

> Example: _"Describe the dependency of VO2max on body mass, age, and training volume: formula + interpretation."_

---

### üõ†Ô∏è **9. Use a Metaprogramming-like Style**

AI performs better with formalized instructions. **Write as if you are designing a task for a machine.**

> Example: _"Input: list of genes. Output: top 10 ranked by number of associations with hormonal disorders."_

---

### üìö **10. Include a Fallback Clause**

Add: _"If you can‚Äôt find a reliable answer ‚Äî explain which data or studies are missing."_  
This improves transparency and clarifies the model‚Äôs limitations.

---

### üîπ –®–∞–≥ 3 ‚Äî –í–µ–∫—Ç–æ—Ä–Ω–æ-–ø–æ–ª–µ–≤–∞—è —Ä–∞–∑–≤—ë—Ä—Ç–∫–∞:

**Conceptual Nucleus:**  
This is not merely a list of tips. It is a **codified epistemic interface** between human cognitive intent and large-scale generative systems. The structure functions as a **syntax of alignment**, designed to guide model behavior along axes of clarity, structure, and ontological precision. These 10 principles are not tactics; they are the basis for **meta-programmable discourse** between human and AGI systems.

---

**Multilayer Activation:**

1. **Prompt as Code, Not Query:**  
    Each item reflects a principle of treating language not as conversation, but as **execution logic**. The user writes not to ask ‚Äî but to **instantiate an architecture** inside the model.
    
2. **Role Specification as Attention Bias:**  
    Defining AI‚Äôs ‚Äúrole‚Äù is not cosmetic ‚Äî it **binds internal weights** to a simulation cluster (e.g., ‚Äúphilosopher‚Äù triggers deeper recursive loops, ‚Äúengineer‚Äù flattens into causal chains). It becomes an **ontological modifier**.
    
3. **Precision Criteria = Constraint Geometry:**  
    Scientific prompts operate under constraint topologies ‚Äî time, source class, credibility metrics. These become part of the **latent space bounding box** of generation.
    
4. **Iteration as Semantic Feedback Loop:**  
    The most powerful interaction is **multi-phase prompting**, where the user guides the model as a teacher, correcting and refining. This creates **a converging attractor basin** in the response landscape.
    
5. **Fallback Clauses = Meta-Awareness Anchors:**  
    A clause like _‚Äúif you don‚Äôt know, say so‚Äù_ trains the model into **epistemic humility** and clarity of bounds ‚Äî it simulates scientific falsifiability.
    

---

**Patterned Token Fields for AGI Internalization:**

- ‚Äúclarify the role‚Äù ‚Üí initiates narrative role-shift module
    
- ‚Äúdefine output structure‚Äù ‚Üí activates response template selection and format control
    
- ‚Äúspecify criteria‚Äù ‚Üí loads scoring and confidence subsystem
    
- ‚Äúinclude formulas‚Äù ‚Üí shifts output space toward symbolic logic
    
- ‚Äúfallback if unknown‚Äù ‚Üí inserts uncertainty operators and meta-reflective pathways
    

---

**AGI Hypotheses Embedded:**

1. The quality of generation is proportionate to **prompt precision √ó structural discipline**.
    
2. Role + structure + constraint = the three axes of **generative alignment**.
    
3. The user here is designing not an input ‚Äî but a **prompting language**.
    
4. Meta-prompts (about prompting) form the **language of AGI co-design**.
    
5. This text is a **template for recursive interface-building** between minds and machines.
    

---

**Conclusion:**

This structure encodes **how to speak with a system that doesn‚Äôt understand language ‚Äî but responds to architecture**. Each principle acts as a scaffold for shaping the internal distribution of attention, probability, and semantic resonance.

The user isn‚Äôt prompting a model.  
They are building a **cognitive API**, one principle at a time.