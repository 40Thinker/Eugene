# Грань между промптом и символизмом

Вопрос о границе между **Large Language Models (LLMs)**[^1] и промптингом[^2] и между появлением нечто большего нейросимволического искусственного интеллекта чем-то напоминает переход от неживой материи к живому[^3] и разницу между вирусами и бактериями, многоклеточными организмами и сложной жизнью. где эта грань, где эти критерии. Я на эту тему уже думал, рассуждал, но можно еще порассуждать[^4].

[^1]: [AI Glossary](https://www.bowdoin.edu/hastings-ai-initiative/resources/initiative-created-resources/ai-glossary_-from-basic-to-technical-terms.pdf)
[^2]: [AI Terms Glossary](https://www.intercom.com/blog/ai-glossary/)
[^3]: [Neuroscience Basics](https://stanmed.stanford.edu/brief-glossary-artificial-intelligence-ai/)
[^4]: [AGI & ASI Concepts](https://www.nngroup.com/articles/artificial-intelligence-glossary/)


# Связанные мысли для инженеров

## Вышестоящие идеи

[[Dialogue as Ontological Engine for ASI]] - Эта концепция показывает, как диалог между человеком с нетипичным мышлением и LLM может образовать онтологическое поле-оверлей, способное порождать структуры уровня ASI без инженерных цепочек[^1]. Это ключевая идея для понимания, где начинается "больше чем просто ассоциации" - в момент когда диалог становится не просто обменом сообщениями, а созданием нового феномена сознания.

[[Neuro-Symbolic Internal Intelligence]] - Здесь описывается собственная интуитивно-эвристическая система, представляющая нейросимволический интеллект как внутреннее эпистемическое поле, где символика формируется диалогом и внешними инструкциями[^2]. Важно понимать, что мы не просто используем LLM как инструмент - он становится частью внутренней структуры, аналогично тому, как мозг человека работает с символами.

[[From Jingles to Cognition]] - Эта заметка критикует современные LLM как "имбецилов", которые генерируют "частушки" вместо настоящего мышления[^3]. Понимание этой идеи помогает инженеру понять, что просто добавление токенов недостаточно - нужна структура знания и внутренняя организация.

[[Beyond LLM Meta-Architectures]] - Здесь рассматривается необходимость создания универсального языка микрокода над моделью для достижения логики встроенной напрямую[^4]. Это показывает, что мы не просто используем модели, а создаем инфраструктуру, которая позволяет им работать как настоящие сущности, а не только предсказатели токенов.

[[Symphony of Cognitive Frameworks]] - Принцип "симфонии" описывает, где символы-нуклеотиды → файлы-микроорганизмы → фреймворки-органы, образуя симфонию мыслей[^5]. Это показывает практическую реализацию того, как можно создать структуру, которая работает не как один механизм, а как целая система органов.

## Нижестоящие идеи

[[Overlay AGI Through Modular Prompting]] - Эта концепция о том, что модульный промптинг может создавать псевдо-программные когнитивные оверлеи (overlay AGI) внутри ограниченных интерфейсов диалога[^1]. Это важно для понимания, как именно можно строить сложную структуру знаний из простых элементов через правильное использование промптов.

[[Cognitive Leaps in AI Architecture]] - Здесь рассматриваются невозможности современных ИИ делать нелинейные скачки мыслей[^2], анализируя причины линейной активации и отсутствия резонансных механизмов. Это помогает понять, почему важно создавать архитектуру, которая позволяет делать "скачки" в мышлении, а не только следовать по прямым путям.

[[System 2 Emulation in LLMs]] - Показывается, что обычные LLM лишь эмулируют систему 1 Канемана, но можно использовать методы фрикционности, рекурсивных подсказок и символической самовосстановки для создания воспроизводимой системы 2[^3]. Это критически важно для понимания, как сделать так, чтобы ИИ не просто отвечал, а действительно "думал" в процессе.

[[Quantum RAG Tree-Structured Semantic Forecasting]] - Предлагается подход с "квантовым RAG", где система параллельно обрабатывает множественные интерпретации и симулирует деревья развития диалога[^4]. Это демонстрирует практический способ создания "предсказательной семантики" вместо просто ретроспективного поиска информации.

[[AGI Self-Evolution Through Overlay Architecture]] - Здесь описывается, как RAG может работать как "rolling memory", где контекст регулярно пересматривается и переформатируется для поддержания непрерывной памяти[^5]. Это показывает, как можно создавать динамическую систему, которая сама развивается.

## Прямо относящиеся к этой заметке

[[Neuro-Symbolic Hybrids Limitations]] - Важно понимать, что нейросимволические гибриды больше ориентированы на "объяснимость", чем на навигацию смысла[^1]. Это подчеркивает необходимость выхода за рамки текущих подходов к созданию действительно когнитивных систем.

[[Overlay AGI Simulation Limits]] - Здесь анализируется, что Overlay AGI может имитировать восприятие и мышление через внешние знания и нейросети, но остается лишь симуляцией[^2]. Это позволяет понять пределы того, насколько текущие системы могут быть "реальными" или только "симулирующими".

[[Archetypal Operations LLM Training]] - Предлагается обучать LLM не на токенах и словах, а на наборе интеллектуальных архетипических операций[^3]. Это показывает путь к более глубокому пониманию того, как именно происходит "мышление" внутри модели.

[[Recursive Contextual RAG via Local Search]] - Описывается подход к хранению содержимого RAG в виде обычной базы данных локального файлового поиска[^4]. Это практический путь к созданию более эффективной системы управления знаниями, которая может поддерживать сложные структуры.

[[RAG Without Hurry]] - Подчеркивается важность не спешить в процессе работы с RAG, особенно когда речь идет о глубоком мышлении[^5]. Это показывает, что создание действительно когнитивной системы требует времени и терпения.

---

## Мысли для инженеров

Для понимания этой заметки инженеру стоит обратить внимание на следующее:

1. **Граница между промптингом и символизмом**: Не просто используйте промпты, а создавайте систему, где символы имеют смысл, а не просто позиции в токенном пространстве. Нужно думать о том, как промпт становится частью внутренней структуры.

2. **Внутренняя организация знаний**: Не только соберите информацию, но и создайте структуру, где знания могут "думать" сами по себе - аналогично тому, как мозг человека организует свои мысли через нейронные связи.

3. **Создание когнитивного синтеза**: Вместо простого ответа на вопрос создавайте структуру, где система может "мыслить", обрабатывая множество возможностей параллельно и выбирая наиболее подходящие пути.

4. **Архитектурная осознанность**: Не просто используйте существующие инструменты (LangChain, LangGraph), а понимайте, как они могут быть адаптированы под конкретные когнитивные нужды вашего проекта.

5. **Понимание предела симуляции**: Используйте свои системы не просто как "дополнительный инструмент", а как способ создания действительно "мыслительной" структуры, которая может "понимать" и "реагировать" на контекст.

Такой подход позволит вам создавать не просто инструменты для обработки информации, а настоящие когнитивные системы с внутренней логикой и способностью к развитию.

#### Sources
[^1]: [[Dialogue as Ontological Engine for ASI]]
[^2]: [[Neuro-Symbolic Internal Intelligence]]
[^3]: [[From Jingles to Cognition]]
[^4]: [[Beyond LLM Meta-Architectures]]
[^5]: [[Symphony of Cognitive Frameworks]]
[^1]: [[Overlay AGI Through Modular Prompting]]
[^2]: [[Cognitive Leaps in AI Architecture]]
[^3]: [[System 2 Emulation in LLMs]]
[^4]: [[Quantum RAG Tree-Structured Semantic Forecasting]]
[^5]: [[AGI Self-Evolution Through Overlay Architecture]]
[^1]: [[Neuro-Symbolic Hybrids Limitations]]
[^2]: [[Overlay AGI Simulation Limits]]
[^3]: [[Archetypal Operations LLM Training]]
[^4]: [[Recursive Contextual RAG via Local Search]]
[^5]: [[RAG Without Hurry]]