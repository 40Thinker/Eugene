>[!nexus_user] **User** - 10.06.2025 at 16:12
> Обсудил с спецом по ИИ, он не имеет опыта обучения под узкие сферы на малых датасетах. Я могу собрать наверное 400 000 страниц текста который может быть базой для моих вглядов спорте. Могу еще миллионы страниц в потенциале собирать 2-3 кругов источников и делать переосмысления учебников. Но не миллиарды страниц. Интересен реальный опыт проектов, где под узкие сферы учили на уникальных или малых датасетах стандартные модель 7-70б, если нет на этом диапазоне - опыт с более больших моделей. Чтобы понимать практические кейсы обучения под узкие сферы либо под уникальные взгляды, как повышали приоритет над классическими взгляда на что-то обучения допустим. какое качество дают малые, но уникальные и насыщенные дата сеты.
<!-- UID: 7b80f92e-eb1f-48d1-9bfd-bcce0eccb446 -->




>[!nexus_agent] **Assistant** - 10.06.2025 at 16:12
> Хочу убедиться, что точно понял твою цель. Ты хочешь примеры реальных проектов или исследований, где:
> 
> 1. Обучали или дообучали стандартные open-source модели (7B–70B, можно и больше),
> 2. На малых, но уникальных или специально отобранных датасетах (в духе "когнитивно насыщенных" или "узконаправленных"),
> 3. Для получения уникальных reasoning/взглядов в узкой области (например, спорт, биотехнологии, философия и т.п.),
> 4. При этом интересует не теоретика, а реальный опыт, результаты и выводы: насколько это помогает, насколько смещает мышление модели, какое качество достигается по сравнению с просто большим количеством общих данных.
> 
> Ты хочешь узнать примеры из открытого доступа: статьи, посты, публикации команд, чей опыт можно изучить — правильно ли понимаю? Хочешь ли ты также, чтобы я включил кейсы с "инверсией приоритетов" — когда модель при fine-tune начинала думать не как GPT/stackoverflow, а по логике кастомного мира (например, философского подхода или спортивной системы)?
<!-- UID: 68f2e8c8-bd8c-43ee-8ac9-5cad2f1c4d49 -->