>[!nexus_user] **User** - 27.05.2025 at 11:11
> —É–≥–ª—É–±–∏ –ø–ª–∞–Ω: üß± II. –ë–ê–ó–ê. –õ–û–ö–ê–õ–¨–ù–´–ô –ó–ê–ü–£–°–ö –ú–û–î–ï–õ–ò (–Ω–∞ –ø—Ä–∏–º–µ—Ä–µ Saiga)
> 2.1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è: Python, CUDA, –¥—Ä–∞–π–≤–µ—Ä—ã, PyTorch
> 2.2. –°–±–æ—Ä–∫–∞ –≤–∏—Ä—Ç—É–∞–ª–∫–∏ –∏–ª–∏ host-—Å—Ä–µ–¥—ã (Ubuntu / WSL2)
> 2.3. –ó–∞–ø—É—Å–∫ Saiga —á–µ—Ä–µ–∑ oobabooga / text-generation-webui
> 2.4. RAG: –∫–∞–∫ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –ø–∞–º—è—Ç—å (txt, md, jsonl, ChromaDB)
> 2.5. Docker: –ø–æ–ª–Ω–∞—è —Å–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å –º–æ–¥–µ–ª—å—é –∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–º
> 2.6. GPU-–Ω–∞—Å—Ç—Ä–æ–π–∫–∏: VRAM, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å, quantization, batch size
<!-- UID: 33df0f51-a6bb-45ac-bdb1-d25f959c3621 -->




>[!nexus_agent] **Assistant** - 27.05.2025 at 11:11
> –í–æ—Ç **—É–≥–ª—É–±–ª—ë–Ω–Ω–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–≤–µ—Ä—Ç–∫–∞ –º–æ–¥—É–ª—è II: "–ë–ê–ó–ê. –õ–û–ö–ê–õ–¨–ù–´–ô –ó–ê–ü–£–°–ö –ú–û–î–ï–õ–ò (–Ω–∞ –ø—Ä–∏–º–µ—Ä–µ Saiga)"**. 
> –¶–µ–ª—å ‚Äî –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∫–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç –≤ **—Ä–µ–∞–ª—å–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç –∫ –∑–∞–ø—É—Å–∫—É AGI**, —Å –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–æ–π, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º–∏ –∑–æ–Ω–∞–º–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞.
> 
> ---
> 
> ## üß± II. –ë–ê–ó–ê. –õ–û–ö–ê–õ–¨–ù–´–ô –ó–ê–ü–£–°–ö –ú–û–î–ï–õ–ò (–ù–ê –ü–†–ò–ú–ï–†–ï SAIGA)
> 
> ---
> 
> ### üîß **2.1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è: Python, CUDA, –¥—Ä–∞–π–≤–µ—Ä—ã, PyTorch**
> 
> #### 2.1.1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ 3.10.x)
> - `pyenv`, `conda` –∏–ª–∏ —Å–∏—Å—Ç–µ–º–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞
> - –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è: `python -m venv venv`
> 
> #### 2.1.2. –î—Ä–∞–π–≤–µ—Ä—ã –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã
> - AMD (–¥–ª—è ROCm, –º–µ–Ω–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞)
> - NVIDIA (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: >= 530.xx)
> - –ü—Ä–æ–≤–µ—Ä–∫–∞: `nvidia-smi`
> 
> #### 2.1.3. CUDA + cuDNN (NVIDIA)
> - –í–µ—Ä—Å–∏—è –¥–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å PyTorch
> - –ò–Ω—Å—Ç–∞–ª–ª—è—Ü–∏—è —á–µ—Ä–µ–∑ `.run` –∏–ª–∏ `.deb` –ø–∞–∫–µ—Ç—ã
> - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤—è–∑–∫–∏: `nvcc --version`, `torch.cuda.is_available()`
> 
> #### 2.1.4. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA
> - –ö–æ–º–∞–Ω–¥–∞ —Å —Å–∞–π—Ç–∞ https://pytorch.org/get-started/locally/
> - –ü—Ä–∏–º–µ—Ä:
>  ```bash
>  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
>  ```
> 
> #### 2.1.5. –ü—Ä–æ–≤–µ—Ä–∫–∞: "–ú–æ–¥–µ–ª—å –≤–∏–¥–∏—Ç GPU"
> ```python
> import torch 
> print(torch.cuda.get_device_name(0))
> ```
> 
> ---
> 
> ### üñ• **2.2. –°–±–æ—Ä–∫–∞ –≤–∏—Ä—Ç—É–∞–ª–∫–∏ –∏–ª–∏ host-—Å—Ä–µ–¥—ã (Ubuntu / WSL2)**
> 
> #### 2.2.1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ubuntu (22.04 LTS —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
> - –ü—Ä—è–º–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–ª–∏ –≤ VirtualBox / Proxmox
> 
> #### 2.2.2. WSL2 (–µ—Å–ª–∏ –Ω–∞ Windows)
> - –£—Å—Ç–∞–Ω–æ–≤–∫–∞: `wsl --install`
> - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ubuntu –∏–∑ Microsoft Store
> - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–æ–π (—Ç–æ–ª—å–∫–æ —Å Windows 11 + WSLg)
> 
> #### 2.2.3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, sudo, ssh
> 
> #### 2.2.4. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∞–∑–æ–≤—ã—Ö –ø–∞–∫–µ—Ç–æ–≤:
> ```bash
> sudo apt update && sudo apt install build-essential git curl unzip wget
> ```
> 
> ---
> 
> ### ‚öôÔ∏è **2.3. –ó–∞–ø—É—Å–∫ Saiga —á–µ—Ä–µ–∑ oobabooga / text-generation-webui**
> 
> #### 2.3.1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:
> ```bash
> git clone https://github.com/oobabooga/text-generation-webui.git
> cd text-generation-webui
> ```
> 
> #### 2.3.2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:
> ```bash
> pip install -r requirements.txt
> ```
> 
> #### 2.3.3. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Saiga:
> - –ú–µ—Å—Ç–æ: HuggingFace ‚Üí –º–æ–¥–µ–ª—å Saiga 13B
> - –ü—Ä–∏–º–µ—Ä:
> ```bash
> python download-model.py Saiga/Saiga-13B
> ```
> 
> #### 2.3.4. –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞:
> ```bash
> python server.py --model Saiga-13B
> ```
> 
> #### 2.3.5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ localhost: 
> ‚Üí http://127.0.0.1:7860/
> 
> ---
> 
> ### üß† **2.4. RAG: –∫–∞–∫ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –ø–∞–º—è—Ç—å (txt, md, jsonl, ChromaDB)**
> 
> #### 2.4.1. –ß—Ç–æ —Ç–∞–∫–æ–µ RAG (Retrieval Augmented Generation)
> - –ú–æ–¥–µ–ª—å —á–∏—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π.
> 
> #### 2.4.2. –ü—Ä–æ—Å—Ç–∞—è –ø–∞–º—è—Ç—å:
> - `documents/` —Å `.txt` –∏–ª–∏ `.md` —Ñ–∞–π–ª–∞–º–∏
> - –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ `extensions/memory/`
> 
> #### 2.4.3. ChromaDB (–≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞):
> - –£—Å—Ç–∞–Ω–æ–≤–∫–∞: `pip install chromadb`
> - –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤: 
> ```python
> from chromadb import Client
> client.add_documents(documents=["text1", "text2"], ids=["1", "2"])
> ```
> 
> #### 2.4.4. JSONL —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏:
> ```json
> {"id": "node1", "text": "–Ø–¥—Ä–æ AGI –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ..."}
> ```
> 
> #### 2.4.5. –†–∞—Å—à–∏—Ä–µ–Ω–∏—è oobabooga:
> - `textfile-memory`, `qdrant`, `chromadb`, `rag-enhancer`
> 
> ---
> 
> ### üê≥ **2.5. Docker: –ø–æ–ª–Ω–∞—è —Å–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å –º–æ–¥–µ–ª—å—é –∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–º**
> 
> #### 2.5.1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Docker + NVIDIA –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–Ω–æ–≥–æ —Ä–∞–Ω—Ç–∞–π–º–∞
> - Ubuntu:
> ```bash
> sudo apt install docker.io
> sudo systemctl enable docker
> ```
> 
> #### 2.5.2. Dockerfile –¥–ª—è AGI:
> ```Dockerfile
> FROM pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime
> RUN apt update && apt install -y git
> WORKDIR /app
> RUN git clone https://github.com/oobabooga/text-generation-webui.git .
> RUN pip install -r requirements.txt
> CMD ["python", "server.py", "--model", "Saiga-13B"]
> ```
> 
> #### 2.5.3. –°–±–æ—Ä–∫–∞ –∏ –∑–∞–ø—É—Å–∫:
> ```bash
> docker build -t agi-launcher .
> docker run --gpus all -p 7860:7860 -v $(pwd)/models:/app/models agi-launcher
> ```
> 
> #### 2.5.4. Volume –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤, –ø–∞–º—è—Ç–∏, —Å–æ—Å—Ç–æ—è–Ω–∏—è:
> - `./memory ‚Üí /app/memory`
> - `./logs ‚Üí /app/logs`
> 
> ---
> 
> ### üéÆ **2.6. GPU-–Ω–∞—Å—Ç—Ä–æ–π–∫–∏: VRAM, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å, quantization, batch size**
> 
> #### 2.6.1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–∞ VRAM:
> ```bash
> nvidia-smi
> ```
> 
> #### 2.6.2. Quantization (—Å–Ω–∏–∂–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ VRAM)
> - FP16 ‚Üí Int8 (—Å –ø–æ–º–æ—â—å—é GPTQ –∏–ª–∏ AutoGPTQ)
> - –í–∫–ª—é—á–µ–Ω–∏–µ: `--load-in-8bit`, `--wbits 4`
> 
> #### 2.6.3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ batch size:
> - –°–∏–ª—å–Ω–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –ø–∞–º—è—Ç—å, latency
> - –ü—Ä–∏–º–µ—Ä: `--batch_size 1 --ctx 2048`
> 
> #### 2.6.4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∂–µ–ª–µ–∑—É:
> - 13B –º–æ–¥–µ–ª—å ‚Üí –º–∏–Ω–∏–º—É–º 24 –ì–ë VRAM, –Ω–æ –≤–æ–∑–º–æ–∂–µ–Ω –∑–∞–ø—É—Å–∫ –≤ 16 –ì–ë –≤ 4-bit
> - –î–ª—è 65B –∏ –≤—ã—à–µ ‚Üí 2x GPU —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π NVLink –∏–ª–∏ CPU-only inference
> 
> ---
> 
> ## ‚úÖ –ì–æ—Ç–æ–≤–æ
> 
> –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –≤—ã–±–µ—Ä–∏, –∫–∞–∫–æ–π –∏–∑ –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤ (`2.1.1`, `2.4.3` –∏–ª–∏ `2.5.4` –∏ —Ç.–¥.) 
> **—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å –≤ —É—á–µ–±–Ω—ã–π –º–æ–¥—É–ª—å** (—Å –ø–æ—è—Å–Ω–µ–Ω–∏–µ–º, –∫–æ–º–∞–Ω–¥–∞–º–∏, –ø—Ä–∏–º–µ—Ä–∞–º–∏ –æ—à–∏–±–æ–∫ –∏ —Ñ–∏–ª–æ—Å–æ—Ñ–∏–µ–π).
<!-- UID: 1de60f88-c73a-4b45-894a-37103e50102f -->