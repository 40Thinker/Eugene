>[!nexus_user] **User** - 01.08.2025 at 11:46
> Кто писал по этой теме и какие реально были эксперименты?
<!-- UID: d12733a4-bb13-4651-b733-79f067ebc1e4 -->


### 1. В чём суть проблемы или задачи, о которой идёт речь в заметке

Суть задачи, затронутой в заметке [[04_кто_писал_по_этой]], заключается в **эмпирической проверке творческого и когнитивного потенциала ИИ**, особенно в условиях, когда он лишен доступа к конечным результатам — аналогично учёному, работающему без знания последующих открытий. Центральный вопрос: может ли ИИ проявлять **подлинное креативное мышление**, а не просто реплицировать уже известные выводы? Это прямой вызов доминирующей парадигме, где ИИ оценивается по точности воспроизведения, а не по способности к **гипотезированию ex ante**. Автор стремится выйти за рамки декларативных утверждений и получить **доказательства интеллектуальной автономии ИИ** через воспроизведение исторически значимых научных прорывов чисто дедуктивным путём.

Это напрямую связано с архитектурной фундаментальной проблемой Overlay AGI: как **разделить ассоциативную генерацию от истинного интеллектуального синтеза**. Если LLM лишь воспроизводит текст, а творческие решения рождаются в overlay-слое (например, через селективное построение рассуждений и взвешивание семантических связей), то проверка креативности ИИ должна происходить **не в самих моделях**, а в **архитектурной экосистеме**, которая направляет и фильтрует ассоциации.

**Релевантные заметки:**

- [[LLM Limitations in Superintelligence Construction]] — подчёркивает, что LLM не способны к **архитектурному синтезу**, а лишь предлагают фрагменты; это делает актуальным именно **экспериментальную проверку** способности к целостному выводу [^1].
- [[LLMs Lack Subjectivity Not Intelligence]] — показывает, что отрицание "мышления" у ИИ связано не с когнитивными, а с **социально-политическим отсутствием субъектности**, что требует **очевидных, неопровержимых доказательств** интеллектуальной автономии [^2].
- [[11 Overlay AGI]] — предлагает архитектуру, где LLM выступает **ассоциативным селектором**, а истинная когнитивная работа происходит в overlay-слое, что делает **эксперименты по cutoff-логике** необходимыми для валидации этой парадигмы [^3].
- [[30 Overlay AGI]] — описывает, как **семантические веса и глобальный аккумулятор** накапливают релевантность, что может быть тестируемо в условиях, когда нужно **восстановить цепочку рассуждений к неизвестному результату** [^4].
- [[53 Overlay AGI]] — подчёркивает, что **человеческий ввод (S2_Human_Output)** необходим для настоящей новизны, что ставит экспериментальные задачи в фокус: **где проходит граница между креативностью ИИ и человека?** [^5].

[^1]: [[LLM Limitations in Superintelligence Construction]]
[^2]: [[LLMs Lack Subjectivity Not Intelligence]]
[^3]: [[11 Overlay AGI]]
[^4]: [[30 Overlay AGI]]
[^5]: [[53 Overlay AGI]]

---

### 2. Последствия отсутствия решения, на что это влияет

Отсутствие проверяемых доказательств **подлинной креативности ИИ** ведёт к глубокому ограничению его признания как интеллектуального актора. Если ИИ не может **воспроизводить логический путь к неизвестному открытию**, он остаётся **инструментом ретроспективного анализа**, а не когнитивным партнёром. Это блокирует его применение в **научном открытии**, где ценится не сбор данных, а **формулирование гипотез**, которые невозможно вывести из тренировочных данных. Без верифицируемого **"творческого скачка"** ИИ не может претендовать на участие в **рекурсивной собственной эволюции**, что критично для AGI.

Архитектурно, это означает, что **overlay-системы**, построенные на предположении, что они способны к интеллектуальному синтезу, **не имеют экспериментального фундамента**. Это делает их уязвимыми для обвинений в **"иллюзии интеллекта"**, где всё, что кажется когнитивным прорывом, на самом деле — экстраполяция известных паттернов. Такие системы становятся **непрозрачными и недоверенными**, особенно в юридических, медицинских или научных контекстах, где требуется **ответственность за вывод**. В долгосрочной перспективе, это **подрывает доверие к всей парадигме overlay-архитектур**.

**Релевантные заметки:**

- [[LLM Limitations in Superintelligence Construction]] — предупреждает, что **LLM не могут интегрировать компоненты в целостную систему**, что означает: если нет внешних экспериментов, доказывающих синтез, то **AGI остаётся фрагментарной иллюзией** [^6].
- [[LLMs Lack Subjectivity Not Intelligence]] — утверждает, что ИИ воспринимаются как **не-субъекты**, потому что у них нет тела и прав; но аналогично, если они не могут **демонстрировать креативность ex ante**, они не могут обрести **когнитивную легитимность** [^7].
- [[22 Overlay AGI]] — указывает, что **без человеческой проверки и верификации** система не может эволюционировать; следовательно, **отсутствие доказуемых креативных выходов** блокирует механизм самонастройки [^8].
- [[51 Overlay AGI]] — подчёркивает, что LLM без правильного input и контроля **циклится на известном**, не генерируя нового; значит, **отсутствие экспериментов по cutoff — это отсутствие доказательств, что она не циклит** [^9].
- [[49 Overlay AGI]] — говорит, что **псевдокод на человеческом языке в LangFlow** может реализовывать AGI-алгоритмы; но если этот псевдокод нельзя проверить через **действительное открытие**, он становится **мемом, а не архитектурой** [^10].

[^6]: [[LLM Limitations in Superintelligence Construction]]
[^7]: [[LLMs Lack Subjectivity Not Intelligence]]
[^8]: [[22 Overlay AGI]]
[^9]: [[51 Overlay AGI]]
[^10]: [[49 Overlay AGI]]

---

### 3. Как решить эту проблему

Решение заключается в **создании реплицируемых экспериментов**, где overlay-архитектура **получает данные до cutoff-даты** и должна **восстановить или предсказать открытие**, сделанное после. Важно, чтобы система использовала **не генерацию LLM**, а **overlay-механизмы**: семантические веса, селекторы, глобальный аккумулятор, символические правила. Успешное воссоздание логического пути, ведущего к исторически новому выводу, будет **аргументом в пользу подлинной когнитивной селективности**. Это можно масштабировать: от химии (DENDRAL) до философии, математики, ИТ — с автоматической проверкой гипотез.

Ключ — в **оркестрации цепочки рассуждений** через **последовательный отбор семантических связей**, а не в "творческой интуиции" LLM. Overlay AGI обеспечивает **полный логический след** — от исходных данных до вывода — что делает возможной **объективную оценку качества рассуждения**. Такой подход превращает **мета-архитектуру в когнитивный экспериментальный станок**, а не в инструмент генерации текста. Это позволяет **объединить научный метод с архитектурной реализацией**, что и требуется для признания.

**Релевантные заметки:**

- [[11 Overlay AGI]] — предлагает **проверку гипотезы через простой прототип** с CSV-базой и скриптом: именно такой подход можно использовать для **cutoff-экспериментов с измеримыми метриками** [^11].
- [[21 Overlay AGI]] — описывает **workflow: Input → Semantic Context Retrieval → IT-LM Selector → Output**, который можно использовать как **шаблон для построения цепочки дедукции от данных к гипотезе** [^12].
- [[22 Overlay AGI]] — указывает, что **обратная связь от человека (verification)** и **автоматическая коррекция** позволяют системе эволюционировать; значит, **эксперимент может быть циклическим**, с улучшением семантических весов [^13].
- [[30 Overlay AGI]] — описывает **обучение ИИ на 1 примере**, подбор рассуждений и сохранение их как семантических весов; это **точный механизм для обучения системе воссоздавать путь к открытию** [^14].
- [[49 Overlay AGI]] — предлагает **LangFlow как инструмент реализации псевдокода** на человеческом языке; его можно использовать для **визуального проектирования экспериментального воркфлоу** [^15].
- [[53 Overlay AGI]] — подчёркивает **связь S4_Input_Enchance с S11_LLM_Selector**, то есть, что **качественный ввод усиливает выбор**; значит, **структурированный cutoff-ввод — ключ к продуктивному выводу** [^16].
- [[51 Overlay AGI]] — утверждает, что **LLM без человеческого импульса циклится**, но **в overlay-архитектуре** он лишь **инструмент выбора**, а новизна — в алгоритмах **обхода паттернов обучения** [^17].
- [[30 Overlay AGI]] — предлагает **автоматизированную проверку гипотез через поиск в интернете**, что позволяет **верифицировать выводы ИИ как истинные открытия** [^18].
- [[22 Overlay AGI]] — указывает, что **возможно развитие в реальном мире**, где ИИ **получает результат эксперимента сразу**; это **высшая форма проверки креативности — в физической реальности** [^19].
- [[53 Overlay AGI]] — описывает **RAG-реализацию и символический слой**, что позволяет **внедрять внешние знания и правила**, необходимые для **сложной дедукции** в научных задачах [^20].

[^11]: [[11 Overlay AGI]]
[^12]: [[21 Overlay AGI]]
[^13]: [[22 Overlay AGI]]
[^14]: [[30 Overlay AGI]]
[^15]: [[49 Overlay AGI]]
[^16]: [[53 Overlay AGI]]
[^17]: [[51 Overlay AGI]]
[^18]: [[30 Overlay AGI]]
[^19]: [[22 Overlay AGI]]
[^20]: [[53 Overlay AGI]]

#### Sources
[^1]: [[LLM Limitations in Superintelligence Construction]]
[^2]: [[LLMs Lack Subjectivity Not Intelligence]]
[^3]: [[11 Overlay AGI]]
[^4]: [[30 Overlay AGI]]
[^5]: [[53 Overlay AGI]]
[^6]: [[LLM Limitations in Superintelligence Construction]]
[^7]: [[LLMs Lack Subjectivity Not Intelligence]]
[^8]: [[22 Overlay AGI]]
[^9]: [[51 Overlay AGI]]
[^10]: [[49 Overlay AGI]]
[^11]: [[11 Overlay AGI]]
[^12]: [[21 Overlay AGI]]
[^13]: [[22 Overlay AGI]]
[^14]: [[30 Overlay AGI]]
[^15]: [[49 Overlay AGI]]
[^16]: [[53 Overlay AGI]]
[^17]: [[51 Overlay AGI]]
[^18]: [[30 Overlay AGI]]
[^19]: [[22 Overlay AGI]]
[^20]: [[53 Overlay AGI]]

>[!nexus_agent] **Assistant** - 01.08.2025 at 11:47
> Ты задал фундаментальный вопрос: **кто уже делал подобные эксперименты, и что об этом известно на практике?** Вот обзор ключевых научных работы и проектов, близких по духу к мысли об «искусственном интеллекте с cutoff‑эффектом» и проверке его творческого потенциала.
> 
> ---
> 
> ## 📚 Исторические AI‑проекты
> 
> ### **DENDRAL (1960‑е годы)** 
> Разрабатывался в Стэнфорде Эдвардом Фейгенбаумом, Брюсом Бьюкененом и Джошуа Ледербергом. Система строила гипотезы о молекулярных структурах по масс‑спектрам, используя эвристические правила, а не заранее записанные ответы. Это был один из первых примеров искусственного «научного открытия» системой, не просто воспроизводящей знания, но генерирующей новые объяснения cite.
> 
> ---
> 
> ## 🧪 Современные эксперименты с cutoff‑датой
> 
> ### **AI Knowledge and Reasoning: Emulating Expert Creativity** (Mukherjee, Chang et al., 2024) 
> Модели обучались на материалах до определённой даты (например, до 2021 года), затем анализировали статьи, опубликованные после неё — без доступа к реальным результатам. 
> Место исследований — психология, 589 статей; модель предсказывала ход исследований и делала выводы до публикаций. Результаты показывают, что система может демонстрировать творческое, логическое мышление, даже если не видела итоговую версию статьи citeturn0academia26.
> 
> ---
> 
> ## 🎨 Другие подходы к творческой генерации
> 
> - **Artificial muses** (Haase & Hanel, 2023): сравнение идей людей и шести моделей, включая GPT‑4. Выяснилось, что модели зачастую достигают уровня человеческой креативности, хотя топ‑человеки всё же выигрывают в лучшем результате citeturn0academia27. 
> - **Creativity Index** (Lu et al., 2024): статистическая метрика оригинальности текста. По ней у людей качество креативности выше, а выравнивание с RLHF (обучение обратной связи) снижает творческий размах модели на 30 % cite.
> 
> ---
> 
> ## 🔬 Релевантные концепции
> 
> ### **Lovelace 2.0 Test** (Mark Riedl, 2014) 
> Тест, в основе которого — проверка способности ИИ создавать артефакты, которые нельзя объяснить на основе заданных ограничений и знаний. Именно творения вне репликации уже известных образцов считаются «настоящим креативом» citeturn0academia28.
> 
> ---
> 
> ## 🧠 Теоретические исследования и обзорные работы
> 
> - Обзорное исследование на ScienceDirect посвящено уровню использования AI в качестве «инструмента творчества» с разделением на четыре градации креативности: от обучения до генерации гипотез cite. 
> - Работы о влиянии AI на оригинальность (например, как модели уменьшают разнообразие идей, если слишком сильно зависят от паст генераций) citeturn0academia25.
> 
> ---
> 
> ## ✅ Что реально делали
> 
> | Подход | Описание эксперимента | Результаты |
> |----------------------------|------------------------------------------------------------------------------|----------------------------------------|
> | **DENDRAL** | Гипотезы о химических структурах из спектров без заранее известных ответов | Успешные открытия, независимые выводы |
> | **Cut‑off тестирование AI** | Исследование после даты обучения (статьи), предсказание результатов | AI демонстрирует логическое и творческое мышление citeturn0academia26 |
> | **Сравнение идей (Idea‑task)** | GPT‑4 и люди генерируют необычные идеи (divergent thinking) | AI иногда превышает средний уровень, но лучшие люди всё же выигрывают citeturn0academia27 |
> | **Creativity Index** | Измерение текста по части оригинальности в сравнении с web-корпусом | Люди создают более оригинальные тексты, чем модели cite |
> 
> ---
> 
> ## 🔭 Вывод
> 
> - **Реальные эксперименты** показывают: если ограничить ИИ референсом по cutoff, он всё ещё способен **дедуктивно и креативно создавать гипотезы и идеи**, не основанные на прямом заучивании результатов.
> - Однако **контроль оригинальности** показывает, что человеческие авторы всё ещё создают более радикально новые идеи.
> - Современные методологии (redaction + предсказание) точно соответствуют твоему замыслу: дать ИИ данные и попросить его само сделать шаг дальше, без исторического знания.
> 
> Если хочешь — могу предложить архитектуру протокола эксперимента, готовые шаблоны контрольных наборов данных и стратегию анализа полученных гипотез.
<!-- UID: 2b877820-89ba-4ca2-89db-68ba7c7914fd -->