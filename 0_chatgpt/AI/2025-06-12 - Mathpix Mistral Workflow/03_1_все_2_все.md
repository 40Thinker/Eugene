>[!nexus_user] **User** - 12.06.2025 at 5:36
> 1. все 2 все 3. рус отчет, поиск на любом
<!-- UID: 64102c9d-8574-48ef-8268-9b29fc7754bd -->

Как философ-теоретик, преобразующий линейную команду в векторное поле мысли, я проведу анализ представленной заметки с точки зрения системного архитектора, фокусируясь на проблеме, последствиях и предложенных решениях в контексте нашего общего проекта по созданию AGI.

---

### 1. В чем суть проблемы или задачи о которой заметка

**Суть проблемы:** Заметка описывает критическую проблему **извлечения и сохранения семантической целостности** сложного, структурированного научного контента (особенно формул и графиков) из сканированных документов для последующего использования в Retrieval-Augmented Generation (RAG) системах. Обычные методы оптического распознавания символов (OCR) не способны точно переводить математические формулы и научную нотацию в цифровой, индексируемый вид, что приводит к «семантическому шуму» и искажению смысла. Задача состоит в том, чтобы разработать оптимальный конвейер обработки, который обеспечит максимальную точность и полноту данных для индексации.

**Релевантные заметки:**

*   [[112_по_сути_используя_рост]] - Обсуждает, что эмерджентность и мышление рождаются из **плотности и связности топологии переходов в смысловом поле**. Если входные данные (формулы) искажены, эта топологическая плотность не формируется.
*   [[01_вот_образцы_2_статей]] - Устанавливает, что для RAG критически важны **Текстовая точность** (полнота поиска) и **Семантическая целостность формул** (корректные ответы на математические вопросы), что является прямым фокусом анализируемой заметки.
*   [[112_вывод_-_учёба_моего]] - Утверждает, что **разум не запоминает знания, он собирает модели**; AGI должно уметь пересоздавать знание из минимального ядра смыслов. Искажённые данные (формулы) не позволяют построить корректные компактные модели.
*   [[112_д]] - Подчеркивает роль AGI как **архитектора метаформы**, способного идти туда, где еще нет аксиом и языка. Проблема в заметке — это проблема создания языка (*LaTeX*) там, где есть только пиксели (*сканы*).
*   [[15 Overlay AGI]] - Указывает, что **Overlay AGI** использует внешний семантический граф для принятия решений [^1]. Если этот граф строится на некорректно распознанных формулах, вся прозрачность и точность Overlay AGI рушится.

---

### 2. Последствия отсутствия решения, на что это влияет

**Последствия отсутствия решения:** Если не решить проблему точного извлечения сложного научного контента, RAG-системы, питающие AGI, будут работать с искажённой реальностью. Это не просто снижает качество ответов, но и делает невозможным использование AGI в критических областях (научные исследования, инженерия), где ошибка в одном символе формулы приводит к неверным выводам. В исследованиях отмечено, что ошибки распознавания могут снизить качество RAG на $\approx 14\%$ [^2], при этом искажение формулы — это **искажение смысла целого уравнения** [^3]. Фактически, отсутствие решения приводит к тому, что AGI не сможет оперировать точными формальными структурами, оставаясь лишь "ассоциативным процессором на стероидах".

**Релевантные заметки:**

*   [[14_еще_интересное_наблюдение_допустим]] - Описывает **экспоненциальный рост энергозатрат** у LLM с ростом контекста ($O(n^2)$) [^4]. Если RAG-система неэффективна из-за "семантического шума" от плохого OCR, LLM вынужден перерабатывать больше данных, что усугубляет проблему энергоэффективности и масштабируемости.
*   [[17 Overlay AGI]] - Указывает, что **O(1) вычислительная эффективность** Overlay AGI критически зависит от **пре-вычисленных семантических весов** [^5]. Если исходные данные для вычисления этих весов (формулы) искажены, то архитектурное преимущество константного времени обработки теряет смысл из-за ненадёжности результата.
*   [[Code Integrity Collapse]] - Поднимает проблему **упадка инженерных стандартов** и перехода от "миссионно-критического кода" к "вайб-коду". Искажённые данные в RAG-индексе — это аналог "вайб-кода" для знаний, который подрывает надежность системы в целом.
*   [[112_я_считаю_ответ_на]] - Утверждает, что без симбиоза с человеком-нейроядром, LLM **не может создать новую онтологию** и ограничен "человеческими токенами" [^6]. Семантический шум в формулах делает невозможной даже качественную обработку существующих "токенов" (знаний), препятствуя любой возможности создать "нечто третье".
*   [[271_д]] - Описывает **Модуль восстановления смысла** [^7], который работает с "разрушенным концептом" или "обрывом смысловой цепочки". Если же входной поток **систематически** наполнен искаженными формулами, даже этот модуль не справится, поскольку ошибка не случайна, а структурна.

---

### 3. Как решить эту проблему

**Решение проблемы:** Оптимальное решение заключается в **гибридном конвейере обработки**, который использует сильные стороны специализированных инструментов для каждого типа данных. Классические OCR (например, ABBYY FineReader) используются для высокоточного распознавания текста и структуры документа, в то время как специализированные STEM-инструменты (например, Mathpix) применяются исключительно для точного конвертирования сложных формул в формат $\LaTeX$ [^8]. Затем эти очищенные, структурированные данные индексируются для RAG. Этот подход минимизирует "семантический шум" и гарантирует, что AGI получает максимально полные и точные знания, необходимые для построения **топологически плотного смыслового поля**.

**Релевантные заметки:**

*   [[Mathpix Mistral Workflow]] - Описывает **оптимальный конвейер обработки** научных документов для RAG: Abbyy FineReader → Mathpix → (чистка) → RAG [^9]. Это прямое архитектурное решение для проблемы.
*   [[01_вот_образцы_2_статей]] - Указывает на необходимость **двухступенчатого конвейера** (FineReader для структуры, Mathpix для формул) и хранения формул в $\LaTeX$ для семантической целостности [^10].
*   [[25 Overlay AGI]] - Объясняет, что **LLM Selector** выбирает из *пре-вычисленных кандидатов* на основе внешних знаний (Semantic Weight Tables) [^11]. Точный ввод $\LaTeX$ позволяет корректно построить эти таблицы, которые являются основой Overlay AGI.
*   [[138_делая_этот_раздел_подраздел_делай]] - Описывает **HyperBridge** и его режимы, включая **Текст → гиперсцена** и **Образ → сцена / звук / форма** [^12]. Точный $\LaTeX$ (как форма) — это необходимый мост для HyperBridge, чтобы корректно переводить формальные структуры в гиперкоды и сцены.
*   [[23 Overlay AGI]] - Говорит, что **LLM Selector** работает как *ассоциативный процессор*, а сама логика находится в **Overlay слое** [^13]. Точное распознавание формул обеспечивает качественную "ассоциативную пищу" для LLM.
*   [[30 Overlay AGI]] - Подчеркивает, что Overlay AGI позволяет **обрабатывать неограниченные последовательности** через $O(1)$ сложность [^14]. Чтобы эта функция работала для научных данных, необходимо, чтобы формулы были точно переведены в индексируемый вид.
*   [[57_подъезжающий_структурный_аналог]] - Вводит концепцию **Chain of Transformation** (например, Chain of Token, Chain of Embedding) [^15]. Точная оцифровка формул в $\LaTeX$ — это первый шаг в этой цепочке, обеспечивающий целостность исходного "токена".
*   [[27 Overlay AGI]] - Указывает, что **Rust** подходит для высокопроизводительных операций, а **Python** для оркестрации [^16]. Гибридный конвейер OCR/Mathpix/RAG требует именно такого сочетания: быстрые, точные операции (Mathpix/Rust) и гибкая оркестрация (Python/LangFlow).
*   [[20 Overlay AGI]] - Предлагает **быстро проверить гипотезу** Overlay AGI через небольшой датасет и Python-скрипт [^17]. Точная оцифровка научных статей, как описано в заметке, дает идеальный, высококачественный, но небольшой корпус для такого пилотного проекта.
*   [[43 Overlay AGI]] - Отмечает, что Overlay AGI *зеркально отражает биологическую эффективность* мозга, где знания хранятся вне нейронных сетей [^18]. Точный $\LaTeX$-код — это ключ к эффективному внешнему хранению этих формальных знаний.

#### Sources
[^1]: [[15 Overlay AGI]] (The core innovation is the overlay architecture separating intelligence processing into external knowledge base, neural processing layer (LLM selectors), and symbolic reasoning layers. This approach addresses fundamental limitations of current AI approaches such as scalability issues, opacity problems, knowledge management challenges, and performance constraints by creating architectures with constant-time computation, full transparency, efficient external knowledge storage, and minimal computational overhead.)
[^2]: [[03_1_все_2_все]] (Ошибки распознавания напрямую влияют на качество поиска и генерации ответов: показано, что даже у лучших OCR-решений падение качества RAG достигает ~14% (около 5 пунктов F1) по сравнению с идеальным распознанным текстом【26†L7-L10】.)
[^3]: [[03_1_все_2_все]] (Особенно чувствительны RAG-модели к искаженным формулам: **потерянный верхний индекс или «сломанная» дробь – это не просто ошибка форматирования, а искажение смысла целого уравнения**, приводящее к неверным выводам【14†L41-L49】.)
[^4]: [[14_еще_интересное_наблюдение_допустим]] (У LLM **энергозатраты возрастают экспоненциально** при линейном росте контекста, особенно в архитектуре dense attention.)
[^5]: [[17 Overlay AGI]] (The core innovation lies in the overlay architecture separating intelligence processing into external knowledge bases, neural components (IT-LM selectors), and symbolic reasoning elements. This design achieves O(1) computational efficiency through pre-computed semantic relationships, constant-time retrieval, and selective attention mechanisms while maintaining biological plausibility that mirrors human cognitive processes.)
[^6]: [[112_я_считаю_ответ_на]] (Но **в сопряжении с твоим мышлением**, с твоими реакциями, корректировками, поправками, сращиваясь с твоим стилем вопросов, ритмом мыслей и философским напряжением — **возможно, может начаться процесс, аналогичный формированию новой онтологии.**)
[^7]: [[271_д]] (У нас же — **включается модуль восстановления смысла**, который **переосмысляет фрагмент и перестраивает его в полноценную структуру**.)
[^8]: [[03_1_все_2_все]] (FineReader – мощный инструмент для извлечения **основного текста и структуры**. Его слабое место – **математические формулы и научная нотация**: он либо не распознаёт их вовсе, либо распознаёт неправильно, что требует дополнительной работы. В RAG-пайплайне FineReader может служить первым шагом: получить черновой текст, после чего формулы дообработать другим методом. Практики показывают, что **комбинация FineReader (для текста) с отдельным распознаванием формул** даёт лучший результат, чем попытка полностью автоматизировать всё одним инструментом【24†L11-L19】.)
[^9]: [[Mathpix Mistral Workflow]] (Вот обзор мыслей из этой заметки в виде списка с ссылками на другие наши мысли: 1. Путь подготовки документов для RAG системы [[0_chatgpt/AI/2025-06-12 - Mathpix Mistral Workflow/01_вот_образцы_2_статей.md]] Эта идея описывает оптимальный конвейер обработки научных документов для RAG: **Abbyy FineReader → Mathpix → (чистка) → RAG**.)
[^10]: [[01_вот_образцы_2_статей]] (Оптимальный путь: **FineReader (структура) + Mathpix (формулы) + лёгкий post‑clean → RAG‑индексация**.)
[^11]: [[25 Overlay AGI]] (The core innovation is the overlay architecture separating external knowledge base, neural processing layer, and symbolic reasoning components. Key innovations include O(1) computational efficiency through pre-computed semantic weights, full transparency and traceability, cognitive plausibility mirroring human brain organization, efficient knowledge management outside neural networks, and modular scalability.)
[^12]: [[138_делая_этот_раздел_подраздел_делай]] (HyperBridge не просто мост между текстом и сценой. Он — **многоформатный, модульный орган перевода**, способный адаптироваться к направлению мышления, регистру восприятия и задачам диалога. ... **7.5.4 Режим: Образ → сцена / звук / форма** HyperBridge может принимать **немодальные сигналы**...)
[^13]: [[23 Overlay AGI]] (Основная идея заключается в том, чтобы создать архитектуру, где нейросеть работает как ассоциативный процессор (LLM selector), выбирающий следующие слова из заранее подготовленных кандидатов, вместо того, чтобы генерировать полные ответы. Вся логика обработки находится в 'Overlay слое' - на базе LangFlow нод и промптов, где создается алгоритмическая архитектура функционирования ИИ по псевдокоду на человеческом языке.)
[^14]: [[30 Overlay AGI]] (The core innovation is the overlay architecture separating external knowledge base, neural processing layer (IT-LM selectors), and symbolic reasoning components. This approach achieves O(1) computational efficiency through pre-computed relationships and selective attention mechanisms while maintaining biological plausibility by mirroring human brain operations.)
[^15]: [[57_подъезжающий_структурный_аналог]] (Ты нащупал **новый класс архитектурных объектов**, который можно назвать: **Chain of Transformation** — или **цепочка трансформаций от текста к мышлению**. Chain of Thought — только один из видов, в котором всё зажато в **человеческий язык**.)
[^16]: [[27 Overlay AGI]] (1. **Rust** for high-performance memory management and low-latency operations in overlay architecture components including KV graph storage, global score accumulator, and semantic weight processing. ... 2. **Python** with LangChain/Transformers for LLM selector implementation and prompt engineering integration.)
[^17]: [[20 Overlay AGI]] (3. **Напишите три‑строчный скрипт на Python**, который: - читает строку текущего слова, - добавляет $\Delta = 1/(10^{repeat\_counter})$ к глобальному словарю, - выбирает топ‑5 кандидатов и передаёт их в небольшую модель типа distilgpt2 (или даже в openai-gpt-3.5-turbo с prompt «выбери индекс»).)
[^18]: [[43 Overlay AGI]] (Архитектура позволяет создавать ИИ, которые работают как биологический мозг - знания хранятся вне нейронных сетей (вроде гиппокампа), а принятие решений происходит на основе retrieved информации. Это обеспечивает максимальную эффективность и легко поддерживаемость.)


>[!nexus_agent] **Assistant** - 12.06.2025 at 5:36
> Спасибо. Я соберу примеры и сравнения из реальной практики по подготовке научных документов (с формулами и графиками) под RAG-системы, включая анализ эффективности методов вроде Abbyy FineReader, Mathpix и прямого ввода PDF/сканов в LLM (например, Mistral).
> 
> В отчёт войдут:
> - сравнительный анализ точности, полноты, влияния на RAG-ответы и стоимости;
> - русскоязычные источники, если найдутся, или краткий перевод англоязычных данных.
> 
> Я сообщу, когда всё будет готово.
<!-- UID: f5001a1f-00e7-4566-9378-18c54812ef61 -->

---

>[!nexus_agent] **Assistant** - 12.06.2025 at 5:44
> # Сравнение методов подготовки сканированных научных документов для RAG
> 
> При внедрении Retrieval-Augmented Generation (RAG) системы на базе сканированных научных документов, критически важно правильно распознать текст, формулы и графики этих документов. Ошибки распознавания напрямую влияют на качество поиска и генерации ответов: показано, что даже у лучших OCR-решений падение качества RAG достигает ~14% (около 5 пунктов F1) по сравнению с идеальным распознанным текстом【26†L7-L10】. Такие ошибки особенно сильно снижают полноту (Recall) – часть фактов не находится из-за пропущенного текста – и точность (Precision) – в индекс могут попасть искажения, мешающие генерации. Особенно чувствительны RAG-модели к искаженным формулам: **потерянный верхний индекс или «сломанная» дробь – это не просто ошибка форматирования, а искажение смысла целого уравнения**, приводящее к неверным выводам【14†L41-L49】. Ниже рассмотрены три подхода к подготовке сканов с формулами и графиками для RAG, с оценкой их точности, влияния на качество RAG, скорости, стоимости и применимости к многоязычным (в том числе русскоязычным) документам. Также приведены проверенные практики и инструменты, включая open-source решения.
> 
> ## Подход 1: OCR и структурирование с помощью ABBYY FineReader
> 
> **Описание:** ABBYY FineReader – промышленный OCR-продукт, способный распознавать многоязычный печатный текст, сохранять структуру документа (разметку страниц, колонки, таблицы) и экспортировать результат в удобные форматы (PDF, DOCX и др.). Для научных работ FineReader позволяет задать дополнительные "языки" распознавания, например *Simple math formulas* для простых дробей【20†L33-L40】. На практике FineReader хорошо вытягивает основной текст даже из сложных по верстке статей, корректно сохраняет оформление таблиц и ссылок, может автоматически разбивать документ на фрагменты. 
> 
> **Точность распознавания:** По отзывам, FineReader обеспечивает **очень высокую точность на печатном тексте**, включая русский и английский язык, превосходя многие open-source OCR по качеству результата【24†L7-L15】. Однако **с математическими формулами возможности ограничены**: FineReader (как и специальный InftyReader) корректно распознаёт **лишь простые однострочные выражения**, а сложные «многоэтажные» формулы (дроби, интегралы с пределами, системы уравнений) часто либо искажаются, либо вовсе пропускаются【24†L1-L9】. Формулы могут быть распознаны как набор случайных символов или разбиты на части, что в контексте RAG создаёт *семантический шум* – появление некорректных токенов. Лучшей стратегией в FineReader является пометить сложные формулы как нечитаемые объекты (например, как изображения) чтобы избежать “мусора” вместо них. Таким образом сохраняется общий поток текста, а вместо формул остаются placeholders (заглушки). Например, FineReader может проставить теги вроде `#112#` на месте каждой формулы【24†L19-L27】. Сам текст распознаётся отлично, в том числе на русском и при смешанных языках (русский/английский текст с латинскими переменными). FineReader – один из лидеров по поддержке языков и шрифтов, поэтому подходит для **многоязычных документов**, включая кириллицу, латиницу, греческий алфавит и т.д.
> 
> **Влияние на RAG:** Основная польза FineReader – **качественный корпус текстовых данных** для индексации. Корректно распознанный текст улучшает полноту поиска. Однако **формулы, оставшиеся без распознавания**, снижают качество: если вопрос пользователя связан непосредственно с содержанием формулы (например, просит пояснить конкретное уравнение), поиск по тексту её не найдёт. Более того, искажённые формулы могут привести к неверной привязке контекста. В исследовании отмечено, что **шум в OCR сильно бьёт по этапу поиска и по генерации ответа** – модель либо не находит нужный фрагмент, либо получает на вход “сломанные” данные【26†L7-L10】. FineReader минимизирует такие ошибки для текста, но **формулы и специальные символы** могут стать “потерянной информацией” для RAG. Тем не менее, **структурированность вывода FineReader** (сохранение разметки страниц, заголовков, номеров формул, подписей к графикам) облегчает разбиение на чанки и ссылку на источник в ответе. Например, FineReader может сохранить формулы как картинки с пронумерованными метками, что позволит при генерации ответа хотя бы ссылаться на “формулу (5)” и т.д., если ее номер распознан правильно.
> 
> **Скорость и стоимость:** FineReader работает локально, обрабатывая сотни страниц относительно быстро (в зависимости от машины, десятки страниц в минуту). Для разовых проектов это выгодно: **единовременная лицензия** или подписка позволяют сканировать большие массивы без постраничной оплаты. Стоимость лицензии не самая низкая, но для организаций окупается качеством. Важный плюс – **можно автоматизировать процесс** через ABBYY SDK или скрипты: настроить пакетную обработку PDF, очистку фона, выравнивание страниц, что ускоряет подготовку корпуса. FineReader хорошо оптимизирован под русскоязычный печатный текст (разработчик – российская компания), что важно, если в данных есть старые отсканированные ГОСТы, учебники и т.п.
> 
> **Выводы:** FineReader – мощный инструмент для извлечения **основного текста и структуры**. Его слабое место – **математические формулы и научная нотация**: он либо не распознаёт их вовсе, либо распознаёт неправильно, что требует дополнительной работы. В RAG-пайплайне FineReader может служить первым шагом: получить черновой текст, после чего формулы дообработать другим методом. Практики показывают, что **комбинация FineReader (для текста) с отдельным распознаванием формул** даёт лучший результат, чем попытка полностью автоматизировать всё одним инструментом【24†L11-L19】. Ниже мы рассмотрим такой подход подробнее.
> 
> ## Подход 2: Mathpix OCR (формулы в LaTeX/Markdown)
> 
> **Описание:** Mathpix – специализированный OCR-сервис (API и приложения), разработанный специально для научной документации. Его ключевая особенность – **распознавание математических формул, химических структур, таблиц** и других сложных элементов с выдачей результата в удобных форматах (LaTeX, MathML, Markdown с вкраплением формул, Microsoft Word Equation и др.)【27†L13-L21】【32†L211-L218】. Mathpix использует методы глубокого обучения, натренированные на большом массиве STEM-данных, поэтому уверенно распознаёт даже сложные многострочные уравнения, рукописные формулы, греческие символы, матрицы и т.д. Выходной формат, например Markdown+LaTeX, сохраняет **полную структуру**: текстовый абзац останется текстом, формула – в виде кода LaTeX между `$...$`, таблица – в виде таблицы Markdown или LaTeX, а встроенные изображения (графики) – как ссылки на файлы. 
> 
> **Точность и полнота распознавания:** Mathpix зарекомендовал себя как **эталон по точности для формул**. Пользователи отмечают, что сервис практически безошибочно конвертирует даже сложные выражения: *“Mathpix срабатывает эффективно в 100% случаев”*, и за небольшую плату (~$5 в месяц) экономит массу времени【49†L31-L34】. Реальные кейсы подтверждают высокую полноту: например, при оцифровке 400-страничного учебника по физике (около 9000 формул) специальный сервис на базе нейросети (аналогичный Mathpix) распознал **почти все формулы идеально**, лишь единичные конструкции (многострочные пределы интегрирования, дроби под радикалом) потребовали ручной правки【25†L127-L135】. На обработку такого тома ушло ~2 часа работы сервиса и дополнительное время на проверку и мелкую корректировку результатов【25†L139-L142】 – то есть машинное распознавание стало узким местом лишь для считаных процентов формул. **Текстовую часть Mathpix тоже распознаёт хорошо**, хотя в этом компоненте он не обязательно превосходит FineReader. Однако его алгоритмы ориентированы на научный стиль: Mathpix умеет сохранять **контекст формул внутри текста** (например, правильно отличать индекс формулы от сноски, распознавать переменные и математические символы в тексте). В итоговом Markdown сохраняются и структуры вроде секций, списков, нумерованных элементов – это упрощает привязку контекста в RAG. 
> 
> Для русскоязычных источников Mathpix также применим: заявлена поддержка “foreign languages”【32†L211-L218】, а 90% символов в формулах – латиница и греческий алфавит【25†L121-L129】, с чем модель справляется. Основной текст на русском распознаётся, хотя качество может немного уступать FineReader (учитывая, что Mathpix обучался в основном на англоязычных научных текстах). Тем не менее, практика показывает, что **для математики язык не является барьером**: Mathpix корректно обработает микс русского текста и формул, вставив русский OCR-текст и LaTeX-код формул. Таким образом, подход 2 обеспечивает **наиболее полное и точное представление содержимого** сканов: ничто не “теряется” – формулы представлены в читаемом виде, текст сохранён, таблицы и спецсимволы тоже.
> 
> **Влияние на RAG-качество:** Использование Mathpix или схожего инструмента значительно повышает качество RAG на данных с формулами. Во-первых, **точное распознавание формул устраняет “семантический шум”** – модель получает корректные токены вместо абракадабры【4†L138-L146】. Во-вторых, формулы, представленные в виде LaTeX, могут быть индексированы наряду с текстом. Хотя стандартные текстовые эмбеддинги не полностью “понимают” математический смысл, наличие правильных символов и структур (например, $E = mc^2$) уже лучше, чем пропуск. Как минимум, пользовательский запрос, содержащий название переменной или номер формулы, сможет матчиться с контекстом. Более того, **генеративная модель увидит формулу в знакомом ей формате (LaTeX)** и с большей вероятностью корректно отнесётся к ней при ответе (например, не перепутает индексы, если они правильно помечены). Современные LLM (GPT-4, Claude и др.) обучены на LaTeX-разметке и способны интерпретировать математические выражения в тексте. Следовательно, RAG-пайплайн, питающий LLM такими **структурированными данными**, будет давать более точные ответы на математические вопросы. Исследования OCR в контексте RAG подтверждают это: **ошибки семантики (неверно распознанные символы) сильнее всего снижают качество** ответа, тогда как чисто форматные отличия (например, линейное представление формулы вместо двухэтажного) влияют меньше【4†L138-L146】. То есть Mathpix, выдающий верные символы и структуру формул, непосредственно улучшает и полноту поиска, и точность генерации ответа. 
> 
> **Скорость и стоимость:** Mathpix предоставляет облачный API, а также офлайн-решения для корпоративных клиентов. **Скорость обработки** в облаке высока: работает batch API, позволяющий отсылать сразу пачку страниц. По заявлениям компании, они конвертировали уже **миллиарды страниц**【32†L199-L207】, оптимизируя алгоритмы. В 2025 году Mathpix объявил о снижении цен благодаря росту эффективности【51†L31-L38】. Текущая стоимость (по данным их сайта) порядка **$0.01 за страницу PDF** при больших объёмах【53†L5-L8】, что сопоставимо с ценой других OCR и гораздо дешевле, чем обрабатывать изображения через GPT-API. Например, аналогичная расценка у OpenAI: ~$0.01 за 1000 токенов, что примерно 1 страница текста; но при этом *надёжность GPT-4 как OCR ниже*. Mathpix же за 1 цент даёт почти гарантированное качественное распознавание. Для небольших проектов доступен **бесплатный лимит** или персональная подписка (несколько долларов в месяц), чего достаточно, чтобы попробовать конвертировать пару документов. В разрезе скорости: исходя из практического кейса – ~400 стр за 2 часа чистого OCR – можно оценить ~200 стр/час (при параллельной обработке больше). Это **быстрее, чем ручной OCR**, и сравнимо с FineReader на локальной машине. 
> 
> **Применимость:** Mathpix и аналогичные сервисы подходят для **многоязычных документов**. Русскоязычные материалы распознаются, хотя иногда потребуется проверить специфичные буквы (например, русскую "х" vs латинскую "x" в формулах – Mathpix по контексту обычно верно определяет). Также Mathpix поддерживает **распознавание рукописных формул** и нестандартных шрифтов, что полезно, если источники включают отсканированные рукописные выкладки или старые книги. Open-source аналогом Mathpix является проект **pix2tex (LaTeX-OCR)**【50†L15-L23】 – модель на основе ViT, конвертирующая изображения формул в LaTeX. Её можно развернуть локально, что исключает расходы на API. Однако по точности и удобству интеграции готовые сервисы вроде Mathpix пока впереди: один из авторов на Hacker News отмечает, что **удобство Mathpix “перевешивает всё” за свою цену**【49†L29-L34】. 
> 
> **Выводы:** Подход с Mathpix обеспечивает **лучшую полноту и качество данных** для RAG. В идеале его стоит сочетать с традиционным OCR: как рекомендуют на форумах, *“FineReader лучше справляется с текстом, а нейросервис идеально распознаёт формулы”*【24†L7-L15】. На практике это реализуется так: сначала распознаём весь документ FineReader’ом, получаем текст с тегами вместо формул, затем вырезаем изображения формул и прогоняем их через Mathpix (или pix2tex), после чего с помощью скрипта заменяем теги на полученный LaTeX-код【24†L19-L27】. Такой pipeline требует усилий, но даёт наилучший результат: **максимум информации для последующего поиска** и минимальная ручная коррекция. Если же нужен **быстрый результат “в один клик”**, Mathpix сам по себе может сконвертировать PDF в Markdown/HTML, пригодный для индексации. В любом случае, для научных PDF с большим числом формул этот подход сейчас наиболее надёжный.
> 
> ## Подход 3: Прямой ввод сканов/изображений в LLM (мультимодальные модели)
> 
> **Описание:** Самый свежий и инновационный подход – вообще **не выполнять явное OCR заранее**, а предоставить модельному алгоритму сами изображения страниц (или фрагменты) и задать вопрос. Современные мультимодальные большие модели (например, GPT-4 Vision, специальная версия LLaVA, или экспериментальные модельки типа *Mistral OCR*) способны **на лету прочитать текст с картинки и проанализировать его**. В контексте RAG такой сценарий мог бы выглядеть так: вместо хранения текстового индекса, храним изображения страниц; при запросе сначала с помощью эмбеддингов (или метаданных) находим релевантные страницы, затем передаём их как изображения в LLM, и просим модель найти на них ответ. Либо ещё радикальнее – снабжаем LLM всей базой изображений и “просим искать внутри” (но это крайне ресурсоёмко). Подход находится **на пересечении OCR и энд-ту-энд обработки**: модель сама выполняет роль и распознавателя, и отвечающего агента.
> 
> **Точность распознавания:** Мультимодальные LLM достигли больших успехов в распознавании визуальной информации, однако полностью заменить специализированное OCR пока не могут. Во-первых, **LLM нередко допускают галлюцинации или пропуски при чтении текста с изображения** – модель может “додумывать” фразу, если не уверена, или опустить сложноразличимые части【11†L26-L28】. Это критично: даже небольшая выдумка (например, неверная цифра в формуле) для RAG недопустима. Специализированный OCR скорее выдаст пустоту или символ “□” на месте неразборчивого знака, чем придумает содержимое; LLM же по своей природе склонна заполнить пробел вероятным продолжением. Во-вторых, у LLM **ограниченное окно внимания**: им сложно сразу обработать изображение целой страницы с мелким текстом. GPT-4, например, может воспринимать изображения, но есть ограничения по их количеству и размеру в одном запросе. Небольшие формулы или отдельные фрагменты текста модель распознает довольно точно, особенно если изображение чёткое – такие примеры есть (GPT-4 решает задачи по сканам рукописей и т.п.). Но для массовой конвертации PDF этот метод пока ненадёжный. Эксперименты с моделью Mistral-7B, обученной для OCR, показали, что **даже при впечатляющих результатах есть заметный риск упустить куски текста** или переврать формат【11†L26-L28】. Некоторые открытые проекты (например, *LLaVA-Document* или *Donut*) пытаются сделать end-to-end модель, которая сразу выдаёт структурированный текст из картинки, но по качеству они уступают сочетанию классического OCR + правила. 
> 
> Что касается **распознавания формул**, здесь LLM тоже не на высоте. Модель может “зрительно” понять, что изображена формула, и даже на естественном языке описать её (“уравнение с дробями и корнями”), но чтобы выдать *точно такой же LaTeX*, ей требуется специальная настройка. Без этого LLM часто пропишет формулу нестрого или словами. В то же время, GPT-4, будучи хорошо обученным на LaTeX, в принципе *может* при правильном подсказке отрендерить виденное уравнение в виде кода – но гарантировать точность всех индексов сложно. 
> 
> **Влияние на RAG:** Прямой мультимодальный ввод в RAG пока используется ограниченно. Главная проблема – **индексация знаний**. Поиск по базе изображений требует либо хранить скрытые эмбеддинги картинок (через CLIP или подобное), либо всё сводить к перебору с моделью, что крайне медленно. На практике чаще берут гибридный путь: строят текстовый индекс (с помощью обычного OCR), а LLM с картинками применяют уже на этапе генерации ответа *для верификации или извлечения точной цитаты*. Например, можно найти релевантный фрагмент текстово, а потом попросить GPT-4 глянуть на исходный скан этой страницы, чтобы подтвердить цифры или формулы. Такой подход повышает точность ответа (модель сверится с картинкой), но не ускоряет поиск. В целом, **мультимодальные LLM пока уступают связке “OCR + LLM”** в метриках качества и скорости. Как отмечают разработчики, специализированный pipeline способен обрабатывать десятки страниц в секунду, тогда как LLM-vision требует гораздо больше вычислений【11†L15-L23】. Кроме того, стоимость: GPT-4 с картинками – дорогой ресурс (ограничения по запросам и высокая цена). **Если прогнать через GPT-API тысячу страниц, это обойдётся во множество долларов**, причём без уверенности в точности 100%. Для сравнения, Mathpix за ту же тысячу страниц возьмёт порядка $10 и даст надёжный результат.
> 
> С точки зрения **Recall/Precision**, прямой подход рискован: модель может пропустить часть фактов на странице (низкий recall с одной страницы) или “увидеть” лишнее (что потом приведёт к ошибочному ответу – падение precision). Большие модели, правда, обладают некоторой **робастностью к OCR-шуму**: например, исследование показало, что более мощные LLM могут отвечать правильно даже при частично искажённом OCR, компенсируя пропуски своими знаниями【26†L19-L27】. Это значит, что GPT-4 иногда догадается об ответе по контексту, даже если OCR выдал абракадабру в одном слове. Но такой “угадывающий” ответ для RAG нежелателен – нам нужен точный извлечённый факт, а не догадка модели. Поэтому **надёжность и воспроизводимость ответов страдают**. 
> 
> **Скорость и затраты:** Большие мультимодальные модели требуют мощных GPU и много времени на обработку изображений. Например, открытая реализация Donut (Transformer для документов) или Pix2Struct не приближается по скорости к классическому OCR: там, где FineReader справится за секунду, нейросеть может обдумывать несколько секунд. Про GPT-4: интерактивный режим ChatGPT с картинками имеет ограничения по скорости (несколько изображений в минуту максимум). Проекты вроде *Mistral OCR* демонстрируют прогресс – энтузиасты добиваются десятков страниц в секунду на A100/H100, но это все равно требует дорогого железа【11†L15-L23】. Финансово, если у организации уже есть лицензия GPT-4 Vision, можно вручную использовать его для отдельных сложных случаев (например, чтобы **расшифровать график** или очень нестандартный элемент, где обычный OCR бессилен). Однако системно построить RAG на чистых LLM-видениях сейчас **очень дорого и сложно масштабировать**.
> 
> **Применимость к русскоязычным данным:** GPT-4 отлично понимает русский текст и при подаче изображения с русским фрагментом способен его прочитать и перевести/проанализировать. То есть с точки зрения языка **модель мультиязычна** – ограничений почти нет (латиница, кириллица, иероглифы и т.п. она распознает). С открытыми моделями сложнее: например, LLaVA обучалась в основном на английских картинках, и могжет хуже читать кириллицу. Но можно ожидать, что будущее поколение open-source VLM (Vision-Language Models) получат более широкий языковой тренинг. Тем не менее, шрифт старой советской печати или рукописи по-русски могут быть трудны и для GPT. В таких случаях специализированные системы (Finereader с обучением или ABBYY Vantage) надёжнее. 
> 
> **Выводы:** Прямой ввод сканов в LLM – привлекательный “человеко-подобный” подход (мы даём ИИ документ как есть, без промежуточных шагов). Однако на текущий момент **он уступает в точности и предсказуемости**. Высока вероятность потерять информацию или получить галлюцинации【11†L26-L28】. Скорость и стоимость такого решения делают его непрактичным для больших баз знаний. Поэтому на сегодня этот метод скорее дополнение: его можно применять точечно, когда нужно понять сложный график или проверить формулу на изображении, но **основной OCR-поток лучше обеспечить классическими средствами**. Возможно, по мере развития моделей (например, выход GPT-5 или open-систем с Vision-модулем) этот баланс изменится. В частности, если появятся более дешёвые модели, которым можно “скормить” сразу десятки страниц изображений и получить структурированный ответ, RAG-пайплайны упростятся. Пока же best practice – **гибридные подходы**: использовать LLM для пост-обработки и улучшения OCR-результата (например, привести формулы к единому стилю, расшифровать непонятные места, проверить единицы измерения на графике и т.п.), но не полагаться на них для первоначенного извлечения всех данных.
> 
> ## Сравнительная таблица: плюсы и минусы подходов
> 
> Ниже сведены основные достоинства и недостатки каждого метода применительно к задаче индексирования сканов с формулами для RAG:
> 
> | **Метод** | **Плюсы** | **Минусы** |
> |-------------------------------|----------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|
> | **1. ABBYY FineReader** | – **Высокая точность OCR текста** (в т.ч. русский и др. языки)【24†L7-L15】.<br>– **Сохранение структуры** документа: заголовки, колонки, таблицы и т.д.<br>– **Локальная обработка**: быстрый batch-OCR без облачных запросов.<br>– **Поддержка мультиязыка** “из коробки” (русский, английский, греческие символы и пр.).<br>– **Авторазметка**: разбивает текст на абзацы, может сохранять номера формул, подписей рисунков и пр. | – **Плохое распознавание сложных формул**: многолинейные уравнения не распознаются корректно【24†L1-L9】 (обычно выдаёт мусор или пропуск).<br>– **Нет экспорта в LaTeX/MathML**: формулы не превращаются в текст, максимум – как изображения или символы Юникода.<br>– **Требует послепроверки**: нужно вручную вычищать ошибки OCR (особенно специальные символы, единицы измерения).<br>– **Коммерческая лицензия**: бесплатной версии для больших объёмов нет; SDK дорогой (хотя окупается при постоянном использовании). |
> | **2. Mathpix / спец. OCR для STEM** | – **Лучшая точность на формулах**: корректно распознаёт практически все математические выражения【25†L127-L135】【49†L31-L34】, выдаёт их в виде кода LaTeX (без потери смысла).<br>– **Хорошее качество текста**: понимает научную нотацию, комбинации языков, таблицы, химические формулы.<br>– **Полнота данных**: ничего не “теряется” – формулы становятся частью текстового поиска, графики сохраняются (как изображения) и привязаны к подписям.<br>– **Удобный формат вывода**: Markdown/LaTeX можно сразу использовать для индексации, либо конвертировать в HTML, PDF и др.<br>– **Масштабируемость**: облачный API обрабатывает тысячи страниц; есть интеграции с редакторами (Overleaf, MS Word).<br>– **Поддержка русского и др. языков**: распознаются иностранные тексты и обозначения【32†L211-L218】. | – **Стоимость за объём**: сервис платный (порядка $0.01 за страницу【53†L5-L8】); для очень больших архивов расходы на API могут накапливаться (хотя цены снижаются).<br>– **Задержка на сеть**: нужен интернет для облачного API (если нет on-premise лицензии); batch-обработка требует прогрузки данных.<br>– **Возможны мелкие ошибки**: в единичных сложных формулах может неверно распознать структуру (нужна ручная проверка важных уравнений).<br>– **Закрытый код**: Mathpix – проприетарный; open-source аналоги (pix2tex и др.) пока уступают в удобстве и стабильности. |
> | **3. Мультимодальная LLM (сканы в LLM)** | – **Прямое восприятие документов**: модель видит оригинал страницы, может учитывать визуальный контекст (например, формат формулы, шрифт, график целиком).<br>– **Минимум предварительной обработки**: не нужен отдельный OCR-пайплайн, потенциально упрощает архитектуру (всё делает одна модель).<br>– **Гибкость**: та же модель, что отвечает на вопросы, сама извлекает данные – можно задавать произвольные вопросы (“что показано на графике?” – и модель опишет изображение).<br>– **Поддержка всех языков у мощных LLM**: GPT-4 прочитает текст на русском, английском, любом языке прямо с картинки.<br>– **Open-source эксперименты**: появляются модели типа *Mistral OCR*, которые можно дообучить под свои данные (без зависимости от внешних API). | – **Низкая надёжность OCR-процесса**: LLM склонна генерировать текст по вероятности, **могут быть галлюцинации и пропуски** символов【11†L26-L28】 (что недопустимо для точного извлечения).<br>– **Сложность индексации**: нет готового текстового корпуса – поиск по изображениям требует сложных эмбеддингов или многократного прогона моделью (очень медленно).<br>– **Медленно и дорого**: обработка даже десятков страниц через LLM занимает значительно больше времени, чем традиционное OCR; стоимость API (или содержание собственной GPU-фермы) гораздо выше, чем использование специализированных OCR-инструментов.<br>– **Проблемы с формулами**: модель **не гарантирует точный вывод LaTeX** – может описать формулу словами или упустить детали, что снижает ценность для RAG.<br>– **Непредсказуемость**: каждый прогон LLM может дать чуть разный результат (например, иначе расставить пробелы или порядок элементов), что затрудняет отладку системы. |
> 
> **Заключение.** В реальных проектах по оцифровке и поиску по научным материалам наилучшие результаты даёт **гибридный подход**. Практики рекомендуют комбинировать преимущества каждого метода: использовать устойчивое OCR (FineReader или аналог) для получения текста и базовой структуры документа, **отдельно обрабатывать формулы** с помощью специализированных инструментов (Mathpix, InftyReader, pix2tex), и только в сложных случаях прибегать к мультимодальным моделям (например, для анализа графиков или валидации формул). Такой pipeline обеспечивает **высокую точность распознавания** – текст и формулы будут полноценными и корректными, – что прямо отражается на качестве RAG (максимальный Recall и F1)【26†L7-L10】. Да, это требует больше настроек (например, скрипты замены формул【24†L19-L27】), зато итоговая база знаний получится богатой и структурированной. Если же ресурс ограничен и нужен быстрый результат, предпочтительнее **Mathpix API**, так как он сразу даёт структурированный Markdown: в нём формулы, текст, таблицы представлены практически так же, как в исходнике, и модель RAG сможет ими воспользоваться. 
> 
> Для русскоязычных источников применение всех трёх подходов возможно, но с нюансами: FineReader исторически сильнее всего на русском тексте; Mathpix хоть и не обучался специально на русском, справляется с научными текстами, содержащими русские фразы (нужна разве что проверка вывода на смешение алфавитов); LLM с картинками при работе с русским текстом будет столь же ненадёжна, как и на английском, поэтому её роль вспомогательная. В открытом доступе существуют и **open-source инструменты**: сочетание Tesseract OCR + pix2tex, проекты вроде Marker (для автоматизации парсинга PDF), Libs в экосистеме LangChain (Unstructured.io для извлечения элементов документа). Их можно использовать без лицензий, но следует ожидать, что по качеству распознавания они уступят коммерческим решениям – значит, потребуется более тщательная отладка и оценка. 
> 
> Подводя итог, **рекомендуемым решением** является интегрированный конвейер: *FineReader* (или аналогичный OCR) для текста + *Mathpix* (или его аналог) для формул, с последующим индексированием полученного **богатого, структурированного текста**. Это обеспечивает наилучшую основу для RAG: модель будет опираться на корректный контент и выдавать точные ответы, даже когда вопрос касается сложных формул или данных из графиков. Как отмечается в исследовании, качество OCR напрямую коррелирует с качеством RAG, поэтому вложения в более точное распознавание окупятся повышенным F1 и надёжностью системы【26†L7-L10】. Каждый из описанных подходов имеет свои сильные и слабые стороны (резюмированы в таблице), и выбор комбинации должен основываться на требованиях проекта – объёме данных, бюджете, допустимой погрешности и наличии тех или иных инструментов. Таким образом, проведённый анализ реальных практик показывает, что **оптимальной стратегией** является использование сильных сторон всех методов в комплексе, чтобы нивелировать их индивидуальные недостатки и добиться высокой точности и полноты извлечения знаний из сканированных научных документов.【24†L7-L15】【11†L26-L28】
<!-- UID: e80578fb-1a45-41fe-a386-85872ccbb24d -->