>[!nexus_user] **User** - 06.07.2025 at 11:36
> –ø–æ–ø—Ä–æ–±—É–π —Ç—ã —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å: I'm building a self-hosted AGI-like system. Search for research since June 1, 2020 with practical or conceptual value for this. These are examples (not strict rules) of what to look for ‚Äî focus on anything that might be useful for local AGI, even if unusual:
> 
> ‚Äì Modular or self-improving LLMs (example: cognitive agent frameworks or modular memory)
> ‚Äì Long-term memory systems: RAG, LoRA, attention compression, vector DBs, memory agents
> ‚Äì Reasoning architectures (example: symbolic-neural hybrids, tool-using agents, logical chains)
> ‚Äì Offline learning: distillation, continual learning, data-efficient training, training by dialog
> ‚Äì Small models with large effects (examples: novel routing, curriculum tricks, subnetwork activation)
> ‚Äì Unusual post-training techniques (example: training like raising a child, or behavioral shaping)
> ‚Äì Innovative interfaces (example: AGI with sketchpad, gesture, world model overlays)
> ‚Äì Alternative to tokenization (example: JEPA, concept vectors, joint multimodal anchors)
> ‚Äì Entirely new math or representations (examples: topological thinking, dynamic graphs, phase fields)
> ‚Äì Hybrid RAG systems that include web search + local index + on-the-fly memory construction
> ‚Äì Self-rewriting/self-updating models (example: agents that modify their own weights or config via prompts)
> ‚Äì Emergent AGI traits (examples: subjective behavior, unpredictability, recursive insight)
> Please exclude SaaS/cloud-only systems. Give papers, projects, or even unexplored ideas worth prototyping for local AGI.
<!-- UID: 39439191-a2c1-4fc8-a563-a54332970d0b -->




>[!nexus_agent] **Assistant** - 06.07.2025 at 11:36
> Search query: I'm building a self-hosted AGI-like system. Search for research since June 1, 2020 with practical or conceptual value for this. These are examples (not strict rules) of what to look for ‚Äî focus on anything that might be useful for local AGI, even if unusual:
> 
> ‚Äì Modular or self-improving LLMs (example: cognitive agent frameworks or modular memory)
> ‚Äì Long-term memory systems: RAG, LoRA, attention compression, vector DBs, memory agents
> ‚Äì Reasoning architectures (example: symbolic-neural hybrids, tool-using agents, logical chains)
> ‚Äì Offline learning: distillation, continual learning, data-efficient training, training by dialog
> ‚Äì Small models with large effects (examples: novel routing, curriculum tricks, subnetwork activation)
> ‚Äì Unusual post-training techniques (example: training like raising a child, or behavioral shaping)
> ‚Äì Innovative interfaces (example: AGI with sketchpad, gesture, world model overlays)
> ‚Äì Alternative to tokenization (example: JEPA, concept vectors, joint multimodal anchors)
> ‚Äì Entirely new math or representations (examples: topological thinking, dynamic graphs, phase fields)
> ‚Äì Hybrid RAG systems that include web search + local index + on-the-fly memory construction
> ‚Äì Self-rewriting/self-updating models (example: agents that modify their own weights or config via prompts)
> ‚Äì Emergent AGI traits (examples: subjective behavior, unpredictability, recursive insight)
> Please exclude SaaS/cloud-only systems. Give papers, projects, or even unexplored ideas worth prototyping for local AGI.
<!-- UID: a766ab0f-9016-405e-9a39-938074eebf31 -->

---

>[!nexus_agent] **Assistant** - 06.07.2025 at 11:36
> {"query":"research papers since June 1, 2020 on self-hosted AGI: modular LLMs, memory systems (RAG, LoRA), symbolic-neural hybrids, offline learning, emergent behavior, JEPA, alternative tokenization, hybrid RAG"}
<!-- UID: 6fafb8f6-9797-4087-8877-e8908b08eaf2 -->

---

>[!nexus_agent] **Assistant** - 06.07.2025 at 11:36
> –í–æ—Ç –ø–æ–¥–±–æ—Ä–∫–∞ —Å—Ç–∞—Ç–µ–π –∏ –∏–¥–µ–π —Å **–≤—ã—Å–æ–∫–∏–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º –∫ AGI**, –æ—Ç–≤–µ—á–∞—é—â–∏—Ö —Ç–≤–æ–µ–º—É —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É –ø—Ä–æ–º–ø—Ç—É –∏ –∑–∞–ø—Ä–æ—Å—É ¬´—Å June¬†1¬†2020¬ª, —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ *—Ä–µ–¥–∫–æ–µ/—ç–∫–∑–æ—Ç–∏—á–µ—Å–∫–æ–µ*, *–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é*, *—Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –∏ —ç–º–µ—Ä–¥–∂–µ–Ω—Ç–Ω–æ—Å—Ç—å*, *–≥–∏–±—Ä–∏–¥–Ω—ã–µ RAG*.
> 
> ---
> 
> ## 1. üîÑ **Discrete-JEPA: –Ω–æ–≤—ã–π —Å–ø–æ—Å–æ–± —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏**
> - **Learning Discrete Token Representations without Reconstruction** (Discrete-JEPA, –∏—é–Ω—å 2025). –ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è **—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –¥–∏—Å–∫—Ä–µ—Ç–Ω–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è**, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–º—ã—Å–ª –∏ –ø–æ–≤—ã—à–∞—è –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—é –¥–ª—è reasoning; –∑–∞–º–µ–Ω–∞ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–µ –∫–æ–¥—ã cite.
> - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–π –±–∞–∑—ã JEPA –∏ –µ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π, –≤ –¥—É—Ö–µ **–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∏ –Ω–æ–≤–æ–≥–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ø–ø–∞—Ä–∞—Ç–∞** cite.
> 
> ---
> 
> ## 2. üß† **JEPA –∏ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ world models**
> - **Hierarchical JEPA** (LeCun et al., –¥–æ –∏—é–Ω—è 2025) ‚Äî non-generative –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –æ–±—É—á–∞—é—â–∞—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è, –ø—Ä–∏–≥–æ–¥–Ω—ã–µ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –¥–æ–ª–≥–∏—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–∞—Ö cite.
> 
> ---
> 
> ## 3. üõ† **Self-MoE & modular LLMs**
> - **Self‚ÄëMoE** (–∏—é–Ω—å 2024): –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç LLM –≤ —Å–∏—Å—Ç–µ–º—É –º–æ–¥—É–ª–µ–π –ø–æ—Å—Ä–µ–¥—Å—Ç–≤–æ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä–∞. –ú–æ–¥–µ–ª–∏ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è —É–º–Ω–µ–µ –±–µ–∑ —Ä–æ—Å—Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: +6.5‚ÄØ% –Ω–∞ reasoning –∏ coding citeturn0academia23.
> 
> ---
> 
> ## 4. ü§ñ **Self-refinement & self-updating**
> - **Self‚ÄëRefine** (2023): LLM —Å–∞–º–æ–æ—Ç—à–ª–∏—Ñ–æ–≤—ã–≤–∞–µ—Ç —Å–≤–æ–π –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ —Ü–∏–∫–ª feedback-refine, +20‚ÄØ% —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è citeturn0academia22.
> - Reddit (2025): —É–ø–æ–º—è–Ω—É—Ç—ã **Sakana‚Äôs Darwin G√∂del Machine**, MIT SEAL, DeepMind AlphaEvolve ‚Äî –∞–≥–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ **—Å–∞–º–æ–ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É—é—Ç—Å—è** –ø—Ä—è–º–æ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ cite.
> - Wikipedia: —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏ —Ç–∏–ø–∞ **STOP** –∏ **AlphaEvolve** ‚Äî –ø—Ä–∏–º–µ—Ä —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–≥–æ self-optimize cite.
> 
> ---
> 
> ## 5. üß¨ **OpenAGI –∏ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã**
> - **OpenAGI** (–∞–ø—Ä–µ–ª—å 2023): LLM + —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ + RLTF ‚Äî –ø—Ä–∏–º–µ—Ä —Å–∞–º–æ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ feedback –ª–æ–≥–∏–∫–∏ –∞–≥–µ–Ω—Ç–Ω–æ-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã citeturn0academia20.
> 
> ---
> 
> ## 6. ü§ù **OpenCog Hyperon ‚Äî –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π AGI –ø–æ–¥—Ö–æ–¥**
> - OpenCog Hyperon (—Å–µ–Ω 2023): –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è AGI-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ —Å –∏–Ω–æ–π **–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Å–Ω–æ–≤–æ–π** (AtomSpace, PLN, ECAN), **—Å–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é** –∏ **–ø–∞–º—è—Ç—å—é/—Å—É–±—ä–µ–∫—Ç–Ω–æ—Å—Ç—å—é** citeturn0academia21.
> 
> ---
> 
> ## 7. üöÄ **Hybrids –∏ reasoning**
> - **I-JEPA / V-JEPA** (LeCun & Meta): world-model predictive –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è, –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—â–∏–µ, –∞ **–ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—â–∏–µ latent embeddings**, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ reasoning –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ‚ÄÇcite.
> 
> ---
> 
> ## 8. üìâ **–ù–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ post-training –ø–æ–¥—Ö–æ–¥—ã**
> - –•–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ —á–µ—Ä–µ–∑ JEPA, Self-MoE, Self-Refine: –Ω–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–µ fine-tuning, –∞ –æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ **—Å–∞–º–æ—Ä–µ—Ñ–ª–µ–∫—Å–∏—é, —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π feedback, —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è** ‚Äî —ç–∫–∑–æ—Ç–∏–∫–∞ –≤—Ä–æ–¥–µ ¬´–≤–æ—Å–ø–∏—Ç—ã–≤–∞—Ç—å –∫–∞–∫ —Ä–µ–±—ë–Ω–∫–∞¬ª.
> 
> ---
> 
> ## 9. üß© **–°–º–∞—Ä—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –∏ –≥–∏–±—Ä–∏–¥ RAG**
> - –ù–∞—à—ë–ª **Self‚ÄëMoE**, **OpenAGI**, **JEPA** ‚Äî –Ω–æ 
> ‚Äì‚Äì –≥–∏–±—Ä–∏–¥ RAG + web + –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å = –ø–æ—Ç—Ä–µ–±—É–µ—Ç –∫–∞—Å—Ç–æ–º–Ω–æ–π –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏; –ø–æ–∫–∞ –ø—Ä—è–º—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –Ω–µ—Ç, –Ω–æ –º–æ–∂–Ω–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–Ω—É—Ç—å.
> 
> ---
> 
> ## 10. ‚ú® **–≠–º–µ—Ä–¥–∂–µ–Ω—Ç–Ω–æ—Å—Ç—å –∏ —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**
> - –£ Hyperon ‚Äî –∑–∞—è–≤–ª–µ–Ω–∞ **—Å—É–±—ä–µ–∫—Ç–Ω–æ—Å—Ç—å**, –æ—Ç—Ä–∞–∂–∞—Ç–µ–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞. 
> - Self‚Äëimproving –∞–≥–µ–Ω—Ç—ã –∏ JEPA –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç **–Ω–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–µ emergent —Å–≤–æ–π—Å—Ç–≤–∞** –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –∏ reasoning.
> 
> ---
> 
> ### üìä –ò—Ç–æ–≥ ‚Äî –ú–∞—Ç—Ä–∏—Ü–∞ –∏–¥–µ–π
> 
> | –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä—ã | –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ AGI |
> |-------------|---------|-------------------------------|
> | **–ù–æ–≤–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è** | Discrete-JEPA, JEPA | ‚úÖ –¥—Ä—É–≥. —Ç–æ–∫–µ–Ω—ã, –ø—Ä–æ–∫–∞—á–∫–∞ reasoning |
> | **–ú–æ–¥—É–ª–∏ & routing** | Self‚ÄëMoE | ‚úÖ modular LLM, –±–µ–∑ —Ä–æ—Å—Ç–∞ |
> | **–°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ** | Self‚ÄëRefine, Darwin, STOP | ‚úÖ self-rewriting, —ç–≤–æ–ª—é—Ü–∏—è –æ–Ω–ª–∞–π–Ω |
> | **AGI-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏** | OpenAGI, OpenCog | ‚úÖ hybrid agents, –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ |
> | **–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞/world models** | JEPA –∏ –µ–≥–æ –∏–µ—Ä–∞—Ä—Ö–∏–∏ | ‚úÖ non-gen world model –¥–ª—è planning |
> 
> ---
> 
> ## üîß –ß—Ç–æ –¥–∞–ª—å—à–µ?
> 
> - –•–æ—á–µ—à—å ‚Äî –º–æ–≥—É —É–≥–ª—É–±–∏—Ç—å—Å—è –≤ **Discrete-JEPA**, Self‚ÄëMoE –∏–ª–∏ OpenCog —Å PDF –∏ –∫–ª—é—á–µ–≤—ã–º–∏ –∏–¥–µ—è–º–∏.
> - –•–æ—Ä–æ—à–µ–π –∏–¥–µ–µ–π –±—É–¥–µ—Ç **–ø—Ä–æ—Ç–æ—Ç–∏–ø –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ RAG + –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å + –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π memory build –æ—Ç web + JEPA embed**.
> - –î–ª—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤ ‚Äî –º–æ–∂–Ω–æ –≤–Ω–µ–¥—Ä–∏—Ç—å **sketchpad-—Å–ª–æ–π –ø–æ–≤–µ—Ä—Ö world model JEPA**, –∏–ª–∏ LLM-driven drawing.
> 
> –°–∫–∞–∂–∏, –∫—É–¥–∞ –∫–æ–ø–∞—Ç—å –≥–ª—É–±–∂–µ ‚Äî –∏–ª–∏ –¥–µ–ª–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é –∏—Ç–µ—Ä–∞—Ü–∏—é –ø–æ –¥—Ä—É–≥–æ–π –Ω–µ–¥–µ–ª–µ?
<!-- UID: b7fc63aa-aa72-4dfa-bd09-3e329210e294 -->