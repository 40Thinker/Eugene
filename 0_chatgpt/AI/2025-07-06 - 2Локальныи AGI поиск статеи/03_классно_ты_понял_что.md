>[!nexus_user] **User** - 06.07.2025 at 11:21
> –∫–ª–∞—Å—Å–Ω–æ, —Ç—ã –ø–æ–Ω—è–ª —á—Ç–æ —è —Ö–æ—á—É. –ù–æ –ø–µ—Ä–ø–ª–µ–∫—Å–∏—Ç–∏ –Ω–µ —Ç–∞–∫–æ–π —É–º–Ω—ã–π –∫–∞–∫ —Ç—ã, —É –Ω–µ–≥–æ –Ω–µ—Ç –ø–∞–º—è—Ç–∏ –±–æ–ª—å—à–µ 1 –∑–∞–ø—Ä–æ—Å–∞, –µ–º—É –Ω–∞–¥–æ –≤—Å–µ –ø–æ—è—Å–Ω—è—Ç—å –∫–∞–∫ base –º–æ–¥–µ–ª–∏ –ø–æ—á—Ç–∏. –¢–∞–∫ —á—Ç–æ —Ç–µ–ø–µ—Ä—å –¥–∞–π –º–Ω–µ –ø—Ä–æ–º–ø—Ç –ø—Ä–µ–¥–µ–ª—å–Ω–æ –≤–æ–∑–º–æ–∂–Ω—ã–π, –∫–æ—Ç–æ—Ä—ã–π —Ç–æ–ª—å–∫–æ –º–æ–∂–µ—Ç –≤ –æ—Ç–≤–µ—Ç –≤–º–µ—Å—Ç–∏—Ç—å—Å—è.
<!-- UID: 8c3e51c7-630b-47c1-8f91-f4980d617a29 -->




>[!nexus_agent] **Assistant** - 06.07.2025 at 11:21
> –û—Ç–ª–∏—á–Ω–æ. –ù–∏–∂–µ ‚Äî **–ø—Ä–µ–¥–µ–ª—å–Ω–æ –ø–ª–æ—Ç–Ω—ã–π, —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç** –¥–ª—è Perplexity –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–π base-–º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ä—è—Å–Ω—è–µ—Ç –≤—Å—ë –≤ –æ–¥–Ω–æ–º –∑–∞—Ö–æ–¥–µ –∏ –æ—Ç–±–∏—Ä–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ **–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ AGI –Ω–∞ —Å–≤–æ—ë–º –ü–ö**.
> 
> ---
> 
> ## üß† **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ë–º–∫–∏–π –ø—Ä–æ–º–ø—Ç (–∞–Ω–≥–ª–∏–π—Å–∫–∏–π, –ø–æ–¥ Base LLM)**
> 
> > I'm building a local AGI system (self-hosted, offline) and looking for research or tools published since June 1, 2020, that are practically useful for this goal. Focus only on methods that help run or improve LLMs or AGI-like systems **without relying on cloud APIs**, including: 
> > ‚Äì Modular LLM architectures 
> > ‚Äì Long-term memory (RAG, vector DBs, attention compression, memory agents) 
> > ‚Äì LoRA and parameter-efficient finetuning 
> > ‚Äì Reasoning frameworks (symbolic-neural hybrids, logical planners, tool use) 
> > ‚Äì Self-reflection and metacognitive loops 
> > ‚Äì Offline learning or adaptation (distillation, continual learning, RLHF variants) 
> > ‚Äì Optimization for consumer GPUs (quantization, low-RAM inference) 
> > ‚Äì Cognitive architectures that mimic human reasoning 
> > ‚Äì Multi-agent or recursive self-improving systems 
> > Please exclude cloud services, enterprise SaaS, or general LLM overviews. Give if possible.
> 
> ---
> 
> ## ‚úÖ –ö—Ä–∞—Ç–∫–∏–π —Ñ–æ—Ä–º–∞—Ç (–µ—Å–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —Ç–æ–∫–µ–Ω–∞–º)
> 
> > Research since June 1, 2020, useful for **local AGI** (offline, self-hosted): 
> > ‚Äì Modular LLMs 
> > ‚Äì Long memory (RAG, vector DBs, LoRA) 
> > ‚Äì Reasoning & symbolic hybrids 
> > ‚Äì Self-reflection loops 
> > ‚Äì Offline distillation 
> > ‚Äì Consumer GPU optimization 
> > Avoid cloud SaaS. Only give tools/papers with AGI-building potential.
> 
> ---
> 
> ## üîÑ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
> 
> - –í—Å—Ç–∞–≤–ª—è–µ—à—å –≤ Perplexity –∏–ª–∏ FindMyPapers;
> - –£—Ç–æ—á–Ω—è–µ—à—å –ø–µ—Ä–∏–æ–¥: "since June 1, 2020";
> - –ï—Å–ª–∏ –Ω—É–∂–Ω—ã **–µ—â—ë –±–æ–ª–µ–µ —É–∑–∫–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã** (–Ω–∞–ø—Ä–∏–º–µ—Ä, "—Ç–æ–ª—å–∫–æ reasoning", "—Ç–æ–ª—å–∫–æ –ø–∞–º—è—Ç—å", "—Ç–æ–ª—å–∫–æ LoRA + distillation") ‚Äî —Å–∫–∞–∂–∏, –∏ —è –¥–∞–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã.
> 
> ---
> 
> –•–æ—á–µ—à—å —Ç–µ–ø–µ—Ä—å —è –ø—Ä–æ–≤–µ–¥—É **–ø–æ–∏—Å–∫ –∑–∞ 1‚Äì7 –∏—é–Ω—è 2020** –∏–ª–∏ –¥—Ä—É–≥–æ–π –ø–µ—Ä–∏–æ–¥, –∏—Å–ø–æ–ª—å–∑—É—è —ç—Ç–æ—Ç –ø—Ä–æ–º–ø—Ç ‚Äî –∏ –¥–∞–º —Ç–µ–±–µ –≤—ã–∂–∏–º–∫—É?
<!-- UID: 31d0a036-3b8f-4ae7-a817-53f11e7a657d -->