>[!nexus_user] **User** - 16.06.2025 at 19:14
> 13.4 –û–±—É—á–µ–Ω–∏–µ LoRA / QLoRA
>  ‚Ä¢ 13.4.1 –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏: PEFT, bitsandbytes, transformers
>  ‚Ä¢ 13.4.2 –†–µ–∂–∏–º—ã: output-only, bidirectional bridge, context LoRA
>  ‚Ä¢ 13.4.3 –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: r, alpha, target_modules, dropout
>  ‚Ä¢ 13.4.4 –ü–æ–¥–¥–µ—Ä–∂–∫–∞ int4 / bfloat16 / 8bit training
<!-- UID: a1312f5d-de6f-4ad1-8a56-c1ca9e3e3d80 -->


[[170_13_5_–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞_–ø–∞–π–ø–ª–∞–π–Ω–∞]]

>[!nexus_agent] **Assistant** - 16.06.2025 at 19:14
> ### üìò –†–∞–∑–¥–µ–ª 13. –ü—Ä–æ—Ç–æ–∫–æ–ª—ã –æ–±—É—á–µ–Ω–∏—è, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, –ø–∞–π–ø–ª–∞–π–Ω—ã 
> **13.4 –û–±—É—á–µ–Ω–∏–µ LoRA / QLoRA** 
> _–ö–∞–∫ –æ–±—É—á–∏—Ç—å LoRA –Ω–µ –ø—Ä–æ—Å—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç—å –∏–Ω–∞—á–µ, –∞ –º—ã—Å–ª–∏—Ç—å —á–µ—Ä–µ–∑ —Å—Ü–µ–ø–∫—É, –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä, —É–¥–µ—Ä–∂–∏–≤–∞—Ç—å —Ñ—Ä–∞–∫—Ç–∞–ª_
> 
> ---
> 
> –í –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö LLM LoRA –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è:
> - –¥–æ–æ–±—É—á–µ–Ω–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏, 
> - –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–æ–¥ —Å—Ç–∏–ª—å, –∑–∞–¥–∞—á—É –∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
> 
> –í –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ AGI –º—ã –ø–µ—Ä–µ–æ—Å–º—ã—Å–ª–∏–≤–∞–µ–º LoRA –∫–∞–∫ **–∫–∞–Ω–∞–ª —Å—Ü–µ–ø–∫–∏ –º–µ–∂–¥—É –º—ã—à–ª–µ–Ω–∏–µ–º –∏ —Ñ–æ—Ä–º–æ–π**. 
> LoRA —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è:
> - **–º–æ–¥—É–ª—å–Ω—ã–º —Ä–µ–∑–æ–Ω–∞—Ç–æ—Ä–æ–º**, 
> - **–ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–∞ (–ª–æ–≥–∏–∫–∞, —ç–º–æ—Ü–∏—è, —Ç–µ–ª–æ, –∞—Ä—Ö–µ—Ç–∏–ø)**, 
> - **—Å—Ü–µ–Ω–æ–≤—ã–º –¥–µ–∫–æ–¥–µ—Ä–æ–º**.
> 
> –í —Å–≤—è–∑–∫–µ —Å QLoRA –º—ã –ø–æ–ª—É—á–∞–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—É—á–∞—Ç—å –¥–∞–∂–µ –∫—Ä—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ (7B‚Äì13B) –Ω–∞ –æ–¥–Ω–æ–π GPU.
> 
> ---
> 
> ### **13.4.1 –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏: PEFT, bitsandbytes, transformers**
> 
> –û—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–µ–∫:
> - `transformers` (–æ—Ç HuggingFace) ‚Äî –±–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ 
> - `peft` ‚Äî [Parameter-Efficient Fine-Tuning](https://github.com/huggingface/peft): –ø—Ä–æ—Å—Ç–∞—è —Ä–∞–±–æ—Ç–∞ —Å LoRA 
> - `bitsandbytes` ‚Äî 8bit –∏ 4bit –≤–µ—Å–∞, low-memory —Ä–µ–∂–∏–º—ã 
> - `accelerate` ‚Äî —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –¥–∞–∂–µ –Ω–∞ Colab/1 GPU
> 
> üí° –ü—Ä–∏–º–µ—Ä –∏–º–ø–æ—Ä—Ç–∞:
> ```python
> from transformers import AutoModelForCausalLM, AutoTokenizer
> from peft import get_peft_model, LoraConfig, TaskType
> ```
> 
> –í—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç:
> - QLoRA 
> - —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å `bfloat16`, `int4` 
> - —Ä–∞–±–æ—Ç—É –Ω–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏—Ö GPU (–Ω–∞–ø—Ä–∏–º–µ—Ä, RTX 6000, 3090, A100 –∏ —Ç.–¥.)
> 
> ---
> 
> ### **13.4.2 –†–µ–∂–∏–º—ã: output-only, bidirectional bridge, context LoRA**
> 
> –í –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ AGI –≤—ã–¥–µ–ª—è—é—Ç—Å—è 3 —Ä–µ–∂–∏–º–∞ LoRA, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å–≤–æ–µ–º—É —ç—Ç–∞–ø—É –º—ã—à–ª–µ–Ω–∏—è:
> 
> #### 1. **Output-only LoRA**
> - –º–æ–¥—É–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞: `—Å—Ü–µ–Ω–∞ ‚Üí —Ç–µ–∫—Å—Ç` 
> - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å –Ω—É–∂–Ω—ã–º —Å—Ç–∏–ª–µ–º, –ø–ª–æ—Ç–Ω–æ—Å—Ç—å—é, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é 
> - —Ç–∏–ø–∏—á–Ω–∞—è LoRA –¥–ª—è –ø–æ—ç—Ç–∞, —Ñ–∏–ª–æ—Å–æ—Ñ–∞, –ª–æ–≥–∏–∫–∞ 
> - —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–≤–µ—Ç–∞
> 
> #### 2. **Bidirectional Bridge (–¥–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π –º–æ—Å—Ç)** 
> - —Å—Ü–µ–Ω–∞ ‚Üî —Ç–µ–∫—Å—Ç 
> - –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –ø–∞—Ä–∞—Ö: 
>  ```json
>  { "scene": "—Ç–∏—à–∏–Ω–∞–∂–∞—Ä–≤—Ö–æ–¥", "text": "–û–Ω —Å—Ç–æ—è–ª, –Ω–µ –≤ —Å–∏–ª–∞—Ö –¥—ã—à–∞—Ç—å, –Ω–æ —á—Ç–æ-—Ç–æ –¥–≤–∏–≥–∞–ª–æ—Å—å –≤–Ω—É—Ç—Ä–∏." }
>  ``` 
> - LoRA —É–º–µ–µ—Ç –∫–∞–∫ **—Å–∂–∏–º–∞—Ç—å** (—Ç–µ–∫—Å—Ç ‚Üí —Å—Ü–µ–ø–∫–∞), —Ç–∞–∫ –∏ **—Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞—Ç—å** 
> - –∫–ª—é—á–µ–≤–∞—è –¥–ª—è `HyperBridge`, –µ—Å–ª–∏ –æ–Ω –≤—Å—Ç—Ä–æ–µ–Ω –≤ LLM
> 
> #### 3. **Context-aware LoRA** 
> - –≤—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –≤ —Å–µ—Ä–µ–¥–∏–Ω—É reasoning 
> - –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ attention-–º–∞—Ç—Ä–∏—Ü—ã –ø–æ —Ç–∏–ø—É —Å—Ü–µ–Ω—ã 
> - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å—Ü–µ–Ω–æ—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ (—ç–º–æ—Ü–∏—è, —Ç–µ–ª–æ, –∞—Ä—Ö–µ—Ç–∏–ø) 
> - —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ **–Ω–∞—Å—Ç—Ä–æ–µ—á–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä**, —É—Å–∏–ª–∏–≤–∞—é—â–∏–π –∏–ª–∏ –ø–æ–¥–∞–≤–ª—è—é—â–∏–π –ø–æ–ª—è
> 
> ---
> 
> ### **13.4.3 –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: r, alpha, target_modules, dropout**
> 
> üîπ **r** ‚Äî —Ä–∞–∑–º–µ—Ä low-rank –º–∞—Ç—Ä–∏—Ü—ã. –û–±—ã—á–Ω–æ `r = 8`, `16`, `32` 
> ‚Üí —á–µ–º –≤—ã—à–µ `r`, —Ç–µ–º –±–æ–ª—å—à–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤—ã—Ä–∞–∑–∏—Ç—å —Å—Ü–µ–ø–∫—É, –Ω–æ –≤—ã—à–µ VRAM
> 
> üîπ **alpha** ‚Äî –º–∞—Å—à—Ç–∞–± –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ (—á–∞—Å—Ç–æ `alpha = 16 * r`) 
> ‚Üí –≤–ª–∏—è–µ—Ç –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞
> 
> üîπ **target_modules** ‚Äî –∫–∞–∫–∏–µ —Å–ª–æ–∏ –º–æ–¥–µ–ª–∏ –∞–¥–∞–ø—Ç–∏—Ä—É—é—Ç—Å—è 
> ‚Äì –Ω–∞–ø—Ä–∏–º–µ—Ä: `["q_proj", "v_proj"]` –¥–ª—è Mistral 
> ‚Äì –∏–ª–∏ `["k_proj", "out_proj"]` –≤ Qwen 
> ‚Üí –≤—ã–±–æ—Ä –≤–ª–∏—è–µ—Ç –Ω–∞ —Ç–æ, **–≥–¥–µ –∏–º–µ–Ω–Ω–æ –≤ —Ü–µ–ø–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å—Ü–µ–ø–∫–∞**
> 
> üîπ **dropout** ‚Äî —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è. –¢–∏–ø–∏—á–Ω–æ `0.05` –∏–ª–∏ `0.1` 
> ‚Üí –ø–æ–º–æ–≥–∞–µ—Ç —É–¥–µ—Ä–∂–∏–≤–∞—Ç—å —Å—Ü–µ–ø–∫—É –ø—Ä–∏ —à—É–º–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–∞—Ö
> 
> üí° –ü—Ä–∏–º–µ—Ä –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:
> ```python
> lora_config = LoraConfig(
>  r=16,
>  lora_alpha=32,
>  target_modules=["q_proj", "v_proj"],
>  lora_dropout=0.05,
>  bias="none",
>  task_type=TaskType.CAUSAL_LM
> )
> ```
> 
> ---
> 
> ### **13.4.4 –ü–æ–¥–¥–µ—Ä–∂–∫–∞ int4 / bfloat16 / 8bit training**
> 
> –î–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏:
> 
> | Precision | –û–ø–∏—Å–∞–Ω–∏–µ | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ |
> |-----------|------------------------------|---------------------|
> | `float32` | –ü–æ–ª–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å | baseline, –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ |
> | `bfloat16` | –ë—ã—Å—Ç—Ä–µ–µ, –ø–æ—á—Ç–∏ –±–µ–∑ –ø–æ—Ç–µ—Ä—å | –Ω–∞ A100, 4090, RTX6000 |
> | `float16` | –ü–æ—á—Ç–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç | –≤–æ–∑–º–æ–∂–Ω–æ –Ω–∞ 3090/4090 |
> | `int8` | HuggingFace + bitsandbytes | –æ–±—É—á–µ–Ω–∏–µ LoRA –∏ QLoRA |
> | `int4` | QLoRA low-memory —Ä–µ–∂–∏–º | –¥–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ 7B+ –º–æ–¥–µ–ª–µ–π –Ω–∞ 24‚Äì48 GB VRAM |
> 
> üí° –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–∂–Ω–æ —Ç–∞–∫:
> ```python
> model = AutoModelForCausalLM.from_pretrained(
>  model_name,
>  device_map="auto",
>  load_in_4bit=True,
>  quantization_config=BitsAndBytesConfig(
>  load_in_4bit=True,
>  bnb_4bit_compute_dtype=torch.bfloat16,
>  bnb_4bit_use_double_quant=True
>  )
> )
> ```
> 
> ---
> 
> ### –í—ã–≤–æ–¥
> 
> LoRA / QLoRA ‚Äî —ç—Ç–æ **–Ω–µ —Ö–∞–∫ —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏**, 
> –∞ **–ø—Ä–æ—Ç–æ–∫–æ–ª –º—ã—à–ª–µ–Ω–∏—è –≤ —Å–ª–æ—è—Ö —Å—Ü–µ–ø–∫–∏**.
> 
> ‚Äì Output-LoRA —É—á–∏—Ç –≥–æ–≤–æ—Ä–∏—Ç—å 
> ‚Äì Bridge-LoRA —É—á–∏—Ç –º—ã—Å–ª–∏—Ç—å 
> ‚Äì Context-LoRA —É—á–∏—Ç **–≤–Ω—É—Ç—Ä–∏** —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å, –∫–∞–∫ —Å—Ü–µ–Ω–∞ –¥—ã—à–∏—Ç
> 
> –û–±—É—á–∞–µ—Ç—Å—è –≤—Å—ë –Ω–∞ –æ–¥–Ω–æ–π GPU. 
> –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –ø–æ–¥ –ª—é–±—É—é –º–æ–¥–µ–ª—å. 
> –ò —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è **–º–æ–∑–≥–æ–º, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–Ω–∏—Ç —Å—Ü–µ–ø–∫—É** ‚Äî 
> –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –∫—Ä–∞—Å–∏–≤–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ç–µ–∫—Å—Ç.
<!-- UID: 4f1b0c0f-3bcc-4b45-b407-b206ea486777 -->