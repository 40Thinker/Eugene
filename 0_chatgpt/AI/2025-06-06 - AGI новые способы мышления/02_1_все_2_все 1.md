>[!nexus_user] **User** - 06.06.2025 at 9:38
> 1 все 2. все 3. все 4. все
<!-- UID: ba61dbf2-5473-4d6c-92a2-696224c096a3 -->


## 1. В чём суть проблемы или задачи, о которой заметка

**Суть заметки (02_1_все_2_все 1)** заключается в обозначении запроса на систематизацию подходов к разработке архитектур искусственного общего интеллекта (AGI), которые не полагаются на брутфорс (масштабирование вычислительных мощностей и данных), а строятся на принципах когнитивной науки, символических рассуждений и биологически правдоподобных моделей. Это подтверждается её переходом к подробному описанию ряда когнитивных архитектур, нейросимволических систем и альтернативных подходов.

**Релевантные заметки по теме проблемы:**

1. **[[51 Overlay AGI]]** – описывает проблему масштабируемости трансформеров (O(n²) сложность) и предлагает Overlay AGI как решение через объединение нейронных и символических методов с использованием внешней памяти.  
2. **[[13 Overlay AGI]]** – акцентирует внимание на прозрачности и эффективности хранения знаний, что напрямую связано с поставленной задачей избежать чисто масштабируемого подхода.
3. **[[24 Overlay AGI]]** – подчеркивает разницу между вычислением паттернов и организацией связей, что согласуется с идеей "умного" мышления, а не перебора.
4. **[[Beyond LLM Meta-Architectures]]** – критикует LLM как предикторы токенов и предлагает логико-ориентированные подходы к архитектуре ИИ, что пересекается с задачей поиска альтернативы брутфорсу.
5. **[[35 Overlay AGI]]** – описывает проблему хранения знаний в параметрах модели и предлагает внешние базы знаний, что напрямую отвечает задаче создания AGI без брутфорса.

## 2. Последствия отсутствия решения, на что это влияет

Отсутствие AGI, которые бы не полагались на брутфорс, ведет к ограничениям в масштабируемости, объяснимости, энергоэффективности и способности к обобщению. Без когнитивно-мотивированных архитектур ИИ остаются черными ящиками, требующими гигантских данных и мощностей, но не способными к глубокому мышлению. Это влияет на мобильные приложения, научные открытия, безопасность и доверие к ИИ-системам.

**Релевантные заметки по последствиям:**

1. **[[51 Overlay AGI]]** – указывает на последствия в виде высокого энергопотребления и непрозрачности решений при использовании традиционных трансформеров.
2. **[[14 Overlay AGI]]** – описывает, как отсутствие биологической правдоподобности и прозрачности мешает доверию к ИИ в корпоративной и образовательной среде.
3. **[[31 Overlay AGI]]** – акцентирует внимание на невозможность обработки длинных цепочек рассуждений без роста вычислительной сложности.
4. **[[Beyond LLM Meta-Architectures]]** – показывает, что без архитектурного контроля ИИ не способен к когнитивной независимости и логическому самоконтролю.
5. **[[34 Overlay AGI]]** – описывает последствия как отсутствие возможности интроспекции и творческой гибкости в мышлении.

## 3. Как решить эту проблему

Решение заключается в построении **гибридных (нейросимволических)** архитектур с явным рассуждением, внешним представлением знаний и модульной структурой. Это позволяет создавать AGI, который мыслит как человек, а не просто обрабатывает статистику. Ключевые подходы: использование символических графов, когнитивно правдоподобных моделей, механизмов выбора (селекторов), а также поддержка эволюции знаний и прозрачности.

**Релевантные заметки по решению:**

1. **[[51 Overlay AGI]]** – предлагает оверлей архитектуру с IT-LM селекторами и семантическими весами как решение масштабируемости и прозрачности.
2. **[[13 Overlay AGI]]** – детализирует роль LLM в качестве селекторов, а не генераторов, что соответствует решению через управление связями.
3. **[[31 Overlay AGI]]** – описывает внедрение внешних таблиц знаний и RAG-систем как способ избежать переподготовки моделей.
4. **[[24 Overlay AGI]]** – показывает, как архитектура может отражать структуру мозга и поддерживать эффективное мышление.
5. **[[54 Overlay AGI]]** – описывает применение в образовании, бизнесе и на мобильных устройствах, что демонстрирует практическую реализацию решений.
6. **[[Beyond LLM Meta-Architectures]]** – предлагает альтернативу через логико-управляемую архитектуру над моделями.
7. **[[14 Overlay AGI]]** – подчеркивает важность O(1) сложности и прозрачного выбора следующего токена.
8. **[[34 Overlay AGI]]** – описывает использование разнообразных агентных модулей и систем RAG для построения сложных рассуждений.
9. **[[35 Overlay AGI]]** – предлагает стыковку LLM с контекстом через семантические веса и мета-обучение.
10. **[[Hidden Micro-Architecture Overview]]** – позволяет увидеть внутреннюю структуру и модульность таких систем.

#### Sources
[^1]: [[51 Overlay AGI]]
[^2]: [[13 Overlay AGI]]
[^3]: [[24 Overlay AGI]]
[^4]: [[Beyond LLM Meta-Architectures]]
[^5]: [[35 Overlay AGI]]
[^6]: [[14 Overlay AGI]]
[^7]: [[31 Overlay AGI]]
[^8]: [[34 Overlay AGI]]
[^9]: [[54 Overlay AGI]]
[^10]: [[Hidden Micro-Architecture Overview]]

>[!nexus_agent] **Assistant** - 06.06.2025 at 9:38
> Хорошо. Я соберу информацию о ключевых разработчиках архитектур мышления для AGI (искусственного общего интеллекта), которые не полагаются исключительно на брутфорс. Это будут как академические исследователи, так и частные компании, охватывающие различные подходы — когнитивные архитектуры, нейросимволические методы, альтернативные модели мышления, и пр. Я также учту как современные, так и исторические примеры.
> 
> Сообщу, как только соберу подробности.
<!-- UID: 402b6c2e-e452-419a-8406-dc4831f0a2d3 -->

---

>[!nexus_agent] **Assistant** - 06.06.2025 at 9:48
> # Архитектуры мышления для AGI без brute force
> 
> В исследованиях **искусственного общего интеллекта (AGI)** накоплен опыт создания специальных *«архитектур мышления»* – интегрированных моделей когнитивных процессов, альтернативных грубому перебору и чисто масштабируемым подходам. В отличие от методов, полагающихся на огромное количество данных и вычислений, эти архитектуры стремятся к более **эффективному обобщению знаний, переносу опыта и явному рассуждению**, часто сочетая нейронные алгоритмы с символическими структурами. Многие эксперты рассматривают такие *нейросимволические гибриды* как перспективный путь к настоящему AGI【65†L72-L79】, поскольку комбинация статистического обучения и **символического reasoning** может дать машине способность размышлять подобно человеку. Ниже приведены ключевые проекты и разработчики когнитивных архитектур – как классических, так и современных – которые ставят во главу угла **«умное» мышление** (обобщение, интроспекцию, выводы), а не brute force. Мы включили как академические инициативы и лаборатории, так и частные компании и стартапы, а также кратко отметили исторические примеры 1980–2000-х годов наряду с разработками 2020-х.
> 
> ## Классические когнитивные архитектуры (1980–2000-е)
> 
> - **Soar** – одна из первых общих когнитивных архитектур, созданная Алланом Ньюэллом и Джоном Лэйрдом (Университет Мичигана). Soar изначально разрабатывалась как воплощение *универсальной теории мышления* Ньюэлла. Архитектура Soar представляет собой производственную систему (production system) с единой памятью и механизмом разрешения целей. Она предназначена для построения интеллектуальных агентов, способных решать широкий спектр задач. **Soar** позиционируется как *«общая когнитивная архитектура для разработки систем, демонстрирующих интеллектуальное поведение»*【13†L222-L227】. На ней реализованы модели решения головоломок, управления роботами, обработки естественного языка и др. (подробно описано в книге J. Laird *«The Soar Cognitive Architecture»*, 2012). Soar продолжает поддерживаться сообществом исследователей, ежегодно проводятся воркшопы разработчиков Soar.
> 
> - **ACT-R** – классическая психологически обоснованная когнитивная архитектура, разработанная Джоном Андерсоном и Кристианом Лебиером в Университете Карнеги-Меллона. **ACT-R** (Adaptive Control of Thought – Rational) моделирует человеческое мышление с выделением декларативной памяти (факты) и процедурной памяти (правила-продукции). Цель ACT-R – определить базовые **элементарные операции ума**, позволяющие воспроизводить широкий спектр когнитивных задач человека【27†L1-L4】. Архитектура ACT-R является гибридной: она сочетает символическую компоненту (продукционные правила) с подсимволическими механизмами (параллельные процессы активации), которые управляют обучением и выбором правил【3†L470-L478】【3†L472-L480】. На базе ACT-R создано множество моделей (от решения задачи "Ханойские башни" до языкового понимания), сравниваемых с данными экспериментов на людях, что делает ее ценной для когнитивной науки. Проект ACT-R активно развивался с 1990-х годов и поныне имеет сообщество исследователей, обновляющих модель в соответствии с новыми данными психологии.
> 
> - **CLARION** – когнитивная архитектура, предложенная Рональдом Суном (RPI). **CLARION** нацелена на моделирование взаимодействия *имплицитного* (подсознательного) и *эксплицитного* (осознанного) знания в мышлении【29†L98-L106】. Архитектура имеет многослойную структуру: нижние уровни представляют подсознательные нейросетевые модули, а верхние – символические правила. CLARION особенно известна моделированием навыкового обучения и *двухуровневой* природы когниции (например, автоматическое vs. осмысленное мышление). Проект разрабатывается с конца 1990-х, им руководит проф. Рон Сун【29†L108-L111】. CLARION применяется для моделирования психологических феноменов и для создания искусственных агентов, умеющих учиться навыкам, используя как ассоциативное обучение, так и логические правила.
> 
> - **LIDA** – архитектура когнитивных агентов, основанная на теориях сознания (модель глобальной рабочей области). Разработана Станом Франклином и коллегами в Университете Мемфиса. **LIDA** (Learning Intelligent Distribution Agent) является развитием раннего проекта IDA и включает механизмы внимания, рабочей памяти, обучения и принятий решений, вдохновленные нейронаукой. Как отмечается, архитектура LIDA *«опирается на когнитивную науку и нейронауку»* и призвана охватить весь цикл от восприятия и эмоций до действий【31†L120-L127】. В LIDA реализован **когнитивный цикл**, включающий фазы понимания, внимания (сознательного «всплеска») и принятия решений с обучением【31†L128-L136】. Благодаря этому LIDA позволяет моделировать процессы восприятия, конкуренции идей за внимание, формирование новых воспоминаний и навыков. LIDA применяется как в программных когнитивных агентах, так и в робототехнике, и служит тестовым полигоном гипотез о работе разума.
> 
> - **Cyc** – масштабный **символический** проект по закладке базы знаний для общеразумного ИИ. Запущен в 1984 году Дугласом Ленатом, проект Cyc нацелен на ручное кодирование обширных фактов и правил здравого смысла (common sense) в виде онтологии и базы знаний. Хотя **основной упор Cyc** делается на накопление декларативных знаний, у проекта есть и элементы архитектуры мышления: центральный механизм логического вывода (дедуктивная машина) и модули понимания языка для общения на английском【69†L360-L368】. В Cyc заложены тысячи понятий и отношений, позволяющих отвечать на вопросы на естественном языке и делать простые выводы о мире. Исторически Cyc был одним из самых амбициозных и длительных AGI-проектов, став “полигоном” для символического ИИ. Хотя полного AGI на основе Cyc не создано, разработка продолжается (часть базы знаний доступна как OpenCyc), и идеи Cyc повлияли на последующие нейросимволические системы.
> 
> - **Copycat** – необычная архитектура для моделирования **аналогического мышления**, разработанная Дугласом Хофштадтером и его группой (FARG) в конце 1980-х. **Copycat** представляет собой программу, способную решать задачки на аналогии (в микромире строк символов) творческим образом. Архитектура Copycat основывается на параллельных *«кодлетах»* – небольших агентах, которые случайно порождают и проверяют гипотезы, взаимодействуя между собой. Этот подход реализует концепцию «параллельного террассированного сканирования» (parallel terraced scan) для перебора идей. Copycat известна способностью *порождать инсайты* и гибко подстраивать правила решения под каждую задачу. Как отмечается, *«Copycat – это программа, созданная для поиска инсайтных аналогий психологически реалистичным способом»*, сочетая символические и соединistские (subsymbolic) методы【74†L42-L49】. Несмотря на узкую предметную область (буквенные головоломки), Copycat продемонстрировала возможность **пластичного, «текучего» мышления** в программе, и служит классическим примером альтернативной когнитивной архитектуры.
> 
> ## Гибридные и нейросимволические архитектуры (2000–2020-е)
> 
> - **Sigma** – современная когнитивная архитектура, разрабатываемая Полом Розенблюмом (USC) как попытка *унификации* разнородных подходов. **Sigma** стремится объединить достижения **символических** когнитивных архитектур за 40 лет, **вероятностных графических моделей** и современных нейросетевых методов в единой архитектуре【67†L59-L67】. Технически Sigma базируется на расширенных факторных графах, что позволяет в единой формализме реализовать и логический вывод, и вероятностное планирование, и распознавание образов. Цель – *«гранд-унификация»* когниции: в Sigma моделируются как классические когнитивные функции (память, восприятие, язык), так и эмоциональные/мотивационные состояния, теория разума (модель других агентов) и пр.【67†L61-L67】. Sigma (Σ) возникла в 2010-х годах как развитие идей Soar/ACT-R, но на математически более общем основании, и применяется для управления виртуальными персонажами, моделирования поведения в видеоиграх и др. сценариях, требующих правдоподобного интеллекта.
> 
> - **AERA** – Autocatalytic Endogenous Reflective Architecture – экспериментальная архитектура AGI, разрабатываемая Кристинн Тороуссоном и коллегами в Исландии (ИИИМ и CADIA). **AERA** задумана как *саморазвивающийся* интеллект: минимальный начальный код (*seed*), который в процессе взаимодействия с миром самостройвается и усложняется. Официальное описание гласит: *«AERA – когнитивная архитектура и чертеж для создания агентов с высокой степенью автономности, начинающих лишь с небольшого объема заданного кода… Используя динамическое расписание приоритетов, AERA параллельно исполняет множество процессов рассуждения, накапливая всё более полезные модели опыта, что приводит к рекурсивному самосовершенствованию»*【7†L49-L57】. AERA ориентирована на **непрерывное обучение из опыта**, неконтролируемое (self-supervised) освоение всё более сложных задач. Отмечается, что AERA-агенты умеют справляться с *новизной* – неожиданными ситуациями, выходящими за рамки программирования, – и добиваться **рекурсивного самосовершенствования** без выхода за заложенные ограничители【7†L55-L63】. Этот проект демонстрирует подход к AGI через принцип “растущего интеллекта” с отражением (metacognition) и считается одним из немногих реализованных примеров архитектуры, поддерживающей самоулучшающийся разум.
> 
> - **OpenCog** – **open-source** платформа для AGI, инициированная Беном Гёрцелом и сообществом с 2008 г. **OpenCog Prime** – архитектура в основе платформы – представляет собой комплекс взаимодействующих компонентов, призванных в совокупности породить человеческого уровня интеллект как *эмерджентное явление* системы【26†L157-L165】. В OpenCog ядром знаний служит графовая база данных Atomspace, где хранятся «атомы» – узлы и связи, представляющие понятия, правила, факты. Различные алгоритмы (модули) работают с этим общим знанием: вероятностно-логический вывод (PLN) для рассуждений, внимание и забывание для управления ресурсами, различные нейросетевые подсистемы для восприятия, обучение поведению через МО (MOSES) и др. Дизайн OpenCog во многом разработан Гёрцелом и опирается на концепцию **когнитивной синергии** – интеграции разнородных методов ИИ, чтобы компенсировать слабости друг друга【26†L159-L166】. OpenCog применялся в робототехнике (например, в роботе Sophia для диалогов) и продолжает развиваться (новая версия *OpenCog Hyperon* в 2020-х годах). Это пример **нейросимволической** архитектуры: комбинирует нейронные методы (для восприятия) с символической логикой и эволюционным программированием на общей когнитивной чертеже.
> 
> - **NARS** – Non-Axiomatic Reasoning System – проект под руководством Пэй Вана (Temple University), представляющий **логико-ориентированную** архитектуру AGI. **NARS** создавался как модель рассуждения в условиях *неполноты знаний и ресурсов*, ближе к реальным условиям интеллекта. Ван определяет цель так: построение системы, следующей тем же принципам, что и человеческий разум, способной решать задачи в различных доменах как “мыслящая машина”【33†L8-L16】. В основе NARS лежит собственно *неаксиоматическая логика* – формальный аппарат, где выводы всегда относятся к текущему знанию и могут пересматриваться при поступлении новой информации. Система не предполагает априорно истинных аксиом, а учится на опыте. Практически NARS реализует универсальный выводчик, который отвечает на вопросы на основе знаний, полученных ранее, и постоянно адаптируется【33†L19-L27】【33†L21-L29】. Особый язык Narsese описывает знания и вопросы. Благодаря такому подходу NARS обладает свойствами **нескучного обучения** и *«относительной рациональности»*: суждения оцениваются относительно текущих знаний и времени, а не абсолютной истины【33†L21-L29】. NARS – знаковый пример альтернативного подхода к AGI, где упор сделан на общий механизм рассуждения, способный к **обобщению** и **адаптации** без перебора, вопреки узкоспециализированным ИИ.
> 
> - **MicroPsi** – когнитивная архитектура, развиваемая Йоша Бахом (в духе психологической теории *Psi* Дитриха Дёрнера). **MicroPsi 2** представляет собой *нейросимволическую* систему, сочетающую представления в виде распределенных активационных сетей и символические структуры, связанные с мотивацией и вниманием. Архитектура ориентирована на **воплощённых агентов** (embodied agents), действующих в среде и имеющих потребности и цели. Отличительная черта MicroPsi – наличие *мотивационной модели*: агенты имеют «эмоции» и драйвы, влияющие на принятие решений. Технически MicroPsi использует **распространение активации** по сети понятий (подобно нейронной сети), что позволяет объединять субсимволические представления с классическими символами. Как отмечают авторы, *«MicroPsi – когнитивная архитектура, комбинирующая нейросимволические представления с ситуационным восприятием и мотивационной системой»*【38†L26-L34】. Проект продемонстрировал работоспособность на примерах виртуальных агентов (и даже в среде Minecraft【38†L26-L34】), которые могут исследовать мир, обучаться задачам с подкреплением, а также **обобщать** знания благодаря единому представлению понятий и восприятия. Бах и коллеги позиционируют MicroPsi как инструмент для исследования, как сочетать перцептивные образы и концептуальные символы для достижения гибкого интеллекта.
> 
> - **IBM Neuro-Symbolic AI** – направление исследований компании IBM (в сотрудничестве с MIT), нацеленное на объединение нейросетевого обучения с символическим знанием для преодоления ограничений глубинного обучения. В IBM считают, что **нейросимволический ИИ** может значительно повысить способность машин к надежному **логическому рассуждению** и обобщению【65†L72-L79】. Примером служит проект **Neuro-Symbolic Concept Learner (NS-CL)**, разработанный в MIT-IBM Watson AI Lab: система, которая учится понимать визуальные сцены и вопросы на естественном языке, сочетая CNN для восприятия и логический модуль для ответа на вопросы. NS-CL *«строит объектное представление сцены и переводит предложения в исполнимые символические программы»*, которые затем выполняет нейросимволический модуль вывода【75†L113-L121】. Эта система смогла научиться отвечать на вопросы о картинках, *не имея* явной разметки концепций – знания о предметах и словах формируются в процессе обучения путем стыковки языка и зрения【75†L113-L121】. Направление нейросимволического ИИ активно развивается в 2020-х: IBM демонстрирует прототипы, которые **комбинируют беглость** больших языковых моделей с **строгими логическими алгоритмами** вывода, добиваясь 100% точности на сложных задачах, где чисто нейронные LLM ошибаются【63†L75-L83】. Эти работы подтверждают, что интеграция символического “знания” с нейронным обучением повышает надежность и прозрачность ИИ.
> 
> ## Биологически вдохновленные и нейрокогнитивные модели
> 
> - **Hierarchical Temporal Memory (HTM)** – теория и платформа, разработанная Джеффом Хокинсом и компанией *Numenta*. **HTM** стремится воссоздать принципы работы неокортекса – иерархическую обработку сенсорных шаблонов во времени. Изначально предложенная в книге Хокинса *«On Intelligence»* (2004), HTM получила развитие в виде алгоритмов извлечения особенностей и предсказания последовательностей. Это **биологически правдоподобная** модель машинного интеллекта: состоит из «регионов», образующих иерархию, где каждый модуль обучается выявлять **спатіально-временные паттерны** в входных данных и делать постоянные предсказания будущих входов. HTM опирается на принципы разреженного распределенного представления и памяти последовательностей, подмеченные в нейронах неокортекса. По сути, HTM – это набор вычислительных алгоритмов, которые *«отражают работу неокортекса человека»*【42†L50-L58】. Numenta выпустила открытую реализацию (NuPIC), применяемую в задачах анализа временных рядов, а Хокинс в 2021 г. предложил *теорию “Тысячи мозгов”*, расширяющую HTM идеей множества моделей мира в колонках коры. HTM – пример подхода, альтернативного глубоким нейросетям: он нацелен на **объяснимое** и **образное** машинное обучение, близкое к работе реального мозга, и на эффективное обучение с малым числом примеров (one-shot learning). 
> 
> - **Spaun** – (Semantic Pointer Architecture Unified Network) – самый крупный на сегодня функциональный моделирующий мозг, созданный командой Криса Элиасмита (Университет Ватерлоо). **Spaun** – это нейронная когнитивная архитектура, содержащая ~2.5 млн искусственных нейронов, объединенных в модули, соответствующие областям мозга (префронтальная кора, базальные ганглии и пр.)【71†L119-L127】. Spaun способен воспринимать визуальные образы цифр, запоминать последовательности, выполнять простые логические задачи (например, продолжить числовой ряд) и выдавать ответы, “рисуя” манипулятором цифры【71†L121-L127】. Все эти функции реализованы *в единой нейронной модели*, обучаемой без градиентного спуска – поведение возникает из структуры сети, спроектированной на основе **Neural Engineering Framework (NEF)**. Spaun продемонстрировал, как из взаимодействия специализированных нейроподобных компонентов может возникнуть целостное когнитивное поведение. Проект служит важным шагом в направлении **биологически правдоподобного AGI**: хотя Spaun уступает гибкости человека, он умеет решать несколько разных задач в единой системе без дообучения, показывая возможность **обобщения** знаний внутри нейронной архитектуры.
> 
> - **Vicarious** – частная исследовательская компания (основана в 2010 Д. Скоттом Фениксом и Дилипом Джорджем), известная **альтернативным подходом к ИИ**, вдохновленным нейрокорой. Vicarious разработала модель визуального восприятия **Recursive Cortical Network (RCN)** – *рекурсивную кортикальную сеть*, основанную на принципах, которые, по гипотезе, использует зрительная кора человека. В 2010-х RCN произвела фурор, сумев распознавать CAPTCHA на уровне сверточных сетей, но при обучении на *несколько порядков меньшем* объеме данных. Модель RCN является **генеративной**: она не просто классифицирует изображения, но и строит иерархическое представление частей и отношений, что позволяет обобщать от одного примера. Как отмечалось, Vicarious *«использует вычислительные принципы мозга, чтобы создавать программное обеспечение, которое может думать и учиться как человек»*【44†L143-L150】. Подход Vicarious демонстрирует упор на **эффективность обучения** и **композиционность знаний** – система может из нескольких увиденных примеров символов обобщить принципы и читать новые символы. В дальнейшем Vicarious расширяла технологии в области робототехники и была приобретена корпорацией Alphabet (Intrinsic) в 2022 году, но ее работы остаются заметным примером успехов нейроинспирированного ИИ.
> 
> - **GoodAI (Badger)** – компания GoodAI (основана Мареком Розой, 2014, Прага) разрабатывает архитектуру AGI под кодовым именем **Badger**. В отличие от монолитных нейросетей, Badger представляет собой *многоагентную* архитектуру: множество небольших модулей-«экспертов», обучающихся совместно. Ключевая идея – **мета-обучение**: все эксперты имеют общий алгоритм обучения и общения, благодаря чему система может *адаптировать свою внутреннюю структуру* под новую задачу, переобучаясь “на лету”【53†L61-L69】. Предполагается двухуровневый процесс обучения: внутренний цикл, где эксперты взаимодействуют и решают текущую задачу, и внешний цикл, где параметры их общего алгоритма подстраиваются для улучшения адаптивности【53†L63-L71】. Роза описывает Badger как набор принципов и протокол обучения, направленный на создание агента, который *быстро обучается новым умениям*【53†L49-L57】. GoodAI публикует исследования и демо-код Badger, приглашает внешних исследователей к сотрудничеству. Хотя архитектура еще в разработке, она отражает стремление к **универсальному обучающемуся агенту**, который, подобно человеку, способен **переносить знания** между разными задачами, а не обучаться каждой с нуля. Такой подход контрастирует с громоздкими моделями, требующими огромных данных, и воплощает принципы эффективного, «умного» обучения.【53†L61-L69】
> 
> - **Elemental Cognition** – стартап, основанный Дэвидом Ферруччи (ведущим создателем IBM Watson) в 2015, который разрабатывает **нейросимволическую платформу** ИИ. Цель – сочетать мощь генеративных моделей (NLU, LLM) с **формальным логическим выводом** для достижения надежного решения сложных задач. Платформа EC пытается быть своего рода мыслительным партнером: она не только отвечает на вопросы, но и объясняет *почему* получился такой ответ, прослеживая цепочку рассуждений. Ферруччи – один из тех, кто продвигает идею, что преодолеть ограничения современных глубоких нейросетей можно, научив ИИ явным правилам и логике【63†L75-L83】. В недавних демонстрациях Elemental Cognition показала, что их нейросимволический ИИ может на 100% точно решать сложные логические головоломки, где большие языковые модели ошибаются【55†L5-L13】【63†L75-L83】. Хотя подробности архитектуры закрыты, известно, что она включает модуль формального доказательства (по типу систем автоматического доказательства теорем), связанный с нейросетевыми моделями языка. Проект EC иллюстрирует стремление бизнеса к AGI, который умеет **рассуждать** и давать обоснованные ответы – это особенно важно для приложений в финансах, медицине, где от ИИ требуется объяснимость и гарантированность вывода, недостижимые «черным ящикам» deep learning.
> 
> **Источники:** Собранная информация получена из открытых материалов – официальных сайтов проектов и публикаций. Например, описание Soar приведено по сайту проекта【13†L222-L227】; сведения об ACT-R – из обзоров Андерсона【27†L1-L4】; данные о CLARION – со страницы Р. Суна【29†L98-L106】; по LIDA – из статьи Н. Дживанандам【31†L120-L127】; по Cyc – из обзора Б. Гёрцеля【69†L360-L368】; по Copycat – из работы Хофштадтера【74†L42-L49】. Современные примеры: Sigma описана в работах Розенблюма【67†L59-L67】; AERA – по материалам CADIA【7†L49-L57】; OpenCog – по Википедии【26†L157-L165】; NARS – по обзору П. Вана【33†L8-L16】; MicroPsi – из публикаций Баха【38†L26-L34】; нейросимволические тенденции – по блогам IBM【65†L72-L79】 и MIT-IBM【75†L113-L121】; HTM – по статье Хокинса【42†L50-L58】; Spaun – по Википедии【71†L119-L127】; Vicarious – по материалам компании【44†L143-L150】; Badger – из блога M. Розы【53†L61-L69】; Elemental Cognition – по интервью Ферруччи【63†L75-L83】 и пресс-релизам. Эти примеры отражают широкий спектр подходов к AGI, где во главу угла ставится не сырой перебор, а архитектурная организованность, приближенная к мышлению.
<!-- UID: 32253c5c-559f-4202-adbc-31bd98768901 -->