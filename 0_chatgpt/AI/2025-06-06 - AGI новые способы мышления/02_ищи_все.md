>[!nexus_user] **User** - 06.06.2025 at 9:40
> ищи все
<!-- UID: 51f6cd7e-28e8-49c1-8681-6e4115dcfa9e -->


## 1. В чём суть проблемы или задачи, о которой заметка?

Заметка поднимает важную критическую тему в области ИИ и научного познания: современные системы, включая AGI и генеративные модели, **не способны к по-настоящему новым научным открытиям**. Вместо этого они ограничены **повторным воспроизведением уже известных законов и моделей**, таких как законы Ньютона, Кеплера или гелиоцентрическая модель[^1]. Это указывает на ключевую проблему в архитектуре и подходе: **ИИ не обладает тем творческим и концептуальным прорывом**, который присущ научной интуиции человека. Он работает на основе ассоциаций и экстраполяций в уже известном пространстве знаний, а не создаёт принципиально новые модели реальности. Таким образом, суть проблемы заключается в **ограниченности ИИ как инструмента научного открытия** — он скорее «повторяет Ньютона», чем становится новым Эйнштейном.

#### Релевантные заметки:
1. **[[Beyond LLM Meta-Architectures]]** — рассматривает фундаментальную ограниченность LLM в понимании, указывая на необходимость создания архитектур, где логика и смысл контролируются извне, а не генерируются моделью.
2. **[[51 Overlay AGI]]** — описывает систему, в которой знания внешние, а модель лишь выбирает связи, что согласуется с критикой о том, что ИИ не генерирует новое знание, а работает с уже известным.
3. **[[22 Overlay AGI]]** — подчеркивает важность внешнего хранения знаний и трассируемости решений, что в контексте заметки позволяет не только избегать «повторных открытий», но и направлять ИИ по уже верифицированным путям.
4. **[[30 Overlay AGI]]** — акцентирует внимание на необходимости селекции смысловых связей, а не генерации, что согласуется с идеей о том, что ИИ должен выбирать между известными путями, а не создавать новые.
5. **[[13 Overlay AGI]]** — обсуждает гибридные архитектуры с внешними знаниями и символическими компонентами, которые потенциально могут быть направлены на преодоление ограничений нынешнего ИИ.

---

## 2. Последствия отсутствия решения, на что это влияет?

Если не решить проблему ограниченности ИИ в научных открытиях, то это приведёт к **заблуждению в оценке возможностей ИИ и его реального вклада в науку**. Ожидания от систем AGI могут быть завышены, что вызывает **разочарование у исследователей и снижение доверия к ИИ как инструменту научного прогресса**[^2]. Это влияет на направление инвестиций, приоритеты исследований и формирование парадигмы ИИ в науке. Если ИИ остаётся ограниченным в генерации нового знания, он не сможет стать равноправным участником научного процесса, а будет использоваться лишь как инструмент ускорения вычислений, поиска и фильтрации уже известного. Без смены архитектурного подхода (например, интеграции символического мышления, внешних верифицированных графов знаний, обратной связи от человека) **научные открытия останутся прерогативой человека**, а ИИ — лишь помощником.

#### Релевантные заметки:
1. **[[Beyond LLM Meta-Architectures]]** — предупреждает о последствиях, если ИИ остаётся ограниченным в понимании: системы будут неэффективны в сложных задачах, требующих осмысленного выбора.
2. **[[31 Overlay AGI]]** — описывает последствия отсутствия прозрачности и трассируемости в системах: потеря доверия, невозможность аудита и адаптации.
3. **[[21 Overlay AGI]]** — подчёркивает, что без внешнего управления знанием и селекцией ИИ остаётся чёрным ящиком, что ведёт к снижению его ценности в ответственных областях.
4. **[[14 Overlay AGI]]** — указывает на важность эволюции через обратную связь, что напрямую связано с необходимостью преодоления инертности "повторного открытия".
5. **[[53 Overlay AGI]]** — демонстрирует, как без правильной архитектуры ИИ просто имитирует интеллект, не способствуя реальному развитию.

---

## 3. Как решить эту проблему?

Проблему можно решить через разработку **новых мета-архитектур**, в которых ИИ будет не генерировать знание, а **работать с уже структурированными и верифицированными графами знаний**, выполняя функции селекции, анализа и логического вывода. Такие системы должны:
- Иметь **внешние базы знаний** (например, семантические графы), а не полагаться на параметры модели;
- Включать **логические и символические компоненты**, которые направляют ИИ по уже верифицированным логическим цепочкам;
- Использовать **механизмы обратной связи от экспертов** для обучения и коррекции;
- Поддерживать **прозрачность каждого шага**, чтобы понимать, является ли результат новым знанием или просто переформулировкой известного.

Решение также требует смены фокуса с "генерации" на **создание архитектур, способных к качественной интерпретации, верификации и адаптации**[^3].

#### Релевантные заметки:
1. **[[Beyond LLM Meta-Architectures]]** — предлагает переход к логически управляемым системам, где ИИ не "думает", а исполняет предопределённые правила, что может избавить от повторения известного.
2. **[[51 Overlay AGI]]** — предлагает структуру, где ИИ не генерирует, а выбирает между известными смысловыми связями, что согласуется с подходом к решению проблемы "повторных открытий".
3. **[[30 Overlay AGI]]** — демонстрирует, как можно внедрить ограничения (запрет на определённые пути) для поиска альтернативных решений, тем самым побуждая ИИ к **инновационному мышлению**.
4. **[[22 Overlay AGI]]** — подчёркивает важность внешнего хранения знаний и селективной обработки, что позволяет ИИ не повторять старое, а опираться на уже проверенные структуры.
5. **[[21 Overlay AGI]]** — описывает важность трассируемости и модульности, что позволяет отслеживать, действительно ли ИИ делает шаг вперёд или просто повторяет известное.
6. **[[13 Overlay AGI]]** — предлагает гибридные архитектуры с внешними знаниями и специализированными экспертными моделями, способными к сужению пространства поиска.
7. **[[14 Overlay AGI]]** — указывает на ценность систем, которые развиваются и адаптируются через обратную связь, что способствует уходу от инертных повторений.
8. **[[31 Overlay AGI]]** — предлагает использовать систему RAG и семантические веса для направления ИИ по уже проверенным логическим путям.
9. **[[53 Overlay AGI]]** — демонстрирует, как правильно организовать архитектуру, чтобы избежать фальшивых "открытий".
10. **[[Hidden Micro-Architecture Overview]]** — указывает на необходимость построения **внутренней микроархитектуры**, способной к осознанной селекции знания, а не к его генерации.

---

[^1]: [[02_ищи_все]]  
[^2]: [[02_ищи_все]]  
[^3]: [[Beyond LLM Meta-Architectures]]

>[!nexus_agent] **Assistant** - 06.06.2025 at 9:40
> Хорошо, я найду статьи и обсуждения, где системы AGI или современные методы искусственного интеллекта критикуются за "повторное открытие Ньютона" — то есть за заново открытие известных физических закономерностей или других научных принципов, уже давно известных науке.
> 
> Я подберу как академические источники, так и экспертные мнения, которые формулируют такую критику, и предоставлю ссылки и краткие описания. Дайте мне немного времени на это.
<!-- UID: 40fe07d0-9a67-49dd-95bb-1fce931c9aa9 -->

---

>[!nexus_agent] **Assistant** - 06.06.2025 at 9:44
> # Критика ИИ за «повторное открытие Ньютона»
> 
> - **Nautilus (2019) – *«Превозносимая революция машинного обучения преувеличена»*.** В статье Гэри Маркуса и Эрнеста Дэвиса «Are Neural Networks About to Reinvent Physics?» авторы отмечают, что шумиха вокруг ИИ, «самообучающегося» физике, чрезмерна. Они разбирают громкие новости («ИИ сам открыл законы физики», «Не нужен Коперник – есть машинное обучение») и указывают, что эти исследования лишь пытаются заново моделировать известные задачи, не давая поводов для заявленной эйфории【59†L146-L153】. Цитата: *«Преувеличенные заявления в этих работах и возникший хайп — симптом склонности журналистов, да и самих учёных, преувеличивать значимость новых достижений ИИ»*【59†L146-L153】.
> 
> - **Новость *Nature* (2019) – *«ИИ-Коперник ‘открыл’, что Земля вращается вокруг Солнца»*.** В заметке Давиде Кастельвеччи описан нейросетевой алгоритм SciNet, который, получив астрономические данные, самостоятельно пришёл к гелиоцентрической модели. Заголовок намеренно обыгрывает это *«открытие»* в кавычках【53†L33-L41】. В русскоязычном пересказе подчёркнуто, что сеть фактически **«заново открыла, что Земля вращается вокруг Солнца»** – то, что наука знала со времён Коперника【46†L191-L199】. Это вызвало смесь восхищения и скепсиса: с одной стороны, подход может помочь в новых задачах (напр. квантовые проблемы), с другой – ИИ пока лишь воспроизвёл фундаментальный закон, известный несколько веков.
> 
> - **Astrobites (2022) – *ИИ вывел закон всемирного тяготения Ньютона*.** Популярный научный блог для астрономов сообщил, что группа исследователей с помощью графовой нейросети и символического регрессионного метода **(re)открыла** закон всемирного тяготения【50†L63-L70】. *“Это был закон, который нам и так давно известен: закон тяготения Ньютона”*, – прямо отмечает автор, добавляя, что хотя результат предсказуем (его проходят в школе), сам факт, что машина вывела его из данных, рассматривается как **«воодушевляющий первый шаг»** к открытию новых уравнений【50†L63-L70】. Тем не менее, скептики указывают: пока что ИИ лишь догоняет классическую механику, не предлагая принципиально новых законов природы.
> 
> - **Habr (перевод Quanta, 2022) – *«Машинные учёные» и повторное открытие известных законов»*.** Обзор Чарли Вуда рассказывает об эволюции алгоритмов, автоматически выводящих физические формулы из данных. Ещё в 1980-х программа **BACON** заново получила третий закон Кеплера и другие классические закономерности. *«Несмотря на повторное открытие третьего закона Кеплера и других классических законов, BACON… был в диковинку»*, отмечается в статье【35†L181-L187】. То есть даже если такие алгоритмы находили уже известные истины, в то время это выглядело удивительно. Однако позже подобные системы (Eureqa, AI Feynman и др.) стали обыденным инструментом, и научное сообщество всё чаще критикует их за **перевыведение существующих знаний** вместо поиска принципиально новых принципов.
> 
> - **Блог *Understanding AI* (2023) – *«Меня обманул хайп вокруг ИИ-в-науке»*.** Физик Ник МакГриви поделился личным опытом разочарования в модных ИИ-методах. Он пытался применять нейросети для решения уравнений физики, но обнаружил, что их преимущества сильно преувеличены. Исследователь приводит примеры заявленных «прорывов», где ИИ якобы открыл нечто грандиозное, но на деле лишь воспроизвёл известные результаты. Например, разработка DeepMind по материалам выдала миллионы новых кристаллических структур, но оказалось, что это **расширение уже известных комбинаций** элементов【10†L102-L106】. Автор задаётся вопросом, действительно ли мы на пороге революции от ИИ, или же **«общий потенциал ИИ в науке преувеличен»**【10†L96-L104】. Его вывод: современные модели ускоряют рутинные задачи, но не имеют *«озарений»* для настоящих научных открытий.
> 
> - **Научная публикация *Scientific Reports* (2025) – *Границы творчества ИИ в науке*.** Свежая исследовательская работа анализирует, способен ли генеративный ИИ совершать научные открытия, подобные человеческим. Авторы приходят к выводу, что **нынешние модели способны лишь к незначительным, инкрементальным находкам**. Они не могут *«с нуля»* придумать фундаментальный закон или гипотезу, не опираясь на уже известные человеку представления【57†L71-L79】. Генеративный ИИ хорошо работает только в пределах уже **известного пространства знаний**, и часто ошибочно считает себя совершившим открытие, проявляя избыточную уверенность【57†L73-L82】. Это академическое подтверждение скепсиса: без человеческого творческого озарения ИИ рискует **«переоткрывать Ньютона»** снова и снова, вместо того чтобы открыть нового Эйнштейна. 
> 
> **Sources:** Все приведённые статьи и обзоры (Nautilus, *Nature*, Astrobites, Habr/Quanta, блог *Understanding AI*, *Scientific Reports*) содержат прямую или косвенную критику того, что современные системы ИИ в научной сфере в лучшем случае переоткрывают давно известные законы (словно **«повторно открывают Ньютона»**), и подчёркивают ограниченность нынешнего ИИ в создании по-настоящему нового знания.
<!-- UID: e1f2d9ea-95d4-4fc3-90b4-7966a4eeb062 -->