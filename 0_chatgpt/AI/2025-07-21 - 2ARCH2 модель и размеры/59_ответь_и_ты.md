>[!nexus_user] **User** - 22.07.2025 at 19:51
> –û—Ç–≤–µ—Ç—å –∏ —Ç—ã
<!-- UID: cc788094-5d1b-4647-9e92-a5e4be1b904d -->




>[!nexus_agent] **Assistant** - 22.07.2025 at 19:51
> –ö–æ–Ω–µ—á–Ω–æ. –í–æ—Ç **—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç** –Ω–∞ —Ç–≤–æ–π –≤–æ–ø—Ä–æ—Å: 
> **—á—Ç–æ –≤ –º–æ–¥–µ–ª–∏ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤—ã–±–æ—Ä —Ç–æ–∫–µ–Ω–∞, –∏ —á—Ç–æ –∏–∑ —ç—Ç–æ–≥–æ –º–æ–∂–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –ø–æ—Å—Ç-–æ–±—É—á–∞—Ç—å, –æ—Å–æ–±–µ–Ω–Ω–æ –ø—Ä–∏–º–µ–Ω–∏–º–æ –∫ Qwen3.**
> 
> ---
> 
> ## üß† –ß—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤—ã–±–æ—Ä —Ç–æ–∫–µ–Ω–∞?
> 
> –í–æ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏ LLM, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞:
> 
> | –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –§—É–Ω–∫—Ü–∏—è | –í–ª–∏—è–Ω–∏–µ –Ω–∞ output |
> |-----------|---------|--------------------|
> | **Token embeddings** | –ü—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç ID –≤ –≤–µ–∫—Ç–æ—Ä | –ó–∞–¥–∞—é—Ç –Ω–∞—á–∞–ª—å–Ω—É—é —Å–µ–º–∞–Ω—Ç–∏–∫—É —Å–ª–æ–≤–∞ |
> | **Positional encodings** | –î–æ–±–∞–≤–ª—è—é—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ–∫–µ–Ω–æ–≤ | –û–ø—Ä–µ–¥–µ–ª—è—é—Ç –ø–æ—Ä—è–¥–æ–∫ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É |
> | **Self-attention layers** | –ü–µ—Ä–µ–¥–∞—é—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ query-key-value | –†–µ–≥—É–ª–∏—Ä—É—é—Ç ‚Äú—á—Ç–æ —Å —á–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç‚Äù |
> | **FeedForward layers (MLPs)** | –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç —Ç–æ–∫–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ—è | –î–æ–±–∞–≤–ª—è—é—Ç –≥–ª—É–±–∏–Ω–Ω—É—é —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é —Å–º—ã—Å–ª–∞ |
> | **LayerNorm, biases** | –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ | –†–µ–≥—É–ª–∏—Ä—É—é—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ |
> | **Output projection head** | –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç hidden state ‚Üí vocabulary | –§–∏–Ω–∞–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π |
> 
> ---
> 
> ## üîß –ß—Ç–æ –º–æ–∂–Ω–æ –ø–æ—Å—Ç-–æ–±—É—á–∞—Ç—å?
> 
> –í –ø–æ—Ä—è–¥–∫–µ –æ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ª—ë–≥–∫–∏—Ö –∫ –Ω–∞–∏–±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–º:
> 
> | –ú–µ—Ç–æ–¥ | –ß—Ç–æ –º–µ–Ω—è–µ—Ç—Å—è | –≠—Ñ—Ñ–µ–∫—Ç | –°–ª–æ–∂–Ω–æ—Å—Ç—å |
> |-------|---------------|--------|-----------|
> | **LoRA (Low-Rank Adapters)** | attention / FFN weights (–¥–æ–±–∞–≤–∫–∞) | –£–º–µ—Ä–µ–Ω–Ω–æ —Å–∏–ª—å–Ω—ã–π | ‚úÖ –õ—ë–≥–∫–∏–π |
> | **Bias tuning** | –¢–æ–ª—å–∫–æ biases (head, MLP) | –°–ª–∞–±–æ/—Ç–æ—á–µ—á–Ω–æ | ‚úÖ –û—á–µ–Ω—å –ª—ë–≥–∫–∏–π |
> | **Output head** | –¢–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π | –ù–∞–ø—Ä—è–º—É—é –≤–ª–∏—è–µ—Ç –Ω–∞ –ª–æ–≥–∏—Ç—ã | ‚ö†Ô∏è –õ–µ–≥–∫–æ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å |
> | **Token embeddings** | –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–ª–æ–≤ | –í—ã—Å–æ–∫–∏–π —ç—Ñ—Ñ–µ–∫—Ç –Ω–∞ low-level | ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç–∏ |
> | **Attention score reweighting** | –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–ª–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–Ω–∏–º–∞–Ω–∏—è | –°–ª–æ–∂–Ω–æ, –Ω–æ –≥–∏–±–∫–æ | ‚ö†Ô∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ |
> | **Adapter modules** | –í—Å—Ç–∞–≤–∫–∏ –º–µ–∂–¥—É —Å–ª–æ—è–º–∏ | –°—Ä–µ–¥–Ω–∏–π —ç—Ñ—Ñ–µ–∫—Ç | ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ Qwen3 |
> | **Full finetuning** | –í—Å–µ –≤–µ—Å–∞ | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç | ‚ùå –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –±–µ–∑ GPU-–∫–ª–∞—Å—Ç–µ—Ä–∞ |
> 
> ---
> 
> ## üß¨ Qwen3 ‚Äî —á—Ç–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç?
> 
> –ú–æ–¥–µ–ª—å **Qwen3 (–æ—Å–æ–±–µ–Ω–Ω–æ 7B –∏ 14B)**:
> - –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ [Transformer + RoPE + SwiGLU + multi-query attention],
> - –∏–º–µ–µ—Ç **LoRA-–ø–æ–¥–¥–µ—Ä–∂–∫—É (—á–µ—Ä–µ–∑ HuggingFace + PEFT)**,
> - –¥–æ–ø—É—Å–∫–∞–µ—Ç –ø–æ—Å—Ç-–æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑:
>  - LoRA (–Ω–∞ attention/MLP),
>  - Adapters,
>  - Output-head tuning (—á–µ—Ä–µ–∑ PEFT),
>  - Prompt tuning (–º–µ–Ω—å—à–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –Ω–∞ token level),
> - **–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ —ç–Ω–∫–æ–¥–∏–Ω–≥–∏ (RoPE)** –º–æ–∂–Ω–æ –¥–æ–æ–±—É—á–∞—Ç—å —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π RoPE tuning.
> 
> ---
> 
> ## üìå –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥:
> 
> > **–î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ –≤—ã–±–æ—Ä–∞ —Ç–æ–∫–µ–Ω–∞ ‚Äî 
> –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã:**
> >
> > - **LoRA –Ω–∞ attention –∏ FFN —Å–ª–æ—è—Ö** (–æ—Å–æ–±–µ–Ω–Ω–æ –Ω–∞ —Ä–∞–Ω–Ω–∏—Ö —É—Ä–æ–≤–Ω—è—Ö),
> > - **–¥–æ–æ–±—É—á–µ–Ω–∏–µ output head** (–µ—Å–ª–∏ —Ö–æ—á–µ—à—å —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏–∫—É –≤—ã–±–æ—Ä–∞),
> > - **–∞–¥–∞–ø—Ç–µ—Ä—ã**, –µ—Å–ª–∏ –Ω—É–∂–µ–Ω –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É –º–æ—â–Ω–æ—Å—Ç—å—é –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å—é.
> 
> –î–ª—è Qwen3:
> - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `Qwen3 + LoRA + PEFT + bit precision`,
> - –∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ **—Ç–µ —Å–ª–æ–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤–ª–∏—è—é—Ç –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–∫–µ–Ω–æ–≤**, 
>  –æ—Å–æ–±–µ–Ω–Ω–æ early attention.
> 
> ---
> 
> –•–æ—á–µ—à—å ‚Äî –º–æ–≥—É —Å–æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞—Ä—Ç—É, –≤ –∫–∞–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö (–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, reasoning, completion) –∫–∞–∫–∞—è —Ç–æ—á–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è –¥–∞—ë—Ç –º–∞–∫—Å–∏–º—É–º —ç—Ñ—Ñ–µ–∫—Ç–∞ –ø—Ä–∏ –º–∏–Ω–∏–º—É–º–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
<!-- UID: defb3521-9973-4c62-95fb-3f618c7203ea -->