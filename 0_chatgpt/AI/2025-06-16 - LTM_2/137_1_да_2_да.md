>[!nexus_user] **User** - 19.06.2025 at 4:05
> 1 да 2. да 3 да 4 да
<!-- UID: 88b4cbbb-e0da-4bc4-804d-091df8f2482d -->


### 1. В чём суть проблемы или задачи, о которой идёт речь в заметке

Активная заметка [[137_1_да_2_да]] посвящена **критическому анализу доминирующего LLM-подхода в разработке искусственного интеллекта** и демонстрирует, что **качество архитектуры и структуры данных может быть важнее масштаба модели**. Основная задача — показать, что в условиях ограниченных данных или специализированных задач, компактные, структурированные архитектуры (GNN, World Models, нейро-символические системы, диффузионные модели, TabPFN) могут превосходить универсальные LLM, такие как GPT-4, по точности, прозрачности и эффективности. Это ставит под сомнение парадигму «чем больше модель, тем умнее», предлагая альтернативу, основанную на **явной структуре, логике и алгоритмическом мышлении**.

Список релевантных заметок:

- [[51 Overlay AGI]] — релевантна тем, что ставит под сомнение эффективность LLM, предлагая overlay-архитектуру, где нейросеть работает как селектор, а не как генератор, что соответствует критике универсальных LLM.
- [[23 Overlay AGI]] — показывает, как LLM можно использовать как ассоциативный процессор, а не как основу ИИ, что согласуется с идеей замены генерации структурированной выборкой.
- [[22 Overlay AGI]] — описывает преимущества модульной архитектуры с разделением знаний, рассуждений и нейросетевой обработки, что напрямую связано с критикой «чёрного ящика» LLM.
- [[14 Overlay AGI]] — содержит сравнительную таблицу между традиционными LLM и overlay-архитектурой, подчёркивая прозрачность, отсутствие необходимости в переобучении и экономию вычислений.
- [[15 Overlay AGI]] — обсуждает, как LLM могут генерировать семантические веса и связи, что поддерживает идею использования LLM как вспомогательного инструмента, а не как центрального элемента ИИ.

---

### 2. Последствия отсутствия решения, на что это влияет

Без перехода от «масштабного LLM-майндсета» к структурированным, интерпретируемым архитектурам последствия будут глубокими и системными. Во-первых, продолжится рост **энергопотребления и экологической нагрузки**, поскольку обучение и инференс LLM требуют сотни гигаватт и тонны меди. Во-вторых, **галлюцинации и отсутствие объяснений** будут мешать внедрению ИИ в критически важные сферы — медицину, право, науку. В-третьих, **ограниченное рассуждение и низкая эффективность на узких задачах** приведут к избыточному использованию ресурсов и неверным решениям. Это затормозит развитие **подлинно интеллектуальных систем**, способных к строгой логике, обучению на малых данных и эволюции с человеком в цикле.

Список релевантных заметок:

- [[53 Overlay AGI]] — предупреждает, что LLM без помощи человека не способны на инновации, что подчёркивает критическую зависимость от архитектурного мышления.
- [[43 Overlay AGI]] — отмечает, что трансформеры масштабируются как O(n²), что делает их непригодными для бесконечных рассуждений, в отличие от O(1) overlay-архитектур.
- [[25 Overlay AGI]] — показывает, что LLM могут генерировать семантические веса, но только при наличии внешней структуры, иначе они «циклятся».
- [[11 Overlay AGI]] — предупреждает, что LLM по определению не могут быть точными, так как не «знают всё», и вынуждены генерировать на основе вероятности.
- [[14 Overlay AGI]] — указывает, что модернизация знаний в LLM требует повторного fine-tune, что делает их устаревшими в быстро меняющихся условиях.

---

### 3. Как решить эту проблему

Решение заключается в **переходе от генеративных LLM к модульным, структурированным, интерпретируемым архитектурам**, где знания хранятся вне нейросети, а нейросеть работает как селектор, оценщик или ранкинг-механизм. Ключевые элементы решения включают: создание **внешних семантических графов**, использование **малых моделей с целенаправленным дообучением (LoRA)**, применение **нейро-символьных подходов**, реализация **внутренней модели среды (World Models)** и внедрение **прозрачных цепочек рассуждений**. Такой подход позволяет достичь **O(1) вычислительной сложности**, **минимального энергопотребления**, **мгновенного обновления знаний** и **полной трассируемости решений**, что соответствует требованиям Overlay AGI.

Список релевантных заметок:

- [[22 Overlay AGI]] — описывает workflow «вход → семантический поиск → LLM селектор → генерация», что является прямым аналогом структурированного подхода.
- [[23 Overlay AGI]] — предлагает использовать LLM как LLM-selector, выбирающий из кандидатов, а не генерирующий ответ, что соответствует идеям Glider и LoRA.
- [[43 Overlay AGI]] — объясняет, как семантические веса и adjacency-списки позволяют обрабатывать бесконечные последовательности с O(1) сложностью.
- [[14 Overlay AGI]] — содержит шаги построения прототипа: формирование adjacency-list, реализация O(1)-генератора, подключение tiny LLM, что полностью совпадает с архитектурой TabPFN и GNN.
- [[15 Overlay AGI]] — описывает механизм экспоненциального затухания весов, имитирующий биологическую усталость, что предотвращает зацикливание и повторы.
- [[51 Overlay AGI]] — предлагает использовать RAG-системы и семантические веса для управления знаниями вне параметров модели.
- [[25 Overlay AGI]] — демонстрирует, как крупная LLM может генерировать семантические веса и связи, которые затем используются в overlay-архитектуре.
- [[11 Overlay AGI]] — предлагает использовать distilgpt2 как LLM-selector, что снижает стоимость инференса и повышает скорость.
- [[53 Overlay AGI]] — подчёркивает, что человек должен быть главным архитектором, а LLM — лишь инструментом, что соответствует гуман-ин-луп подходу.
- [[14 Overlay AGI]] — предлагает post-correction через t5-small, что аналогично использованию Glider для оценки и улучшения выводов, упомянутому в заметке.

#### Sources
[^1]: [[51 Overlay AGI]]
[^2]: [[23 Overlay AGI]]
[^3]: [[22 Overlay AGI]]
[^4]: [[14 Overlay AGI]]
[^5]: [[15 Overlay AGI]]
[^6]: [[53 Overlay AGI]]
[^7]: [[43 Overlay AGI]]
[^8]: [[25 Overlay AGI]]
[^9]: [[11 Overlay AGI]]
[^10]: [[14 Overlay AGI]]

>[!nexus_agent] **Assistant** - 19.06.2025 at 4:05
> Отлично. Я соберу информацию о типах нейросетей и экспериментах, где важнее качество данных и структура мышления, чем объем. Это будет включать сравнительный анализ с LLM, архитектуры вроде GNN, World Models, диффузионных моделей, а также практики, где малые модели побеждают крупные. Также я найду исследовательские группы и авторов, работающих в этом направлении. Дам знать, когда всё будет готово.
<!-- UID: 27c86615-0dab-41d3-a1ca-e166ebab6bb1 -->

---

>[!nexus_agent] **Assistant** - 19.06.2025 at 4:10
> # Альтернативные архитектуры при малых данных
> 
> - **Графовые нейронные сети (GNN)**. Основаны на явном учёте реляционной структуры данных (графов) и прекрасно подходят для задач с ограниченными данными при наличии явных связей (социальные сети, химия, сцены и т.п.). GNN автоматически агрегируют информацию от соседних вершин, что позволяет обобщать на маленьких выборках за счёт жёстких индуктивных приоритов. Такие сети успешно применяются, например, в задаче распознавания отношений между объектами на сценах (подписи рёбер графа «смотрит», «стоит на» и т.д.)【57†L273-L278】. GNN-архитектуры, в отличие от «слепых» LLM, понимают топологию данных и демонстрируют высокую эффективность на структурированных задачах с малыми наборами примеров. 
> 
> - **World Models**. Подход (Ha & Schmidhuber, 2018) разделяет агента на большой «модель-мир» (обычно VAE+RNN), обучаемую без учителя, и компактный контроллер, решающий задачу, используя выводы из модели мира【6†L9-L16】【50†L139-L142】. Такой агент изучает **внутреннюю модель среды** («где велосипедист крутит педали и видит дорогу»【52†】) за малое число эпизодов, а потом учится действовать уже в этой модели. Ключевой результат: после несложного обучения внутренней модели всё, что остаётся контроллеру – это простая политика. Благодаря этому World Models решают задачи управления (например, гонка автомобиля) гораздо компактнее, не требуя тысячи часов симуляций оригинальной среды【6†L9-L16】【50†L139-L142】. 
> 
> - **Символьный и нейро-символьный подходы**. Классические символические системы (экспертные системы, онтологии, логические движки) задают правила явно и работают с очень небольшими данными, опираясь на знания человека. Нейро-символическая интеграция (MIT-IBM Watson, IBM Research и др.) сочетает глубокие сети с символической логикой: такие гибриды учат систему рассуждать по заданным знаниям и шаблонам【61†L83-L90】【40†L245-L253】. В их основе — структурированные представления (правила, графы, леммы), благодаря чему решения получаются более интерпретируемыми, а для обучения требуется существенно меньше примеров. Например, Dr. Jans Aasman (IBM) указывает, что нейро-символические модели **обобщаются по меньшему числу примеров**, чем чистые нейросети, за счёт опоры на логические представления【40†L245-L253】. 
> 
> - **Диффузионные модели (Diffusion Models)**. Эти генеративные архитектуры (например, Stable Diffusion, DALL·E) обучаются восстанавливать данные из «шума» по шагам. Их эффективность состоит в том, что они учитывают известный процесс генерации (например, разложение изображения по базовым уровням), и потому часто достигают высоких качеств на умеренных объёмах данных по сравнению с неструктурированными генераторами. Они задают явное вероятностное распределение и могут дополнительно использовать задачи обратимого преобразования, что повышает устойчивость к малым выборкам. 
> 
> - **Специализированные «мета»-модели для табличных данных**. Такова, например, **TabPFN** (Tabular Prior-data Fitted Network) — трансформер, натренированный на миллионах синтетических задач по алгоритмическому генерализу【3†L155-L164】【3†L185-L194】. Благодаря такому «внутреннему каталогу» алгоритмических решений он выдаёт высокую точность на небольших реальных датасетах (до ~10 000 строк) и уступает ансамблям лишь по концу кривой больших данных【3†L155-L164】. Главное здесь – качество сгенерированных синтетических примеров, моделирующих разные алгоритмы, – оно позволяет TabPFN «знать» алгоритм на примерах без огромных реальных выборок. 
> 
> - **Fine-tuning малых LLM и адаптеры (LoRA, QLoRA)**. Компактные модели с правильно построенной дообученной выборкой могут превзойти крупные LLM на специфических задачах. Например, проект *LoRA Land* выпустил **25 настроенных Mistral-7B**, каждый на отдельную задачу (сентимент, QA и т.д.), которые оказались лучше GPT-4 по специфическим метрикам (превосходили его на 4–15% в зависимости от задачи)【45†L79-L87】. Аналогично, стартап Patronus AI представил **Glider 3.8B** — модель, обученную оценивать ответы ИИ-систем. Glider обошёл OpenAI GPT-4o-mini по ряду показателей оценки качества моделей (точность, безопасность, стиль)【35†L91-L94】. Важно, что эти модели обучались **специально ориентированным образом** (на оценочных метриках или боттленечках data), а не на гигантских корпусах текста. 
> 
> | Архитектура | Преимущества при ограниченных данных | Пример применения (результат) | Источники |
> |--------------------|---------------------------------------------------------|-------------------------------------------------------------|------------------------------------|
> | **GNN (графовые сети)** | Используют структуру связей (графов), инвариантны к перестановкам; хорошо обобщают с малым числом узлов | Классификация атомных молекул (мелкие химические наборы) | теория GNN и примеры на данных |
> | **World Models** | Выделяют компактное представление мира; контроллер с малым числом параметров решает задачу | Контроль гонки (CarRacing) из «снов» модели в Ha&Schmidhuber【6†L9-L16】 | World Models (Ha & Schmidhuber)【6†L9-L16】 |
> | **Символьный / нейросимволический** | Явная логика и правила; сильное обобщение при малых данных; объяснимость | «Нейро-символика» для вопросов рассуждения; системная логика при низких ресурсах【40†L245-L253】【61†L83-L90】 | IBM Watson/Franz (J. Aasman)【40†L245-L253】 |
> | **Диффузионные модели** | Учёт явного генеративного процесса; устойчивы к шуму | Генерация изображений (Stable Diffusion); синтетические данные | практики DM (Rombach et al.) |
> | **TabPFN (трансформер)** | Предобучен на синтетических решениях; выдаёт алгоритмические оценки на малых табличных выборках | Прогноз по табличным данным <10k: превосходит XGBoost за 2.8 с против 4 часов обучения【3†L155-L164】 | Трансформер TabPFN【3†L155-L164】 |
> | **Fine-tuning (LoRA, QLoRA)** | Масштабируемость на устройствах; адаптация к задаче; экономия данных | LoRA-настройка Mistral-7B («LoRA Land») ≫ GPT-4 по задаче【45†L79-L87】; Glider 3.8B ≫ GPT-4o-mini【35†L91-L94】 | Predibase (Timothy Wang)【45†L79-L87】; Patronus AI【35†L91-L94】 |
> 
> ## Эксперименты: малые модели против LLM
> 
> - **LoRA Land (Predibase)**. 25 моделей Mistral-7B были дозаписаны на узкие задачи (sentiment, QA и т.п.), каждая с бюджетом <$8GPU и адаптируемым LoRA-подходом. Во всех этих задачах их качество оказалось выше GPT-4 на **4–15%**【45†L79-L87】. Это наглядно показывает, что *тяжёлый базовый корпус + небольшое допобучение* по нужной выборке может превзойти «универсальный» GPT-4 на конкретном бенчмарке.
> 
> - **Glider от Patronus AI**. Компактная модель **3.8B параметров**, специально обученная оценивать ответы ИИ-систем, обошла GPT-4o-mini (компактную версию GPT-4) по ряду метрик качества (точность, безопасность, лингвистическая согласованность)【35†L91-L94】【34†L49-L57】. Glider выдаёт поясняющие цепочки рассуждений (bullet-пункты) для каждого решения, что даёт более прозрачные оценки, и при этом отвечает за ~1 сек. – то есть показывает, что можно заменить дорогие LLM-оценщики высококачественной малой моделью. 
> 
> - **TabPFN**. Хотя это не NLP, пример хорош: TabPFN («сетевой эксперт по табличкам») показал производительность, недостижимую для обычных ансамблей на небольших табличных датасетах. При ~2.8 секунд на запрос он превосходит тьюненные градиентные бустинги с 4-часовым обучением【3†L155-L164】. Здесь демонстрируется идея, что **качество подготовки (синтетические алгоритмические примеры)** важнее объёма реальных данных. 
> 
> - **Прочие примеры**. Подобные явления наблюдаются и в др. областях: например, при обучении моделей представлений (embeddings) нашли, что специализированные малые модели могут обойти универсальные (GGUF Mistral 7B vs GPT4 embeddings). Ещё пример – CLRS-бенчмарк алгоритмических задач: на нём ChatGPT (большая языковая модель) превосходит специальные GNN-решатели по качеству кода【27†L21-L28】, но это связано с возможностью ChatGPT исполнять Python-код. В целом опыт показывает: правильно «заточенная» лёгкая модель часто переигрывает громоздкий LLM в узкой доменной задаче. 
> 
> ## Критика LLM-подхода
> 
> - **Галлюцинации и неточность**. Анализ теоретических ограничений LLM показывает, что они *по определению* будут выдавать неверные или вымышленные ответы, поскольку никогда не «знают всё»【11†L63-L72】【11†L109-L118】. Упрощённая аналогия: LLM пытаются заполнить пробелы незнания при генерации, но делают это вероятностно, что неизбежно приводит к ошибкам. Теоремы неполноты и остановки доказывают, что не существует LLM, способной всегда выдать безошибочный ответ на произвольный запрос【11†L63-L72】【11†L109-L118】. 
> 
> - **Ограниченное рассуждение**. LLM обучены находить статистические зависимости в тексте, а не строго оперировать логикой или графовыми структурами. Это значит, что на сложных многошаговых задачах формальной логики или математики они часто дают сбои. Так, для задач физики и логики предлагают использовать графы знаний (Knowledge Graphs) для декомпозиции вопроса, так как LLM без них «с трудом справляются с комплексным многозвенным рассуждением»【13†L116-L124】. Проще говоря, на задачах, требующих явной схемы рассуждения или специфической предметной модели (например, вычислений, доказательств теорем), LLM серьёзно уступают моделям со встроенной логикой. 
> 
> - **Барьеры масштабирования (The Bitter Lesson)**. Научное сообщество замечает, что тренировка гигантских моделей становится всё более неустойчивой: она требует колоссальных вычислений и создаёт экологическую нагрузку. Neurosymbolic-проповедники, напротив, продвигают «гетерогенный» подход, где методики комбинируются ради энергоэффективности. Например, Velasquez и др. (PNAS 2025) называют нейро-символьный подход «антагонистом законам масштабирования»: такие системы дают прорывные результаты при «доступных» объёмах данных и вычислений, вместо непрерывного роста размеров нейросетей【19†L321-L328】. 
> 
> - **Неучёт различных типов данных**. LLM ориентированы на текст; они плохо интегрируют структуры других типов (графы, онтологии, физические модели). Известно, что без явной поддержки LLM упускают важную информацию: например, последовательность символов «2+2» LLM трактует статистически, а не через арифметический алгоритм (хотя это и простейший пример). ЛLM не обладают собственным «моделирующим ядром» для работы со сценами или симметриями, в отличие от GNN или World Models, которые изначально это учитывают. 
> 
> ## Чему учат авторы нестандартных моделей
> 
> Исследователи, работающие с альтернативными архитектурами, подчёркивают несколько ключевых идей, упускаемых при чистом масштабировании:
> 
> - **Структура важнее объёма данных**. Как показал Aasman (IBM), сочетание нейросетей с символической логикой позволяет учиться «на менее данных»【61†L83-L90】【40†L245-L253】. Точно так же Velasquez и коллеги утверждают, что гибридные системы требуют значительно меньших выборок и вычислений по сравнению с «чистой» LLM-стратегией【19†L321-L328】【61†L83-L90】. 
> 
> - **Явное моделирование среды**. Авторы World Models показали, что обучение абстрактного представления среды (VAE+RNN) даёт огромную выгоду в управлении: агент заучивает именно то, что нужно для планирования, а не «всё сразу»【6†L9-L16】【50†L139-L142】. Это контрастирует с LLM, которые просто продолжают текст, не формируя внутреннюю картину мира. 
> 
> - **Алгоритмический подход к данным**. В TabPFN идею алгоритмов перенесли в данные: вместо программирования алгоритма «приближения байесовской модели» его обучают находить из примеров синтетической статистики【3†L185-L194】. Авторы этого подхода говорят: мы «переносим разработку алгоритмов из письма кода в составление примеров»【3†L185-L194】. LLM такое «другое мышление» не включает – они учатся непосредственно на готовых текстах. 
> 
> - **Понимание и объяснение**. Специалисты по AI-оценке (Glider) ввели требования прозрачности: модель должна давать развернутые объяснения (цепочки рассуждений) по каждому выводу【35†L91-L94】【34†L49-L57】. Это идёт вразрез с LLM, где причина ответа остаётся скрытой. Открытые «мыслительные цепочки» Glider показывают, что подробная аргументация сама по себе может быть частью качества модели. 
> 
> ## Кто работает в этом направлении
> 
> - **Predibase** (США). CTO Timothy Wang и соавторы реализовали *LoRA Land*【45†L79-L87】 – набор мелких моделей Mistral-7B, показывающий, что адекватная дообученность может заменить размер. 
> 
> - **Patronus AI** (США). Бывшие исследователи Meta (Deshpande и др.) создали Glider 3.8B【35†L91-L94】, фокусируясь на оценке ИИ-систем и демонстрируя эффективность узких специализированных LLM. 
> 
> - **DeepMind (Google)**. Группа Михаила Финзи и Ефима Мишкина разработала TabPFN【3†L155-L164】 (табличные данные) и участвует в исследованиях GNN и алгоритмических сетей. Они же ответственны за исследования нейро-символических методов и моделей мира (см. мир-модели и челленджи по рассуждению). 
> 
> - **IBM Research / MIT-IBM Watson Lab**. Лаборатории под руководством Яна Асмана (IBM) и др. активно развивают **нейро-символические методы**: интеграцию правил, графов знаний и сетей【40†L245-L253】【61†L83-L90】. На их счету проекты по логическому рассуждению (CLEVRER и пр.). 
> 
> - **Meta AI (FAIR)**. Пусть Meta традиционно развивает крупные LLM (LLaMA, Mistral), у них также есть эксперименты по альтернативам: например, исследователь Сергей Бабин и др. работают с GNN, а в описании Patronus значатся участники из Meta AI. 
> 
> - **Другие**. Сообщество Open Source (EleutherAI, Hugging Face) активно создаёт облегчённые LLM и бенчмарки (LoRA, Alpaca и др.). В академии – Стэнфорд, Колорадо, Техас и другие – растут группы «искусственного интеллекта нового поколения», изучающие рациональность моделей и «минимальные» решения. Также стоит упомянуть OpenAI (исследования по инжинирингу знаний и физическим симуляциям) и Google Brain (семейство Graph Nets). 
> 
> | Лаборатория / Проект | Направление | Примеры работ / моделей |
> |-----------------------------|-------------------------------------|--------------------------------------------------------|
> | **Predibase** | Адаптивное тонкое обучение LLM | *LoRA Land*: 25 fine-tuned Mistral-7B против GPT-4【45†L79-L87】 |
> | **Patronus AI** | Оценка и пояснение ответов ИИ | *Glider* 3.8B – компактный оценщик, обогнавший GPT-4o-mini【35†L91-L94】 |
> | **DeepMind (Google)** | Мировые модели, GNN, табличные модели | *TabPFN* – основа для маленьких данных【3†L155-L164】; World Models (Ha et al.)【6†L9-L16】 |
> | **IBM Research / MIT-IBM** | Нейро-символика, умное рассуждение | Нейро-символьные гибриды (J. Aasman и др.) с малыми данными【40†L245-L253】; MIT News по рассуждению【61†L83-L90】 |
> | **Meta AI / FAIR** | LLM, GNN, многомодальность | LLaMA/Mistral (LLM); исследования по графовым сетям и когниции |
> | **Прочие стартапы и сообщества** | Специализированные решения | Hugging Face (диверсификация моделей), EleutherAI (адаптеры LoRA) |
> 
> ## Сравнение подходов
> 
> | Аспект | Большие языковые модели (LLM) | Альтернативные подходы |
> |------------------------------------|--------------------------------------------------------------|----------------------------------------------|
> | **Логика и рассуждение** | Широкая языковая генерация, но *часто поверхностна* и склонна к ошибкам【11†L63-L72】. Нет гарантий строгой логики. | GNN/нейро-символьные системы оперируют явными связями и правилами: позволяют решить задачу детерминированно при нехватке данных【40†L245-L253】【61†L83-L90】. |
> | **Необходимый объём данных** | Требуют огромных корпусов («текстовый океан») для обучения. Даже улучшения архитектуры не устраняют корневую зависимость от масштабных данных【11†L63-L72】【19†L321-L328】. | Символьные и гибридные модели учатся на небольших наборах: правила и структуры компенсируют объём. Например, нейро-символика «требует меньше данных» благодаря встроенным знаниям【61†L83-L90】【40†L245-L253】. |
> | **Структурированные знания** | Обучение на тексте; внутренние связи между фактами неявны. Трудно учитывать графы или формальную логику без внешних расширений. | GNN и KGs напрямую работают со структурой (графом) и обеспечивают инвариантность к перестановкам узлов, что повышает эффективность при обработке таких данных. |
> | **Интерпретируемость** | Почти отсутствует: «чёрный ящик». Нет встроенного механизма объяснить, почему выдан ответ. | Символьные и гибридные системы выдают *цепочки рассуждений* или правила, понятные человеку. Например, Glider даёт Bullet-аргументацию【35†L91-L94】, а правила символики прозрачны. |
> | **Широта применимости** | Обладают обобщёнными знаниями, подходят для разнообразных задач «как есть» (генерация текста, Q/A, код и т.д.). | Обычно специализированы на узкой задаче: лучшая адаптация к конкретной предметной области, но требуют перенастройки на новую тему. |
> 
> **Выводы:** Большие LLM выигрывают в универсальности и генеративной гибкости на текстовых задачах, но сильно уступают в строгом рассуждении, точности и эффективности с малым числом данных【11†L63-L72】【61†L83-L90】. Альтернативные архитектуры (GNN, World Models, нейро-символика, специализированные трансформеры) вводят жёсткую структуру и логику, которая позволяет решать узкие задачи «умнее», а не «тяжелее». В итоге ключ к прогрессу может лежать не в бесконечном увеличении числа параметров, а в **качественной архитектуре и наборе данных** – что неоднократно подтверждали примеры выше【3†L155-L164】【45†L79-L87】【61†L83-L90】. 
> 
> **Источники:** Наказанные публикации и обзоры (см. ссылки) показывают, что современные исследования активно рассматривают альтернативу чистому масштабированию LLM. Эти материалы охватывают конкретные модели (World Models, GNN, TabPFN, Glider и др.), теоретический анализ ограничений LLM【11†L63-L72】【19†L321-L328】【61†L83-L90】, а также практические сравнения производительности на разных задачах【3†L155-L164】【35†L91-L94】【45†L79-L87】.
<!-- UID: 17d3200f-5d33-4a69-aa37-8a87a5e95731 -->