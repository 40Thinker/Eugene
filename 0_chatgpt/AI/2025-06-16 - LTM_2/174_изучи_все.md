>[!nexus_user] **User** - 21.06.2025 at 8:38
> изучи все
<!-- UID: 7b17941b-ee34-4e71-a630-b35663567607 -->




>[!nexus_agent] **Assistant** - 21.06.2025 at 8:39
> Хорошо. Я изучу существующие эксперименты с LoRA-дообучением моделей на разных типах текстов — книг, форматов (JSON, YAML, markdown, plain text), и оценку их влияния на мышление и качество модели.
> 
> Также постараюсь найти:
> - работы с рейтингами влияния книг и текстов;
> - примеры автоматизированной оценки качества мышления после дообучения;
> - кейсы сравнения LoRA с обучением модели с нуля на малых объёмах.
> 
> Сообщу, как только результаты будут готовы.
<!-- UID: 0aa63cf8-ffea-478c-b280-f1ec65374e32 -->

---

>[!nexus_agent] **Assistant** - 21.06.2025 at 8:43
> # LoRA-дообучение LLM на разных данных
> 
> ## Влияние содержания и домена текста 
> Опыт показывает, что **доменные и жанровые тексты** задают разные навыки модели. Так, дообучение на **художественной литературе** (например, корпус произведений из Gutenberg) позволяет модели лучше генерировать связные повествования: в одном исследовании дообученный Mistral-7B (с помощью LoRA) генерировал длинные фанфики с понятной начальной и конечной частью и явной сюжетной дугой【69†L325-L333】. Напротив, для **научных текстов** обычно лучше подходят специализированные модели: например, SciBERT (предобученный на научных статьях) заметно превосходит общие модели на задачах классификации научных текстов【65†L75-L83】. 
> Аннотации и разметка данных (опрос-ответ, инструкции) также критичны: дообучение на текстах, преобразованных в вопросы-ответы или инструкции, дает лучшие результаты, чем на «сырая» литература【23†L679-L685】【62†L1-L4】. Например, при адаптации модели к предметной области тексты сначала переводили в пары «вопрос‑ответ» или «инструкция‑результат», и оказалось, что это повышало качество обучения и обобщения, тогда как простой неструктурированный текст (с ошибками распознавания PDF) ухудшал результаты【23†L679-L685】【62†L1-L4】.
> 
> ## Форматы представления данных 
> Формат подачи текста существенно влияет на эффективность дообучения. Рекомендовано экспериментировать с разными структурами (Markdown, YAML, JSON и т.д.) под задачу: например, при классификации полезно отделять вход и метку специальными токенами【58†L240-L249】. Из отчетов видно, что данные в **структурированном виде** (инструкции, JSON/YAML с полями вопроса и ответа) часто улучшают обучение по сравнению с неразмеченным текстом【58†L240-L249】【62†L1-L4】. В частности, дообучение на одних и тех же текстах в виде инструкций или markdown-промптов дало более точные модели, чем на том же сыром тексте: «инструктированные» форматы помогают модели лучше выучить связи между частями текста【23†L679-L685】【62†L1-L4】. В целом, чистота и структура (например, отсутствие артефактов OCR) также важны: дополнительная порция «грязного» текста (с ошибками) может ухудшить результаты CPT дообучения【23†L67-L75】.
> 
> ## Выгода в качестве генерации и reasoning 
> Разные наборы текстов по-разному влияют на способности модели. Исследования показывают, что **низкоперплексные (LLM-генерированные) данные** ведут к более стабильному дообучению: LLM-сгенерированные ответы (средний перплексити≈1.2) приводят к значительно меньшей неопределённости и меньшим изменениям в весах модели по сравнению с реальными ответами (средний перплексити≈4.8)【72†L13-L17】【73†L1-L5】. Менее изменяются веса LoRA-адаптеров (низкий L2-норм) при низком перплексити данных【73†L1-L5】, то есть модель «сохраняет» предыдущие знания лучше, если тренировать на «привычном» по языку материале. 
> Что касается **логического мышления и CoT**, есть нюансы: например, эксперименты с QLoRA показали, что дообучение зачастую снижает качество chain-of-thought-размышлений. В среднем после fine-tuning модель хуже решает задачи рассуждения, особенно небольшие модели; у больших же (GPT-4) снижение Faithfulness невелико【47†L1-L4】【47†L7-L10】. Иными словами, узкоспециализированные датасеты могут улучшить ответы по предмету, но ослабить общие рассуждения модели. Наконец, при объединении (model merging) дообученных LoRA-моделей часто появляются **новые эмёрджентные свойства**: «слиянный» суперсет может выдавать возможности, отсутствовавшие у его составляющих【74†L37-L40】. Например, было показано, что интерполяция параметров разных LoRA-адаптеров (SLERP) приводит к модели с новыми улучшениями, которых не было у исходных моделей【74†L37-L40】.
> 
> ## Метрики и ранжирование обучающих данных 
> Для отбора или оценки «качественности» текстов предлагают разные метрики. Недавняя работа *Superfiltering* использует **перплексити и оценку «инструкционной сложности» (Instruction-Following Difficulty, IFD)** для оценки примеров. Оказалось, что даже слабая модель (GPT-2) одинаково с большой (LLaMA2-7B) ранжирует примеры по этим метрикам – ранжирование трудности инструкций и перплексити коррелирует сильно для моделей разного размера【78†L139-L148】. То есть малые модели могут отсеивать наиболее «важные» обучающие примеры по этим скорорам, что позволяет резко сократить объём данных без потери качества. В целом, хорошие практики включают: фильтрацию «шумных» данных (нордик/латинские символы, неверное кодирование), и использование оценок автоматических моделей (например, GPT-семейства) для оценки релевантности и сложности примеров【78†L139-L148】【62†L1-L4】.
> 
> ## LoRA vs обучение с нуля на малом наборе данных 
> Все обзоры сходятся: при ограниченных данных (специализированная или маломасштабная задача) **дообучение (в том числе LoRA)** почти всегда предпочтительнее обучения с нуля【38†L720-L724】【58†L318-L324】. Так, авторы практического руководства отмечают: «если ваш датасет мал или специализирован, обычно лучше сделать fine-tuning, а не обучение с нуля»【38†L720-L724】. LoRA при этом даёт результаты, сопоставимые с полным fine-tuning на многих задачах【52†L115-L124】, и помогает избежать переобучения на малых датасетах【52†L115-L124】. Однако у LoRA есть пределы – на «трудных» задачах (например, генерация кода или длинный творческий текст) LoRA-инструменты иногда отстают от полного fine-tuning【56†L93-L101】. 
> 
> **Выводы:** Параметрически эффективное дообучение LoRA показывает высокую адаптивность, но ключевую роль играет выбор корпуса: тексты с низким перплексити и структурированным представлением (инструкции, Q&A) дают лучшие результаты с точки зрения стабильности и сохранения общих способностей модели【72†L13-L17】【23†L679-L685】, а разные домены («художественный», научный, диалоговый) вносят свою специфику в тренировку. Одновременно недавние исследования предлагают использовать метрики перплексити и «сложности инструкций» для ранжирования примеров и фильтрации набора данных【78†L139-L148】. При очень малом объёме данных обучение с нуля обычно неэффективно – предпочтительнее дообучение на предобученной модели【38†L720-L724】【58†L318-L324】.
> 
> **Источники:** результаты последних исследований и экспериментов по LoRA и дообучению LLM【69†L325-L333】【23†L679-L685】【47†L1-L4】【72†L13-L17】【73†L1-L5】【78†L139-L148】【56†L93-L101】.
<!-- UID: 23f65283-1241-4c45-8e03-fc73d6ac8041 -->