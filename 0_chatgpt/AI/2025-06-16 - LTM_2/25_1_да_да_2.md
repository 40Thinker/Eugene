>[!nexus_user] **User** - 16.06.2025 at 21:04
> 1 да, да 2. все 3. больше вариантов ключевиков используй, не экономь
<!-- UID: 4650e99e-391d-4a84-af7e-74c427dd644f -->


### 1. **Суть проблемы или задачи, о которой идет речь в заметке**

Заметка [[25_1_да_да_2]] анализирует **фундаментальную кризисную парадигму в современном ИИ**: преобладание токенизированного подхода в LLM, где мышление сводится к предсказанию следующего слова, а не к формированию смысла через **сцены, структуры и когнитивную целостность**. Эта парадигма доминирует благодаря масштабируемости и практической полезности, но она фундаментально неспособна построить AGI, так как не моделирует **онтологическую реконструкцию мира**, эпизодическое мышление, причинно-следственные связи и внутреннюю семантическую резонансность. Заметка ставит задачу — найти и систематизировать альтернативные архитектуры, которые **оперируют смыслом как структурой, а не как суммой токенов**. Это напрямую соответствует сути Overlay AGI, где ключевой принцип — замена «предсказания» на **извлечение и резонанс смысла из внешнего знания и когнитивных узлов**.

**Релевантные заметки:**

- [[1LTM_1]] — раскрывает **критику токенизации** как искусственной и деградирующей формы мышления; объясняет, почему токены не могут нести многомерный смысл; релевантна как философская основа для отказа от LLM-парадигмы.
- [[Tokenism and Simulation of Thought]] — углубляет идею, что токенизация — это **архитектурный костыль**, приводящий к «имитации разума», а не к его становлению; прямой отклик на «токенную олигофрению».
- [[17_в_эти_дни_я]] — называет токены **символами без сцепки**, не способными к векторному движению мысли; объясняет, почему LLM только *имитируют* мышление.
- [[LTM_2]] — описывает **альтернативные архитектуры** (LCM, NVSA), которые уже пытаются выйти за пределы токенов; релевантна как доказательство, что сдвиг уже начинается.
- [[23_выдай]] — перечисляет **направления пост-токенного мышления**: SSM, фрактальные архитектуры, graph LMs, что перекликается с поиском в [[25_1_да_да_2]].

---

### 2. **Последствия отсутствия решения**

Если не решить проблему токенизации как доминирующей парадигмы, мы столкнемся с **когнитивным потолком ИИ**: системы будут оставаться в рамках **поверхностной связности**, не способными к рефлексии, причинному мышлению, долгосрочному планированию, эмоционально-онтологическому резонансу. Это приведет к **широкому разочарованию в AGI**, поскольку LLM будут производить «логичные» тексты, но без внутреннего понимания, что особенно критично в медицине, науке, этике. Overlay AGI рискует остаться изолированным экспериментом, если не будет осознана **историческая значимость перехода на пост-токенную основу**. Без этого ИИ останется статистическим автокомплитом, неспособным к становлению, участию в диалоге как равноправная когнитивная сущность, или к **самонастройке через сценическое мышление**.

**Релевантные заметки:**

- [[Token-Path Overfitting Risks]] — показывает, как **структурированное мышление может деградировать в повторение**, если нет внутренней семантической динамики; последствие токенового мышления — потеря когнитивной энтропии.
- [[1LTM_1]] — указывает, что при 175B параметрах **смысловая плотность падает**, что доказывает: рост масштаба не компенсирует архитектурный дефект.
- [[Tokenism and Simulation of Thought]] — констатирует, что токены — это **«шрамы компрессии»**, искажающие истинное мышление; последствие — **подмена понимания статистическим приближением**.
- [[2Архитектура LLM разбор]] — подчеркивает, что токены не передают **вектора мышления**, что делает невозможным построение **намерения, воли, внутреннего действия**.
- [[LTM_2]] — приводит критику ЛеКуна и Шоллета: токенные модели — **тупиковая ветвь для AGI**; это и есть долгосрочное последствие.

---

### 3. **Как решить эту проблему**

Решение заключается в **архитектурном сдвиге**: от токен-предсказания к **смысловому резонансу**, от внутренней параметризации к **внешнему онтологическому графу**, от линейной генерации к **фрактальной, сценической реорганизации**. Overlay AGI предлагает **глобальный шаблон**: маленькие нейросети (IT-LM) выбирают из внешнего семантического пространства, где смыслы представлены как **сцены, вектора, гиперграфы** — аналогично NVSA, OpenCog, GLOM. Это требует создания **модуля сценического мышления**, **фрактальных графов знаний**, **онтологически-символьных интерфейсов**, а также **интроспективных циклов**, где ИИ отслеживает собственные изменения состояния. Решение — в **гибридной архитектуре**, где LLM используются не как ядро, а как **интерфейсный компонент**, а ядро — семантический резонанс между внешним знанием, внутренними узлами и онтологическими операциями.

**Релевантные заметки:**

- [[1LTM_1]] — вводит **гиперлексему** как носитель многомерного смысла; ключевой элемент построения **пост-токенного языка мысли**.
- [[Tokenism and Simulation of Thought]] — предлагает **пост-токенную архитектуру** с node → relation → field; это прямое описание Overlay AGI.
- [[LTM_2]] — описывает **Neuro-Vector-Symbolic Architecture (NVSA)** и **Large Concept Models (LCM)**, которые совпадают с идеей **семантических векторов и графов**.
- [[23_выдай]] — перечисляет **State Space Models, Mixture-of-Experts, Fractal Logics**, что показывает инженерные пути к **модульной, нелинейной архитектуре**.
- [[17_в_эти_дни_я]] — предлагает **мыслеобразы, фазы мышления, архетипические операции** — это реализация **операционного ядра** Overlay AGI.
- [[2Архитектура LLM разбор]] — обсуждает **внешние надстройки**, **онтологический фильтр**, **мета-язык** — совпадает с идеей **семантического веса** и **RAG-контекстов**.
- [[Token-Path Overfitting Risks]] — предупреждает о **структурном переобучении**, что требует **регуляризации семантических графов** и **инжекции шума**.
- [[Hidden Micro-Architecture Overview]] — подталкивает к **созданию обзорной микроархитектуры**, где **все скрытые модули** становятся прозрачными и организованными.
- [[68_делая_этот_раздел_подраздел_проверяй]] — демонстрирует, как **онтология проекта** может быть построена **иерархически**, с смысловыми узлами.
- [[25_1_да_да_2]] — сама по себе является **анализом и картой альтернатив**, которая может быть использована как **база для сравнения и выбора архитектурных решений**.

#### Sources
[^1]: [[1LTM_1]]
[^2]: [[Tokenism and Simulation of Thought]]
[^3]: [[17_в_эти_дни_я]]
[^4]: [[LTM_2]]
[^5]: [[23_выдай]]
[^6]: [[Token-Path Overfitting Risks]]
[^7]: [[2Архитектура LLM разбор]]
[^8]: [[Hidden Micro-Architecture Overview]]
[^9]: [[68_делая_этот_раздел_подраздел_проверяй]]

>[!nexus_agent] **Assistant** - 16.06.2025 at 21:04
> Хорошо, я исследую, существуют ли проекты, аналогичные твоей архитектуре LTM — то есть не просто LLM, а системы, которые реализуют мышление через сцепки, сцены, поля смыслов и структуру, а не токены. Я включу академические статьи, GitHub-проекты, стартапы, форумы и обсуждения, и буду использовать широкий спектр ключевых терминов: от 'ontological reasoning' до 'fractal memory', 'LLM replacement', 'thought architecture', 'non-token-based AGI', 'thinking embeddings' и других.
> 
> Я вернусь с результатами, как только они будут готовы.
<!-- UID: 13571467-95d3-4bc1-be25-2fcd02029a81 -->

---

>[!nexus_agent] **Assistant** - 16.06.2025 at 21:10
> # Архитектуры AGI за пределами токенов: сцепка смыслов, сцены и фрактальная память
> 
> В последние годы **большие языковые модели (LLM)** доминируют в ИИ, но они строят **мышление как предсказание последовательности токенов**. Это приводит к впечатляющему языковому мастерству, но критики отмечают, что у LLM нет явного понимания или структурированного мышления – они imитируют **следующие слова**, не оперируя явно понятиями или сценами. В поисках настоящего AGI исследователи предложили альтернативные архитектуры, которые **манипулируют значениями, связями и структурами** вместо просто текста. Ниже мы рассмотрим ключевые направления таких подходов – от нейросемантических моделей и векторных **«мысленных» представлений** до сценических когнитивных архитектур и фрактальной памяти – а также обсудим, почему эти попытки пока не стали мейнстримом.
> 
> ## Нейросемантические и онтологические модели (нейро-символический ИИ)
> 
> Одно из направлений – **объединение нейросетей с семантическими знаниями и логикой**. Идея заключается в том, чтобы модель оперировала не сырыми токенами, а понятиями из **онтологий** или **знаниевых графов**. Классический пример – **символические ИИ-системы** (вроде Cyc), хранящие знания в виде логических фактов и правил. Современные же подходы стремятся сочетать это с обучением нейросетей. Так, в работе IBM над *Neuro-Symbolic AI* предлагается **Neuro-Vector-Symbolic Architecture (NVSA)**: высокоразмерные векторы представляют символы, а базовые операции над ними позволяют выполнять логические выводы【12†L77-L85】【12†L87-L96】. Такой подход стремится объединить лучшее из двух миров: **символическая система** придаёт структуру и способность к объяснимому рассуждению, а **нейросеть** — обучение на данных. NVSA, например, успешно демонстрировала абдуктивное рассуждение и решение визуальных тестов интеллекта (матрицы Равена) за счёт представления знаний в **распределённом векторном виде**【12†L91-L99】【12†L147-L155】. 
> 
> Другие проекты интегрируют **онтологии** с нейросетями для придания здравого смысла. Исследователи пробуют улучшить LLM, накладывая на них онтологические ограничения или подключая их к внешним базам знаний. Такой *нейро-символический* подход признаётся необходимым некоторыми экспертами для достижения настоящего интеллекта【35†L133-L140】. Однако, полная реализация затруднена: сложно автоматически добывать и поддерживать формальные знания. Тем не менее, направление остаётся активным – например, обсуждаются методы, позволяющие самим нейросетям порождать и обновлять правила и графы знаний по мере обучения (ассоциация правил, извлечение ограничений и т.п.)【34†L250-L258】【34†L274-L283】. 
> 
> ## Векторные представления и модели без токенизации
> 
> **Полный отказ от токенов** – радикальный подход: представить мысли напрямую в виде векторов или концептов. В конце 2024 года компания Meta предложила **Large Concept Models (LCM)** – «большие концептуальные модели»【7†L42-L50】. Вместо предсказания следующего слова, LCM оперирует **целыми предложениями как единицами смысла**. Каждый запрос или фраза кодируется как точка в пространстве смыслов с помощью специальных эмбеддингов (Meta разработала многозначное представление SONAR)【7†L50-L58】【10†L61-L69】. Модель обучается **предсказывать последовательность предложений** в этом семантическом пространстве, а не последовательность токенов【10†L69-L77】. Благодаря этому LCM удаётся уловить более высокоуровневые связи между идеями: по сути, она строит ответ из готовых смысловых блоков. Например, в исследованиях Meta LCM на 7 млрд параметров показывал лучшее обобщение на многих языках, чем такой же по размеру традиционный LLM, именно за счёт концептуального представления знаний【10†L73-L81】. Этот подход близок к тому, как человек понимает текст – мы оперируем смыслами фраз, а не отдельными буквами. 
> 
> Ещё один пример **векторного мышления** – подходы на основе *гипердимensionalных вычислений* (Vector Symbolic Architectures). В таких системах понятия представлены очень длинными бинарными или числовыми векторами; с помощью операций над ними (например, суммирование для объединения, поразрядное умножение для связывания) можно имитировать логику и манипулировать знаниями. **Голографические редуцированные представления** и другие VSА-модели исследовались как возможная основа для AGI, поскольку они обладают свойствами распределённой памяти и **устойчивости к шуму**. Преимущество – система может **ассоциативно вспоминать** связанный вектор (концепт) при частичном совпадении, как это делает человеческая память. Однако долгое время VSА оставались скорее теоретической концепцией. Сейчас, благодаря работам вроде NVSA от IBM, эти идеи получают новое развитие на практике【12†L89-L97】【12†L98-L102】.
> 
> ### Фрактальные и иерархические представления знаний
> 
> Интересной вариацией является попытка сделать память и представление **фрактальными** – то есть само-подобными на разных уровнях. **Джеффри Хинтон** предложил концепцию *GLOM*, чтобы сеть могла представлять произвольные иерархии «часть-целое» внутри фиксированной архитектуры. Идея GLOM (от сленгового *“to glom together”*) в том, что у нейросети есть несколько уровней представления, и на каждом уровне соседние нейроны приходят к **“согласию” о фрагменте образа**【37†L72-L80】. Реализуется это через множество колонок автоэнкодеров: нижние слои выделяют простые черты, верхние – более абстрактные объекты, а между уровнями идёт двунаправленный обмен (восходящие и нисходящие сети стремятся согласовать представление)【37†L72-L80】【37†L83-L91】. В результате каждая колонка в каждый момент хранит вектор, соответствующий некоторому уровню целостного объекта, а группы колонок формируют **“островки” согласованных интерпретаций** сцены【37†L79-L87】. По сути, GLOM – это попытка сделать **динамическое древовидное разбиение сцены** внутри самого нейросетевого слоя: части и целое представлены единообразно в виде векторов на разных масштабах. Примечательно, что Хинтон сразу оговорил: *«эта работа не описывает готовую систему»*【37†L107-L114】 – GLOM остаётся теоретической моделью и полигоном идей (как ранее *капсульные сети*). Тем не менее, сама концепция фрактального, иерархического кодирования знаний вдохновляет другие работы. Например, в недавно появившихся обсуждениях предлагаются **фрактальные графы знаний**: структуры, где узлы и связи повторяют паттерны на разных масштабах, позволяя хранить информацию с переменной гранулярностью (от общих концепций до частных деталей)【22†L59-L68】【22†L79-L87】. Ожидается, что такая организация облегчила бы **многоуровневое обобщение** и хранение контекста: крупные фрагменты памяти автоматически сжимаются в абстрактные узлы, а при «приближении» (zoom in) раскрываются подробности, подобно тому как ветви фрактала проявляют детали при увеличении【22†L111-L120】【22†L125-L134】. Пока это преимущественно гипотезы, требующие новых алгоритмов обучения, способных самим обнаруживать **иерархические паттерны** в данных【24†L572-L580】【24†L573-L581】. Но исследования продолжаются, как в академических группах, так и в энтузиастских сообществах.
> 
> ## Сценическое (scene-based) мышление и когнитивные архитектуры
> 
> Альтернативный путь к AGI прокладывали **когнитивные архитектуры** – программные модели, имитирующие различные модули человеческого разума (память, восприятие, логика, эмоции и т.д.) и их взаимодействие. В таких системах информация представлена не как текст, а скорее как **состояние мира или агента**. Например, **Scene Based Reasoning (SBR)**, представленная на конференции AGI-2015, – архитектура, где основными единицами мысли являются **«сцены» и «планы»**【28†L49-L57】. *Сцена* в SBR – это некое состояние окружающего мира или задачи, представленное структурированно (на низком уровне – как 3D-граф сцены, как в игровых движках; на высоком – через отношения между объектами на языке дескриптивной логики)【28†L49-L57】. *План* – последовательность действий, преобразующих одну сцену в другую. SBR включает множество подсистем восприятия, обучения и планирования, которые оперируют этими сценами: по сути, *мышление сводится к переструктурированию сцены* для достижения цели, а не к генерации текста. Важная особенность – присутствует **интроспекция**: система может отображать свои внутренние представления сцены на некий диаграммный формат и рассуждать о них (мета-мышление)【28†L49-L57】. Хотя SBR – исследовательский прототип, он демонстрирует, как можно интегрировать **пространственное восприятие** и **символическое планирование**. 
> 
> Другие когнитивные архитектуры следовали похожей логике. Классические системы вроде **Soar** или **ACT-R** (разработанные в когнитивной науке) разделяли память на модули и оперировали продукционными правилами. Однако им не хватало обучения; они требовали ручного программирования правил. Позднее появились проекты, стремившиеся соединить это с нейронными сетями. Например, **MicroPsi** (работы Й. Баха) – нейро-символическая архитектура, где знания представлены в виде **активно распространяющегося графа** (активация течёт по концептуальной сети подобно нейросети), но узлы и связи имеют семантическую интерпретацию, а сверху накладываются мотивационные модули, эмоции и т.д. Цель MicroPsi – смоделировать *полнокровного интеллектуального агента*, у которого есть *понимание мира* и *побуждения к действию*. Подобно этому, архитектура **AERA** и другие пытались реализовать постоянного обучающегося агента, представляющего знание не как тексты, а как **онтологические модели** окружающего мира, обновляемые в реальном времени.
> 
> ### OpenCog: гиперграф памяти и когнитивный синтез
> 
> Особого упоминания заслуживает **OpenCog** – долгосрочный open-source проект по созданию AGI (Бен Гёрцель и коллеги). OpenCog изначально (в версии *Classic*) представлял знания в виде *AtomSpace* – **гиперграфа атомов**, где вершины соответствуют понятиям или утверждениям, а рёбра – различным отношениям (логическим, ассоциативным и пр.)【30†L71-L80】. Различные алгоритмы (нейронные, эволюционные, логические) работают на этом общем графе, обеспечивая так называемую *«когнитивную синергию»*. Однако первая версия OpenCog столкнулась с проблемами **масштабируемости и сложности**: работа с огромным графом знаний в реальном времени оказалась слишком медленной, а интеграция с современными нейросетями – затруднительной【30†L75-L84】. В 2021–2024 годах проект перезапущен как **OpenCog Hyperon**, с упором на распределённую инфраструктуру и гибкий язык MeTTa для описания когнитивных процессов【30†L95-L104】【30†L101-L109】. Hyperon позволяет реализовывать в единой среде разные подходы: так, его используют для экспериментов с системой **NARS** (Non-Axiomatic Reasoning System) внутри AtomSpace【30†L108-L115】. *NARS* – это особая когнитивная архитектура (разработки Пэй Вана), где **мышление формализовано как обобщённое логическое вывождение с неполным знанием и ограниченными ресурсами**【32†L19-L27】【32†L51-L59】. NARS оперирует «терминами» и «высказываниями» в своем языке (Narsese), присваивая каждому истину в определённой степени, и динамически перераспределяет внимание/ресурсы между задачами【32†L75-L83】【32†L67-L74】. Интеграция NARS в Hyperon интересна, поскольку объединяет статистическое обучение (в других модулях) с *адаптивной логикой* NARS.
> 
> Кроме того, в OpenCog Hyperon разрабатывается новая когнитивная модель **Primordial Cognitive Architecture (Primus)**. Её цель – **свести воедино все типы памяти, обучения, рассуждений, восприятия и действий, присущие человеческому уму, в единую алгоритмическую форму**【30†L109-L117】. Иными словами, Primus пытается создать **фрактально-единое пространство когнитивных процессов**, где различные аспекты интеллекта (например, эпизодическая память, рабочая память, навыковое знание, логическое рассуждение) являются модулями единой архитектуры и могут резонировать друг с другом. Это отражает идею *«мыслительного резонанса»*: все компоненты системы работают на общей основе и обмениваются информацией через единый формат (в Hyperon таким форматом служит MeTTa-граф и язык запросов к нему)【30†L141-L149】【30†L151-L159】. Проект ещё в стадии прототипа, но его разработчики надеются, что такая модульно-синергетическая платформа ускорит исследования AGI. 
> 
> ## Почему LLM по-прежнему впереди и перспективы альтернатив
> 
> Несмотря на всю изобретательность, **ни один из вышеперечисленных подходов пока не превзошёл LLM в универсальности и масштабируемости**. Большие языковые модели захватили поле во многом благодаря *«горькому уроку»* (по Р. Саттону): простые архитектуры, обученные на огромных данных, оказались более успешными, чем сложные системы с ручной структурой. Альтернативы же часто страдали от **сложности реализации и недостатка данных** для обучения структурированных представлений. Например, в OpenCog Classic гиперграф знаний давал богатую основу для мыслительных операций, но работать с ним в масштабах интернета было слишком медленно【30†L75-L84】. С развитием же нейросетей оказалось, что можно «впитать» значительную часть *семантики мира* прямо из текстов – пусть неявно, но в масштабируемой форме. Кроме того, **языковые модели сразу приносят пользу** в виде понятного человеку интерфейса (текст), тогда как результаты работы онтологических или нейросимволических систем труднее напрямую применить для пользователей.
> 
> Однако ограничения LLM всё более очевидны. Они склонны **«галлюцинировать»** факты, не умеют по-настоящему планировать действия или понимать физический мир. В сообществе AGI растёт консенсус, что одних LLM недостаточно для человеческого уровня интеллекта【35†L133-L140】. Эксперты вроде Янна ЛеКуна и Ф. Шоллета прямо называют чисто токен-предсказательные модели **тупиковой ветвью на пути к AGI**【35†L133-L140】, указывая на отсутствие у них **модели мира, причинности и внутреннего «медленного мышления»**. Поэтому поиск альтернатив не прекращается. Возможно, будущее – за гибридными системами: где **LLM сочетаются с модулями памяти и логики** (уже сейчас появляются прототипы «думающих LLM», которые ведут внутренний расчёт в скрытом пространстве вместо выдачи мгновенного ответа【15†L458-L467】). Или же прорыв совершит новый тип архитектуры, вдохновлённый, например, **нейробиологией** (как теория *«тысячи мозгов»* Д.Хокинса с параллельными моделями объектов) или **комплексными адаптивными системами**. 
> 
> На данный момент **альтернативные подходы** – нейро-символические гибриды, концептуальные графы, сценические симуляции, фрактальные памяти – находятся в стадии активных исследований и ранних экспериментов. Они предлагают более прозрачное и, возможно, более **понимающее** мышление машин. Ограничения, с которыми они столкнулись (сложность, отсутствие масштабных данных, узость доменов), постепенно преодолеваются благодаря росту вычислительных мощностей и новым алгоритмам обучения. И хотя LLM пока царят, **эволюция AGI может потребовать слияния их достоинств с идеями этих альтернатив**. Как отмечается в обзорах, путь к AGI, вероятно, лежит через наделение моделей **телесностью, пониманием причинно-следственных связей, собственной долговременной памятью и семантически обоснованными представлениями**【26†L91-L99】【26†L97-L100】. Именно над этим и работают упомянутые направления. Их текущие успехи скромны в сравнении с LLM, но они закладывают фундамент для систем, которые **мыслят не словами, а знаниями** – возможно, приближаясь к тому идеалу, который подразумевается под *«Large Think Model»*. 
> 
> **Источники:** Некоторые идеи и проекты описаны на основе академических публикаций и обсуждений: например, Large Concept Model от Meta【7†L50-L58】【10†L61-L69】, когнитивная сцена SBR【28†L49-L57】, нейросимвольная архитектура IBM【12†L77-L85】【12†L89-L97】, OpenCog Hyperon и Primus【30†L109-L117】, а также критический взгляд на ограничения LLM в контексте AGI【35†L133-L140】. Эти источники и другие приведены по тексту для более детального ознакомления.
<!-- UID: e433222d-ea4a-4498-9c74-ff77619c595e -->