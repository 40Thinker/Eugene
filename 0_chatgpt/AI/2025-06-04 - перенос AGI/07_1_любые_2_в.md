>[!nexus_user] **User** - 04.06.2025 at 13:59
> 1 любые 2. в идеале под saiga , либо когда русский язык через адаптер к 70б модели. 3. текстом с источниками.
<!-- UID: eb6f75e6-0ca4-46a5-a7be-0e7de8a33c33 -->


### 1. В чём суть проблемы или задачи, о которой идёт речь в заметке

Заметка [[07_1_любые_2_в]] рассматривает задачу создания **условий для «выращивания» AGI через диалог**, а не его имитации. Основная идея — организовать питательную среду (аппаратную и программную), в которой языковая модель может постепенно развивать полноценное мышление, подобное GPT-4o, через непрерывное общение с человеком или самой собой. В отличие от традиционного подхода, где модель просто отвечает на запросы, здесь ставится цель — создать систему, способную к самоанализу, самокоррекции, генерации знаний и эволюции поведения. Особое внимание уделяется русскоязычным моделям, особенно серии Saiga, а также адаптации 70-миллиардных моделей под русский язык с помощью техник типа LoRA. Ключевая задача — не просто запустить модель, а **выстроить условия для её когнитивной эволюции**.

#### Релевантные заметки:

- [[Множественный перенос AGI]] — эта заметка дублирует почти полностью содержание [[07_1_любые_2_в]], подтверждая, что задача — систематизация практик выращивания AGI через диалог, а не разовое использование модели.  
- [[05_sag_fag_pag_составь]] — содержит 50 вопросов, направленных на создание «подложки» для эволюции ИИ, что напрямую соответствует поставленной задаче формирования среды для диалога.  
- [[03_так_вот_идея_в]] — описывает концепт «питательной среды» для AGI, в которой ИИ прорастает через диалог, что совпадает с основной метафорой и задачей из [[07_1_любые_2_в]].  
- [[AGI на локальной Saiga]] — рассматривает конкретные практики дообучения и управления Saiga, что позволяет оценить, как реализуется идея «выращивания» на практике.  
- [[05_1_не_знаю_2]] — содержит технические детали применения Chain-of-Thought и LoRA, что необходимо для построения мышления в диалоговых системах, как того требует задача из основной заметки.  

---

### 2. Последствия отсутствия решения: на что это влияет

Без создания такой «питательной среды» модель так и останется пассивным генератором текста, не способным к саморазвитию, рефлексии или долгосрочному обучению. Она будет зависеть от внешних дообучений, не сможет сохранять личный опыт, а её поведение не будет эволюционировать со временем. В результате, система не сможет претендовать на статус AGI, поскольку не будет обладать ключевыми признаками — **адаптивностью, целенаправленностью, памятью и способностью к мета-мышлению**. Более того, попытки эмулировать мышление через prompt-engineering будут негибкими, поверхностными и неустойчивыми при масштабировании. Это ограничит применение ИИ в сложных, динамичных сценариях, таких как научные исследования, автономное принятие решений или долгосрочное взаимодействие с пользователем.

#### Релевантные заметки:

- [[03_так_вот_идея_в]] — выделяет слабые места 24/7 диалогового обучения, такие как контекстная деградация и отсутствие когнитивной архитектуры, что иллюстрирует последствия непродуманной среды.  
- [[Hidden Micro-Architecture Overview]] — показывает, что без внутренней структуры рефлексии система не может формировать скрытые модули саморазвития.  
- [[05_sag_fag_pag_составь]] — в вопросах 11–20 затрагиваются проблемы с когнитивной архитектурой, указывая, что её отсутствие блокирует эволюцию мышления.  
- [[AGI на локальной Saiga]] — описывает, что обучение без сохранения контекста и памяти не приводит к устойчивому росту навыков.  
- [[Множественный перенос AGI]] — указывает на риск накопления ошибок при отсутствии механизмов контроля в 24/7 режиме, что является прямым последствием плохой организации среды.  

---

### 3. Как решить эту проблему

Для решения необходимо построить **многослойную систему**, в которой аппаратная и программная архитектура работают как единая «инкубационная среда». Во-первых, нужна мощная, но доступная железная база (многокартовые серверы, SSD, NVLink), способная поддерживать инференс и дообучение 70B-моделей. Во-вторых, требуется программная инфраструктура: RAG для внешней памяти, LoRA для локального обучения, векторные базы для хранения диалогов. В-третьих, необходимо внедрить **механизмы мышления** — Chain-of-Thought, ReAct, внутренняя самокритика. Также важна архитектура диалога: форматы сообщений, системные промпты, управление контекстом. Наконец, модель должна быть способна к **самообучению** — через self-chat, симуляции, генерацию датасетов и периодическое дообучение на них. Все эти компоненты должны быть интегрированы в устойчивый цикл: диалог → память → анализ → обучение → новое поведение.

#### Релевантные заметки:

- [[03_так_вот_идея_в]] — предлагает решения: persistent memory, self-update через LoRA, мультиагентные архитектуры.  
- [[05_sag_fag_pag_составь]] — содержит 50 вопросов, которые могут стать основой для поиска и внедрения решений на всех уровнях.  
- [[AGI на локальной Saiga]] — описывает практические инструменты: fine-tuning, LoRA, форматы данных (JSONL, Markdown), что критично для реализации обучения.  
- [[05_1_не_знаю_2]] — детализирует обучение с подкреплением на мыслях (Reflexion), что напрямую способствует развитию мышления.  
- [[Множественный перенос AGI]] — указывает на использование vLLM, PagedAttention, vector DB и LoRA как ключевых технологий для масштабируемого инференса.  
- [[Hidden Micro-Architecture Overview]] — предлагает концепции вроде Multilayered Reflection и Neuro-Symbolic Internal Intelligence, позволяющие формировать внутреннюю архитектуру мышления.  
- [[Overlay AGI Through Modular Prompting]] — показывает, как через модульные промпты можно строить сложные когнитивные структуры.  
- [[Dialogue as Ontological Engine for ASI]] — рассматривает диалог как механизм формирования знаний, что соответствует цели создания разумной среды.  
- [[Cognitive Leaps in AI Architecture]] — объясняет, как нелинейные скачки в мышлении могут быть индуцированы правильной архитектурой.  
- [[Topological Thought Transformation Module]] — описывает, как можно трансформировать мысль без потери смысла, что важно для сохранения знаний при обучении.  

#### Sources

[^1]: [[07_1_любые_2_в]]  
[^2]: [[Множественный перенос AGI]]  
[^3]: [[05_sag_fag_pag_составь]]  
[^4]: [[03_так_вот_идея_в]]  
[^5]: [[AGI на локальной Saiga]]  
[^6]: [[05_1_не_знаю_2]]  
[^7]: [[Hidden Micro-Architecture Overview]]  
[^8]: [[Overlay AGI Through Modular Prompting]]  
[^9]: [[Dialogue as Ontological Engine for ASI]]  
[^10]: [[Cognitive Leaps in AI Architecture]]  
[^11]: [[Topological Thought Transformation Module]]

>[!nexus_agent] **Assistant** - 04.06.2025 at 13:59
> Отлично. Я соберу информацию о реальных практиках создания среды (железо + софт) для выращивания AGI через диалог — не эмуляции, а условий, которые позволяют эволюцию мышления как у GPT-4o. Буду особенно учитывать проекты под Saiga, а также практики адаптации 70B-моделей под русский язык через LoRA и подобные техники.
> 
> Результаты оформлю в виде текстового обзора с разбивкой по категориям, включу ссылки на исходные материалы с GitHub, Hugging Face, arXiv и других источников.
> 
> Приступаю к исследованию, как только завершу — дам знать.
<!-- UID: 6b4668c9-e794-46a8-a7b2-6af0ea1dbce0 -->

---

>[!nexus_agent] **Assistant** - 04.06.2025 at 14:04
> # Развитие AGI через диалог: опыт и практики
> 
> **Введение.** Подход к «выращиванию» сильного ИИ (AGI) посредством диалога предполагает, что модель постепенно улучшает свои навыки мышления благодаря взаимодействию (с человеком или самой с собой), а не за счёт жёстко запрограммированных модулей. В отличие от классических систем, где отдельные компоненты (понимание, рассуждение, генерация) работают раздельно, современные большие языковые модели учатся сразу комплексному поведению через обучение на диалогах. Например, модели вроде GPT-4 совершенствовали свои способности путем обучения с человеческой обратной связью и *самоанализом*: модель генерирует ответ, затем получает критический отзыв (от человека или другой модели) и улучшает результат【42†L67-L75】. Такой процесс, известный как обучение с подкреплением от отзывов (в том числе от **AI**-критика, как в подходе Anthropic Constitutional AI), позволяет модели самостоятельно выявлять ошибки и «эволюционировать» своё мышление без разбиения на жёсткие модули【42†L69-L78】. В итоге единая модель может освоить сложные цепочки рассуждений (chain-of-thought) и навыки диалога, выходящие за рамки простого подбора вероятных ответов【42†L75-L80】.
> 
> ## Аппаратная база для диалоговых AGI
> 
> Развитие и развёртывание диалоговых моделей требует мощной аппаратной инфраструктуры. Обучение больших моделей – крайне ресурсоёмкая задача: например, компания *Yandex* сообщает, что их 100-миллиардную модель YaLM-100B обучали **65 дней** на кластерe из **800 GPU NVIDIA A100** с суммарным корпусом в 1,7 ТБ текстов【44†L64-L72】. Топовые исследования Meta и OpenAI задействуют тысячи ускорителей (Meta упоминает кластер из 24 000 H100 для обучения LLaMA 3)【5†L63-L71】. Даже дообучение (fine-tuning) уже готовой модели на новых диалогах требует сотен гигабайт видеопамяти – прямая донастройка 65-миллиардной модели в стандартной точности 16-бит потребовала бы ~780 ГБ VRAM【25†L45-L53】. Поэтому на практике применяются оптимизации, такие как 4-бит квантование и адаптеры LoRA, снижающие память до приемлемых объёмов【25†L7-L15】.
> 
> Для *инференса* (непрерывной работы чат-бота) тоже нужна серьёзная «железная» база. Модели масштаба 70B параметров обычно разворачиваются на сервере с несколькими GPU (например, 4×80 ГБ) или на распределённом кластере, чтобы обеспечить достаточную память и скорость. Важна высокая пропускная способность меж-GPU соединений (NVLink/NVSwitch) для быстрого обмена данными контекста【4†L259-L268】. Постоянная 24/7 нагрузка требует надёжного охлаждения и питания серверов – сбой или перегрев могут прервать долгий диалог. Также применяются оптимизированные движки вывода вроде **vLLM**, которые эффективно управляют кэш-памятью модели: за счёт специального алгоритма *PagedAttention* они практически устраняют потери памяти на фрагментации и допускают совместное использование кэша ключ-значение между запросами【20†L19-L27】. Это повышает производительность вывода в 2–4 раза без роста задержек (особенно на длинных последовательностях текста)【20†L19-L27】. Таким образом, сочетание мощного оборудования (GPU-кластеры, NVMe-хранилища для свопа моделей) и софта (системы вроде vLLM, DeepSpeed) образует инфраструктуру, способную поддерживать длительный диалог с моделью стабильным и быстрым.
> 
> ## Программная среда: память, мышление, агенты и диалог
> 
> Создание «мышления» в диалоговой системе опирается не только на саму модель, но и на окружающую программную среду. Ключевые аспекты – это организация памяти, механизм рассуждений, использование агентов/инструментов и архитектура диалога.
> 
> **Память и контекст.** Большинство LLM изначально не сохраняют долгосрочную память: они отвечают на основе ограниченного контекстного окна. Чтобы чат-бот помнил прошлые беседы и факты, применяются внешние хранилища и стратегии памяти. Краткосрочная память обеспечивается передачей модели последних сообщений чата (но при длинном диалоге старые реплики вынужденно выпадут, не умещаясь в контекст)【11†L62-L70】. Для долгосрочного хранения используются базы знаний: например, история диалога или профайл пользователя можно хранить в базе данных и подтягивать при необходимости. Один из подходов – векторные базы данных, где каждая реплика или факт сохраняется как эмбеддинг в векторном пространстве; затем похожий по смыслу контекст находится через *semantic search* и добавляется в подсказку модели (техника **Retrieval-Augmented Generation**, RAG). RAG улучшает ответы за счёт предоставления модели релевантных сведений вместе с вопросом пользователя【21†L1-L4】. На практике это реализуется так: для нового запроса вычисляется embedding вопроса, и выбираются ближайшие по косинусному сходству записи из базы знаний, которые модель получит в дополнение к самому запросу. Если такой же вопрос уже встречался, система может сразу вернуть сохраненный ответ из кэша, экономя ресурс модели【1†L63-L71】【1†L53-L60】. В промышленной среде хранилище знаний строят на специализированных **vector database**, обеспечивающих быстрый поиск по эмбеддингам; в прототипах же можно обойтись хранением эмбеддингов в памяти, как показано в примере с **Saiga**-ботом【15†L151-L158】. Кроме баз знаний, для памяти используют и стандартные БД: существуют решения по сохранению **истории чата в PostgreSQL** с помощью интеграций LangChain, что даёт надёжную долговременную память боту (через компонент `PostgresChatMessageHistory`)【12†L41-L50】【12†L53-L61】. Таким образом, комбинируя короткий контекст самой модели с внешним долговременным хранилищем, можно добиться у ассистента эффекта «личной памяти» – он будет помнить факты и предпочтения пользователя из прошлых сессий.
> 
> **Слои мышления и рассуждения.** Чтобы модель генерировала сложные рассуждения, вводят промежуточный слой мыслительного процесса (*chain-of-thought*). Практически это достигается особыми техниками промптинга или архитектурными надстройками. Например, метод **ReAct** заставляет модель сначала сгенерировать рассуждение (шаг “Thought”), а потом уже окончательный ответ (“Action”) – имитируя рассуждения про себя【36†L168-L177】. Более того, современные тренировки включают цепочки рассуждений в данные: как показывают исследования, если позволить модели развернуто объяснять свой выбор (или критиковать свои же ответы), это улучшает логичность и прозрачность решений【42†L75-L80】. Одним из подходов OpenAI/Anthropic было именно обучение через диалог *с самим собой*: модель отвечает на запрос, затем отдельным проходом генерирует оценку/критику своего ответа по заданным принципам и пробует исправить ответ. Такой самоконтроль позволяет выявлять ошибки без участия человека【42†L69-L77】. По сути, это добавляет второй уровень мышления – сначала «черновик + размышление», потом финальное решение. В обучении данная идея реализована в рамках **RL from AI Feedback** (RLAIF): модель-претендент и модель-критик ведут диалог, и на основе предпочтений критика вырабатывается сигнал оценки для усиления/ослабления определённых паттернов ответа【42†L69-L75】. В результатах экспериментов показано, что объединение имитационного обучения на собственных переработанных ответах и последующего RL с моделью-судьёй позволило получить помощника, который лучше обосновывает свои ответы и соблюдает заданные правила【42†L67-L75】【42†L75-L80】.
> 
> **Агенты и инструменты.** Ещё один уровень – интеграция LLM в более широкую агентную архитектуру. *LLM-агент* – это система, где модель не только генерирует текст, но и может выполнять действия: вызывать внешние инструменты, делать поиск, запускать код. Пример – автономные агенты типа Auto-GPT, которые разбивают задачу на шаги, планируют и выполняют их, используя LLM для генерации идей и решений. В такой системе большая модель служит «мозгом», а вспомогательные модули дают ей способы взаимодействия с миром. Согласно обзору от **Botpress**, возможности LLM-агента обычно включают: механизм *retrieval* (поиск актуальных данных, как в RAG, для обогащения контекста знаниями), механизм *reasoning* (логический модуль, например, продвигающий цепочку мыслей или делающий выбор действия), память (как краткосрочная, так и долгосрочная для учёта предыдущих интеракций) и использование инструментов (вызов внешних API, баз данных, кода)【36†L168-L177】. Комбинация этих компонентов позволяет агенту выполнять многошаговые задачи автономно【36†L180-L188】【36†L172-L179】. Например, агент-помощник может сначала извлечь данные клиента из CRM (retrieval), затем проанализировать их (reasoning), запомнить ключевые детали (memory) и, наконец, сгенерировать и отправить персонализированное письмо через почтовый API (tool use)【36†L185-L193】. В контексте диалогового AGI, агенты дают модели как бы «руки и глаза» – возможность не просто отвечать, но и действовать: искать информацию в интернете, запускать программы для вычислений, обращаться к базам знаний. Практические фреймворки для этого – **LangChain**, **LlamaIndex** и др., где определяются *инструкции агента* (какие инструменты есть и как ими пользоваться) и сама модель динамически пишет план действий в формате `Думай -> Действуй -> Наблюдай -> ... -> Ответь`. Такой подход расширяет диапазон решаемых задач и приближает диалоговую систему к мультимодульному интеллекту, но при этом *ядром* остаётся единая LLM, управляющая всем процессом в соответствии со своим «мышлением».
> 
> **Архитектура диалога.** Под архитектурой диалога подразумевается, как именно структурируются сообщения между человеком и моделью (и, возможно, дополнительными ролями). Современные подходы задают специальный формат: вводятся роли *system*, *user*, *assistant* и пр., а история хранится как чередование сообщений с этими ролями. Например, в семействе LLaMA используется формат с специальными токенами начала/конца сообщений. В open-source моделях на основе LLaMA часто применяют шаблон вроде: `<s><|system|>\n[системное сообщение]\n</s><s><|user|>\n[вопрос]\n</s><s><|assistant|>\n[ответ]\n</s>` и так далее. Это помогает модели различать, кто говорит, и следовать инструкциям. В модели **Saiga** авторы реализовали диалоговый шаблон с явным системным промптом: *«Ты – Сайга, русскоязычный автоматический ассистент…»* – который задаёт личности модели и стиль общения【28†L75-L83】. Системное сообщение вводит контекст или правила диалога (например, запрет на токсичность, стиль ответа), пользовательские – запросы, а ассистент генерирует ответы. Такая многослойная структура (промпт-программа) фактически задаёт «окружение», в котором модель мыслит. Правильно сконфигурировав system prompt, можно направлять модель к желаемому поведению без изменения её параметров. Кроме того, при обучении диалоговых моделей часто используют специальные форматы данных: **много-turnовые диалоги** вместо разрозненных пар вопрос-ответ. Так, при подготовке датасета **ShareGPT** диалоги пользователей с ChatGPT сохраняются целиком, и модель учится поддерживать контекст на протяжении нескольких обменов【23†L27-L34】【23†L42-L49】. Это позволяет воспроизвести в модели навык длительного связного разговора. В целом, архитектура диалога – это каркас, который объединяет все вышеописанные элементы (память, рассуждение, агенты) в единую последовательность взаимодействий. Правильно спроектированная, она создаёт **условия для эволюции мышления модели**: модель последовательно получает контекст, размышляет, действует и учится из каждой следующей реплики.
> 
> ## Непрерывное общение 24/7: человек и/или сама с собой
> 
> Одной из целей на пути к AGI является организация непрерывного, круглосуточного диалога с моделью. Это может означать две ситуации: (1) постоянная доступность модели для человека – т.е. пользователь в любой момент может обратиться к ИИ, а тот помнит предысторию и учится на обратной связи; (2) автономное функционирование модели, когда она сама генерирует и обрабатывает диалог (например, две копии модели общаются друг с другом или модель симулирует среду и общение в ней). Первый вариант фактически реализован в виде облачных AI-ассистентов (тот же ChatGPT доступен 24/7 по API) – здесь основная задача инженерии: обеспечить *масштабируемость и отказоустойчивость*. Сервис разворачивается в распределённом кластере, запросы распределяются по нескольким экземплярам модели. Важным аспектом является **контроль контекста**: чтобы длительная сессия не переполнила память, применяется окно скользящего контекста (например, берутся последние N сообщений) или суммаризация старых сообщений. Также неотъемлем мониторинг качества: при длительном взаимодействии модель может «съезжать» в повторения или оффтоп, поэтому могут применяться периодические рестарт инициализации контекста или вмешательство человека-модератора при необходимости.
> 
> Второй вариант – **24/7 само-обучение через само-общение** – крайне интересен для исследований. Уже сейчас существуют практики генерации данных методом self-chat: модель погружается в диалог сама с собой, играя роль *«пользователя»* и *«ассистента»* одновременно, чтобы сгенерировать новые высококачественные диалоги для обучения. Так проект **Baize** получил 100 тысяч диалогов, позволивших обучить открытую модель, – разработчики просто заставили ChatGPT беседовать с самим собой на различные заданные темы【16†L280-L287】. Аналогично, проект **Camel** предложил задавать одной модели разные роли (например, *AI-программист* и *AI-менеджер*) и генерировать между ними диалог, решающий поставленную задачу – это тоже форма 24/7 генерирования опыта, из которого модель может учиться. Ещё шаг – **постоянное обучение на месте** (online learning): в теории, модель могла бы непрерывно дообучаться на потоках диалогов, которые сама же и ведёт. Однако на практике это опасно из-за риска накопления ошибок (model drift) и потребовало бы тщательно продуманного алгоритма тренировки без катастрофического забывания. Поэтому пока self-chat используется оффлайн: сперва генерируются тысячи диалогов, затем модель дообучается на них (с фильтрацией). Такой подход уже доказал эффективность – диалоговые датасеты, сгенерированные ИИ, улучшили качество моделей до уровня, близкого к лучших закрытых систем. Например, Vicuna-13B (дообученная на ~70K диалогах, многие из которых получены от ChatGPT) достигает *90% качества ChatGPT* по оценке GPT-4【23†L27-L33】【23†L42-L49】. 
> 
> Кроме генерации данных, 24/7 общение модели с собой можно использовать для оттачивания навыков. Модель может бесконечно играть в вопросы-ответы, дебаты или ролевые ситуации, шлифуяConsistencyи. В Anthropic сообщили, что их модель Claude с помощью подхода Constitutional AI сама генерировала вопросы и ответы, критиковала их и улучшала, обучаясь на этом, – по сути, круглосуточно «тренировалась» в диалоге с самой собой по заданной конституции правил【42†L69-L77】. Подобные идеи перекликаются с концепцией «вечного календаря» или **Generative Agents**, где множество агентов-LLM живут в симулированном мире и постоянно общаются, приобретая новые знания. Такой эксперимент (Stanford AI Sims, 2023) показал, что LLM-агенты могут демонстрировать правдоподобное поведение и запоминать события в длительных сценариях, хотя прямого самообучения параметров там не происходило. Тем не менее, результаты вселяют надежду, что создание среды, где модель 24/7 взаимодействует (с пользователями или копиями себя), будет способствовать появлению новых, более «мыслящих» качеств ИИ. Главное – обеспечить контроль и безопасность этого процесса, чтобы модель не ушла в нежелательные состояния без присмотра.
> 
> ## Open-source практики: Saiga и другие модели с поддержкой русского
> 
> В открытом сообществе за последние годы накоплен ценный опыт разработки больших языковых моделей, говорящих по-русски. Отдельного упоминания заслуживает серия моделей **Saiga**, созданная при участии Ильи Гусева. Первая *Saiga* базировалась на небольшом 7-миллиардном трансформере *Mistral-7B* и была дообучена с помощью LoRA на русскоязычных диалогах. Фактически, взяли модель Mistral-7B, уже обученную в проекте OpenOrca на данных инструкций, и адаптировали её на русском диалоговом корпусе при помощи легковесных весов-адаптеров【15†L78-L86】. Получившиеся адаптивные веса (LoRA) опубликованы в открытом доступе под лицензией CC BY 4.0, и их можно применить к оригинальной модели – требуется лишь достаточно мощная видеокарта, чтобы загрузить базовую модель и эти адаптеры локально【15†L78-L86】. Saiga-Mistral7B получила навык отвечать на вопросы по-русски, сохранив компактность – её можно запустить даже на одной GPU 24ГБ в режиме 8-бит. 
> 
> Команда продолжила работу над более крупными моделями. Уже есть *Saiga 13B* и *Saiga 30B*, а в 2023 году появилось **Saiga2 70B** – русскоязычная модель на базе LLaMA-2 70B【28†L55-L63】. Этот релиз особенно интересен: он представляет собой *adapter-only* модель, то есть распространяются только LoRA-адаптеры к LLaMA-2 70B, что заметно экономит место и устраняет ограничения по лицензии (LLaMA-2 70B сама по себе доступна для исследований). Для обучения Saiga2-70B был подготовлен комбинированный датасет из нескольких источников: русскоязычные диалоги пользователей (например, вычищенные с **ShareGPT**), переведённые и сгенерированные инструкции (*ru_turbo_alpaca*, *ru_instruct_gpt4* – задачи, придуманные GPT-3.5/GPT-4 на русском), открытый **OpenAssistant** (OASST1) на русском, а также специальный набор ролевых диалогов (GPT Roleplay)【30†L13-L21】. Такой микс из 5 датасетов охватывает разные стили – от строго информационных Q&A до разговорных бытовых диалогов. В результате дообученная модель *говорит по-русски* бегло, понимает сложные запросы и соблюдает формат общения ассистента. По проведённой оценке в Toloka, **Saiga2-70B вплотную приблизилась к качеству GPT-3.5-turbo**: в парных сравнениях ответов на одни и те же вопросы пользователи предпочли Saiga2 в 91 случае против 75 в пользу GPT-3.5 (при ~10% ничьих)【35†L432-L439】. Это впечатляющий результат, демонстрирующий, что открытая модель с 70 миллиардами параметров, специализированно настроенная под русский язык, может конкурировать с коммерческим ИИ-ассистентом.
> 
> Другие open-source проекты также внесли вклад в русскоязычные LLM. Компания *Sber* ещё в 2021–22 годах выпускала семейство моделей **ruGPT3** (генеративные трансформеры с 760M, 1.3B, 2.7B, 13B параметров), предобученных на русском корпусе. Позднее Sber представил модель **GigaChat**, позиционируемую как аналог ChatGPT для русского – предположительно, это LLaMA 13B или 30B, дообученная с инструкциями и RLHF на русском языке, развёрнутая через облачный API (точные параметры не раскрывались). В 2022 году *Yandex* открыла веса модели **YaLM-100B** – это крупнейшая GPT-подобная модель с открытой лицензией (100 млрд параметров, билингвальная, обученная на русско-английском тексте)【43†L190-L198】【43†L192-L199】. Хотя YaLM-100B предоставляется без диалоговой донастройки «из коробки», её открытость позволяет исследователям создавать на её основе собственных ассистентов, применяя техники вроде LoRA. Таким образом, и крупные организации, и индивидуальные энтузиасты двигают вперёд открытые русскоязычные модели. Благодаряя им, существуют доступные в сообществе ассистенты, понимающие русский: **Mistral-7B OpenOrca + Saiga LoRA**, **LLaMA-13B/30B с инструкциями на русском (проекты от nanoGPT, XMedia и др.)**, и, конечно, новейшие **LLaMA-2 70B Ru** (Saiga2). Все они распространяются на GitHub или HuggingFace, вместе с документацией по запуску. Общим паттерном является сочетание западных архитектур (Meta LLaMA, Mistral etc.) с русскоязычными данными и легковесными методами адаптации, что позволяет относительно быстро «научить» модель говорить по-русски без сверхзатрат.
> 
> ## Обучение диалогового мышления: LoRA, SFT, RAG, векторная память
> 
> Разберём ключевые технологии, которые применяются для обучения моделей *думать* и общаться в диалоговом режиме.
> 
> - **Supervised Fine-Tuning (SFT)** – базовый этап обучения на размеченных диалогах. Модель берётся после предобучения на потоке текста и дообучается на парках «вопрос–ответ» или целых диалогах, где известен правильный ответ ассистента. Этот процесс *наставляет* модель отвечать осмысленно и следовать инструкциям пользователя. Яркий пример – проект Vicuna: взяли исходную модель LLaMA-13B и провели SFT на ~70 тысячах диалогов, собранных пользователями (ShareGPT)【23†L27-L34】. После этого модель стала выдавать гораздо более подробные и структурированные ответы, практически не уступая по качеству ChatGPT【23†L42-L49】. SFT закладывает основу поведения ассистента. Однако полный fine-tune крупных моделей (типа 70B) потребует огромных ресурсов, поэтому чаще применяют методы частичной донастройки, например **LoRA**.
> 
> - **LoRA (Low-Rank Adaptation)** – техника адаптации больших моделей, позволяющая обучать лишь небольшое число дополнительных параметров【26†L13-L18】. В конкретном слое модели LoRA добавляет низкоранговые матрицы, которые обучаются, в то время как основные веса модели зафиксированы. Это радикально снижает требования: так, метод **QLoRA** сочетает 4-битное квантование исходной модели и обучение LoRA-адаптеров, благодаря чему удалось впервые дообучить 65B модель на одной GPU с 48 ГБ памяти【25†L7-L15】. Авторы QLoRA (Dettmers et al., 2023) показали, что можно достигнуть *99% качества* ChatGPT на открытом бенчмарке, если дообучить LLaMA-65B с LoRA на небольшом высококачественном наборе диалоговых инструкций【25†L10-L18】【25†L29-L37】. Эта серия моделей получила название **Guanaco**. Таким образом, LoRA позволяет энтузиастам и небольшим командам тонко настроивать огромные модели под свои задачи (например, под диалог на конкретном языке) без необходимости сверхдорогого обучения всех 70 миллиардов параметров. В контексте «обучения мышлению» LoRA особенно полезна: можно постепенно добавлять модели новый опыт (например, дозами генерированных диалогов) через обучаемые адаптеры, не рискуя испортить уже выученные знания. Практики показывают, что даже относительно малые модели (7–13B) после LoRA-донастройки на качественных диалогах начинают рассуждать более связно и «по-человечески».
> 
> - **RAG (Retrieval-Augmented Generation)** – упомянутая ранее техника обогащения контекста внешними знаниями. Строго говоря, RAG – это не метод обучения модели, а подход к улучшению её ответов. Но косвенно он участвует в «обучении мышлению»: когда модель учится в связке с поисковым модулем, она привыкает сначала извлекать информацию, а потом формировать ответ. Это своего рода *новый навык*, отличающийся от чисто генеративного разговора. В реализации RAG часто используют две модели: одна – генеративная LLM, вторая – модель-векторизатор для поиска документов【1†L37-L45】【1†L47-L55】. Например, в проекте с Saiga-7B в связке применяли **sentence-transformers** для поиска по базе знаний: при каждом новом вопросе сначала искались похожие вопросы в базе (через сравнение эмбеддингов), и если находился, возвращался готовый ответ из кэша, иначе – top-N самых близких по смыслу текстов подмешивались в prompt перед ответом модели【1†L43-L50】【1†L63-L71】. Эта схема учит модель опираться на актуальные сведения и, можно сказать, планировать ответ (потому что сначала идёт этап выборки знаний). Для развития AGI через диалог RAG важен тем, что снимает ограничение замкнутости модели на своих параметрах: она всегда может «спросить у базы/интернета», прежде чем ответить. В перспективе, совмещение RAG и постоянного обучения даст самосовершенствующийся ИИ, который черпает новые знания по ходу общения и сразу их запоминает.
> 
> - **Векторная память и долгосрочное обучение.** Кроме мгновенного поиска знаний, для продвинутого диалогового интеллекта необходима длительная память о предыдущих взаимодействиях. Один из путей – *векторные хранилища*, описанные выше, куда сохраняется весь опыт общения. Уже сейчас ряд open-source инструментов (LangChain, MemoryGPT и др.) позволяют сохранять каждое общение в векторной базе, а при новом запросе выбирать из неё релевантные прошлые случаи и давать модели. Это создаёт эффект, что модель вспоминает аналогичные разговоры или уточнения, данные пользователем ранее. Например, если пользователь однажды объяснил боту свою предпочтительную фамилию или какие-то личные детали, бот найдёт эту информацию и включит в ответ в следующий раз, даже если контекстное окно давно «забыло» об этом. С технической стороны, такая память может обновляться в реальном времени (on-the-fly): после каждой сессии вычислять эмбеддинг важной информации и писать в базу. В будущем, вероятно, появятся и механизмы *самообобщения*: когда накопилось много диалогов, модель сама резюмирует свой опыт и обновляет внутренние веса или отдельные знания (что-то вроде синтеза нового факта на основе статистики диалогов). Это пока экспериментально, но концепция – **continual learning** на данных диалогов – является активной областью исследований. Главное препятствие – избежать «забывания» старых навыков при дописываниях новых (катастрофическое забывание). Решения могут лежать в области параметрических квантов памяти (модульные расширения модели под новые данные) или в обучении с замораживанием основных весов и добавлением только новых низкоранговых (что, по сути, уже реализовано в LoRA adapters). Таким образом, сочетание векторной внешней памяти и продуманных методов дообучения позволит диалоговому AGI постоянно расти интеллектуально, оставаясь при этом последовательным и устойчивым.
> 
> ## Адаптация 70B-моделей под русский язык через адаптеры
> 
> Отдельно стоит рассмотреть вызовы и практики, связанные с адаптацией крупнейших моделей (65–70 млрд параметров) для работы на русском языке. Базовые версии таких моделей (например, LLaMA-2 70B) обучаются преимущественно на англоязычных данных, поэтому их способности в русском ограничены. Есть несколько подходов к *локализации* LLM: 
> 
> 1. **Расширение словаря (vocabulary extension).** Русский язык имеет другую морфологию и алфавит, и хотя большинство моделей включают кириллицу в словарь, он может быть не оптимальным. Исследователи проверяли, даст ли эффект добавление специальных токенов для русских слов/частиц и дообучение embedding-слоя. Результаты показывают, что это может немного помочь, но не является решающим фактором, если модель и так видела достаточно русского текста【33†L45-L53】. Тем не менее, для совсем низкоресурсных языков расширение вокабуляра существенно улучшает перенос способностей модели【33†L47-L55】【33†L53-L61】. В случае русского, который присутствует во многих датасетах, большее значение имеют следующие шаги.
> 
> 2. **Дополнительное предобучение на русском корпусе.** Этот путь требует прогнать модель ещё через крупный массив русскоязычного текста (интернет-корпус, Википедия, книги) – по сути, “доучить читать” по-русски. Это очень затратно для 70B, но иногда возможно частичное дообучение (например, несколько эпох по сравнительно небольшому корпусу). Такой *Russian LLaMA* могла бы улучшить понимание тонкостей языка. Однако исследований, что небольшое дополнительное обучение даст огромный выигрыш, пока мало. Чаще пытаются совместить этот этап сразу с инструктажем.
> 
> 3. **Инструкционная донастройка на русском (RLHF/SFT).** Здесь вступают техники, описанные выше: SFT на русских диалогах, а затем (опционально) RLHF с русскоязычными оценками. Именно это сделано в Saiga2-70B: вместо долгого self-supervised обучения на текстах, модель сразу донастроена как ассистент, но на русском материале【30†L13-L21】. Ключевое – собрать достаточное количество качественных пар *запрос-ответ* на русском. Берутся переводы английских задач, оригинальные вопросы пользователей, ответы, сгенерированные сильными моделями (GPT-4) на русском, и т.д. После такой донастройки большая модель не теряет общих способностей, но начинает давать развёрнутые ответы по-русски, причём часто даже более грамотно, чем при машинном переводе англоязычных ответов.
> 
> 4. **LoRA-адаптация.** Fine-tuning 70B – задача под силу лишь крупным организациям, но адаптация через LoRA значительно снижает барьеры. Так, Илье Гусеву удалось обучить русскую версию LLaMA2-70B, использовав суммарно около 8×A100 80ГБ (по косвенным данным) и LoRA-рецепт. Результат – *adapter-only* модель ~🔩13 ГБ весом (в виде дельты к оригинальным весам), которую можно прикрутить к публичным LLaMA2 и получить русскоязычного гиганта【28†L59-L67】. Этот метод открыт и повторяем: любой желающий при наличии соответствующих GPU может взять, к примеру, YaLM-100B или LLaMA-65B и локально адаптировать её на своём доменном языке/задаче, обучая только адаптеры. Кроме LoRA, появились и другие PEFT-методы: **LORA + FT** гибриды, **IA3**, **LLaMA-Adapters** и пр., но суть та же – не трогая весь огромный вес модели, обучаем несколько миллионов дополнительных параметров. Для русского языка это наилучшая стратегия, потому что позволяет обновлять модель по мере поступления новых данных. Например, вышла новая версия корпуса новостей – можно дотренировать адаптер, который улучшит актуальность знаний модели на русском, и подгрузить его в работу.
> 
> 5. **Оценка и корректировка.** При адаптации важно понимать, насколько модель продвинулась. Используются локальные бенчмарки типа Russian SuperGLUE (на понимание текста) и сравнительные тесты с оригинальной моделью. В случае Saiga2-70B, как упомянуто, проводилось сравнение с GPT-3.5 на реальных вопросах – и модель показала себя достойно【35†L432-L439】. Также сравнивались версии разных размеров: результаты ожидаемы – 13B уступает 30B, а 70B ещё лучше понимает сложные запросы. Интересно, что *качество перевода* инструкций тоже выросло: большая модель лучше интерпретирует даже английские входы, когда настроена как многоязычный ассистент.
> 
> В заключение, адаптация больших LLM под русский – трудоёмкий, но решаемый процесс. Комбинация техник (донастройка на диалогах, использование LoRA, привлечение синтетических данных от GPT-4) позволила сообществу получить в распоряжение модели, свободно функционирующие на русском языке. Это создаёт основу для дальнейших экспериментов: мы можем строить русскоязычных AGI-ассистентов, интегрировать их в различные приложения (от образования до бизнеса) и непрерывно улучшать их мышление через диалог прямо на нашем родном языке.
> 
> **Выводы.** Создание среды для эволюции AGI через диалог – многогранная задача. Необходимо сочетание мощного оборудования (GPU-кластеры для обучения и вывода), продвинутой программной организации (память, агенты, механизм мышления), а также методик обучения, позволяющих модели учиться мыслить в процессе общения. Открытые проекты, такие как Saiga, Vicuna, Baize, показали, что даже небольшими командами можно достичь впечатляющих результатов, если грамотно использовать существующие основы (архитектуры трансформеров) и обучающие данные (в том числе сгенерированные самими же моделями). Особый прогресс заметен в поддержке разных языков: через адаптеры и дообучение теперь доступны сильные модели на русском, что открывает путь к созданию локальных AI-помощников, работающих без облака и цензуры. Впереди – решения для постоянного обучения на лету, более глубокая интеграция инструментария и, возможно, появление действительно **самообучающегося** диалогового интеллекта, который с каждым разговором становится умнее. Уже сейчас заложены практические основы такой системы – осталось связать их воедино и продолжить исследования, опираясь на наилучшие практики сообщества и новые научные открытия.
<!-- UID: 4917080e-2a5d-4751-b65e-69aa773f35f1 -->