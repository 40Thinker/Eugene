>[!nexus_user] **User** - 02.08.2025 at 1:37
> Best practices for configuring AI plugins in Obsidian (2024-2025) — system prompts, API setup, local LLM integration (OpenAI, Qwen, LLaMA, DeepSeek, Mistral, Vicuna). 
> Looking for:
> - How to define high-quality system prompts for AI assistants in Obsidian
> - Optimizing Scribe, Text Generator, Smart Connections, LLM Obsidian Assistant, etc.
> - Prompt injection techniques per section (e.g. summary, insights, code, mindmap)
> - Handling context limitations in stateless LLM API calls
> - Best practices for embedding local models (ollama, LM Studio, Open WebUI, vLLM, local LLaMA3, Qwen, DeepSeek)
> - YAML / JSON configuration examples for Obsidian plugins
> - How to enable instruction tuning / RAG workflows inside Obsidian
> - Differences in prompt strategies for OpenAI vs. local models
> - Plugins using GPT-4, Claude, Gemini vs plugins calling local Qwen, LLaMA3, DeepSeek or Mixtral models
> - Managing token context, memory simulation, and embedding insertions
<!-- UID: b6471fe8-de9b-4e5d-86fd-bbe978204aa7 -->




>[!nexus_agent] **Assistant** - 02.08.2025 at 1:37
> To tailor the research precisely to your needs, could you please clarify the following:
> 
> 1. Are you primarily interested in **plugins and setups that are production-ready**, or also early-stage community experiments?
> 2. Should we prioritize support for **markdown-based workflows**, **visual mapping (e.g. Mermaid, Canvas)**, or both?
> 3. Do you want focus only on **offline-compatible local LLMs** (Qwen, LLaMA3, DeepSeek, etc.), or include cloud-based models (GPT-4, Claude, Gemini) equally?
> 4. Would you like YAML/JSON config examples to target specific plugins (e.g., Text Generator, Scribe), or general-purpose templates?
> 
> Once I have this, I’ll start a deep research task on best practices for AI plugin setup in Obsidian with LLM integration.
<!-- UID: ea108ead-1d65-4561-adae-e6f2f16c96c7 -->