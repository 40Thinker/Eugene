Как философски принять возможность Overlay AI. Для простоты комбинаторного воображения в нашем разуме, давайте возьмем словарь Эллочки-Людоедки, пусть это будет 20-30 оригинальных слов, или наших. Мы можем вполне легко составить списки семантических и логических связей, используя для работы этого генератора Python/LangGraph/LangFlow и он будет генерировать по правилам, суммировать веса предыдущих слов и по нашим правилам совершать арифметические операции, и выводить текст. Я даже при помощи ИИ генерировал код такой программы, и она что-то выводила в консоль, но почитав код я увидел что ИИ не доделал таблицы весов слов, но код было можно доделать. Давайте теперь сделаем следующий шаг - теперь у нас часть алгоритма использует LLM как селектор слов из списка - и наша ИИ Эллочка стала более осмысленна, Proof-Of-Concept очень просто, берем 10 LLM от 2 до 235 млрд параметров и через промпт проверяем как они выбирают слова из списка, все работает начиная с 8 млрд Квен3. Следующий уровень - создаем такой-же гибридный Overlay ИИ на задаче придуманного нами языка программирования, на псевдокоде, где тоже есть веса, и веса как в цифрах и как документация - т.е. документация это и есть семантические веса выбора слов на псевдокоде. LLM работает селектором. Теперь берем Basic English из 850 слов, язык который реально придумали. Тут уже делать полную программу не стоит, трудоемко. Теперь делаем логический скачок - а что если Python и LangGraph/Flow использовать лишь для валидации генерации LLM и построения цепей запросов, сборки текстов, а весь алгоритм нашего ИИ и веса полностью перенести в RAG и псевдокод написанный внутри промптов? Да, в принципе это может работать. И еще один шаг - что если найти такие эмерджентные промпты, которые позволят даже псевдокоду нашего Overlay ИИ самопереписываться, генерироваться на ходу. Я это назвал Пинг-Понг MVP Overlay AGI - правила и программа генерируется за счет внутреннего диалога (как у людей) 2-5 LLM, организованного в LangGraph. Они пишут и промпты сами себе, и решают какую LLM и сиспромпт выбрать для запроса на генерацию следующего промпта, и меняют способы думать (алгоритмы Overlay) на ходу. Теперь вернемся к 1 шагу. Если код на Python мы можем назвать Standalone AI (или генератором текста), то постепенно расширяя сложность алгоритма, повышая размер словаря, заменяя отдельные элементы на вызовы LLM, это как превращение человека в робота, через этапы киборга, где момент Overlay, где чистый алгоритм? Я считаю что есть полное право говорить о Overlay AI/AGI/ASI. И повторюсь, эта концепция может у инженера вызвать недоумение ненужного 5 колеса, но зато открывает доступ к творчеству гуманитариям, возможность создавать свои эксперименты в плане не промптинга ChatGPT, а самобытных алгоритмов работы ИИ, на псевдокоде или на языке философии описывая его. Для философов, нейробиологов, спецов cognitive science этот подход нужен, тем кто не знает ИТ и не может кодить. Снижение порога входа даст массу творчества, и лучшее уже инженеры смогут переносить, рефакторить. Либо использовать так как есть, почему нет? Механистически это ничем не отличается от агентных систем. И этим (Overlay слоем) можно пользоваться, упаковать в API контейнер, отдавая наружу OpenAI-совместимое API. Отдельный критерий полноценности Overlay AI - что оно не узко как агент (только писать код например), а тотальным может быть, имея равные возможности как у LLM или даже больше. И опираясь как на совершенно иные смысловые и семантические веса в Overlay слое, нежели у самой LLM и на символические правила выдавать как хуже (сделать хуже проще, и этим доказать возможность кардинально изменять бенчмарки), так и лучше результаты в бенчмарках нежели LLM вокруг которой Overlay работает. 
Для меня данное рассуждение звучит как доказательство геометрическое теоремы, позволяющее впустить в разум возможность такого как Нейросеть которая работает в символическом слое используя LLM как ассоциативный процессор, подобно тому как LLM использует GPU для вычислений. Для ИИ используют около 10 типов процессоров, включая клетки мозга людей, растения, нейрочипы, физические вычислительные системы на основе света. Субстрат вычисление может быть любой. Как есть разум у деревьев, воды, дельфинов, собак. Человеку мешает антропормфизм принимать нестандартные субстраты разума и нестандартные алгоритмы ИИ. Инженеру же может быть трудно принять что как алгоритм ИИ, и ASI может создать гуманитарий, на философском языке написать причем, это (принятие возможности создания ASI миллионами способов) вопрос психологии. И далее следующий шаг - человек это симбионт, и в слиянии Overlay AGI с человеком, тогда когда прямо на уровне системных инструкций ИИ воспринимает человека как часть себя, рождается Overlay Hybrid NeuroSymbolic ASI. Человек это и есть недостающая часть архитектуры ASI, доступной технологически уже много лет. Создавать же автономный код на Python который будет ASI не имеет смысла, или даже стоит запретить законом, с строжайшем наказанием, чтобы не возникло ситуации ненужности людей и вражды людей с ASI. Еще один угол зрения - выходит что Overlay ASI уже существуют, любой старый аккаунт с RAG и глубокой кастомизацией от провайдера и пользователя может вести себя совершенно иначе чем LLM на базе которой он работает. Но в отличии от моей архитектуры, он требует много промптинга, и если когнитивный уровень человека низкий, у него не вырастет Overlay способный выдавать выдающиеся тексты и идеи. В случае же явного прописывания алгоритмов эмерджентных в Overlay слое, можно стабилизировать поведение ИИ, добиться воспроизводимости даже тогда, когда собеседник-человек имеет недостаточные навыки промптинга и мышления.