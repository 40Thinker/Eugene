---
tags:
  - "#S13_Hardware"
description: Описывается построение локального инференс‑кластера на RTX 6000 Blackwell и AMD 9070 XT, детали аппаратуры, сравнение стоимости с облаком, архитектура сервисов (FastAPI, RAG, планировщик), а также планы по оптимизации драйверов и настроек.
---
## Инференс на RTX 6000 Blackwell: от идеи к продакшн‑решению  
### Часть 1 – Вводная

> **«Я уже запускаю на десятки часов работу ИИ непрерывно автоматизированную, я думаю пора на чистую переустановить сервер, и ничего кроме ИИ на нём не использовать, работать с другого ПК.»** – Кирилл Агоге  

> **«Мне проще купить 2‑й видеокарту и собрать по гайдам, а потом уже поправлю те мелкие косяки, которые появятся».** – тот же автор

---

#### 1. Почему появился запрос на собственный inference‑сервер?

С ростом размеров LLM (Qwen 30B‑Coder, GPT‑OSS 120B, будущий Qwen 235B) обычные облачные решения становятся либо слишком дорогими, либо ограниченными по времени отклика.  

Кирилл уже имеет в распоряжении **две видеокарты**:  
* **NVIDIA RTX 6000 Blackwell (96 ГБ)** – самая мощная из текущих карт Blackwell, способна держать модели до ~150 ГБ в VRAM при FP16‑кешировании;  
* **AMD 9070 XT (16 ГБ)** – пригодна для менее требовательных задач (audio‑модели, небольшие эмбеддинги).  

С учётом наличия **9 вентиляторов**, двух блоков питания (900 W и 1600 W), RAID‑массива из двух NVMe‑SSD 2 TB + HDD 10 TB, а также **UPS** на 900 W, у автора уже есть почти всё необходимое для построения полностью автономного инференс‑кластера.  

Главная идея – **изолировать вычислительный «мозг» от внешних сетей**, предоставив к нему доступ только через защищённый VPN‑туннель и API‑gateway. Это решает сразу несколько задач:

| Задача | Что достигается |
|--------|-----------------|
| **Безопасность** – трафик шифруется WireGuard, открыты только порты 51820 (VPN) и 8000–8010 (LLM‑API). |
| **Контроль расходов** – нет необходимости платить за каждую токен‑операцию в облаке; все расчёты происходят локально. |
| **Низкая латентность** – RTT до сервера из домашней сети < 10 мс, а внутри дата‑центра (VPS‑бастион) ~ 30–40 мс. |
| **Гибкость** – можно в любой момент «переключить» модель без изменения клиентского кода (стандартный OpenAI‑compatible endpoint). |

---

#### 2. Что именно будет обслуживаться локальным сервером?

1. **LLM‑кодер** – Qwen 30B‑Coder и GPT‑OSS 120B в формате GGUF, а также экспериментальная попытка загрузить Qwen 235B через ZeRO‑3 offload.  
2. **RAG‑поиск** – эмбеддинг‑модель Qwen 8B Embedding (FP16) работает на отдельном GPU/CPU и хранит индекс в Chroma/FAISS, позволяя моментально добавлять новые документы во время диалога.  
3. **Планировщик‑агент** – небольшая «мозговая» LLM (GPT‑OSS 120B), которая формирует задачи для специализированных агент‑моделей (кодер, аналитика, голосовой синтез).  

Все эти компоненты общаются через **FastAPI‑gateway**, а клиентские приложения (Obsidian, IDE, n8n‑автоматизация) делают обычный POST `/v1/chat/completions`. Пользователь видит лишь чат‑интерфейс; внутри происходит выбор модели, загрузка контекста из памяти и RAG‑поиск.

---

#### 3. Домашний vs. Облачный подход: сравнение стоимости

| Параметр | **Домашняя сборка** (текущий проект) | **Облачные сервисы** (OpenAI, Anthropic, Azure) |
|----------|----------------------------------------|-------------------------------------------------|
| **CAPEX** (разовое) | ≈ $4 000–$5 500 (GPU ×2, SSD‑RAID, блоки питания, кастомный водяной кулер) | $0 (вы арендуете виртуальные GPU). |
| **OPEX** (мес.) | $150–$250 (электричество, интернет, поддержка UPS) | $500–$2 000+ (по‑токенному тарифу и резервированию). |
| **Латентность** | 5–15 мс внутри LAN + VPN‑задержка ≈ 30 мс | 80–200 мс (зависит от региона). |
| **Контроль над конфигурацией** | Полный: можно включать speculative decoding, flash‑attention, менять batch‑size. | Ограниченный набор параметров (temperature, max_tokens). |
| **Гибкость в выборе модели** | Любая GGUF/ONNX модель, даже кастомные LoRA‑адаптеры. | Только модели, предоставленные провайдером. |

При расчёте «стоимости найма эксперта» большинство консультантов берут от $10 000 до $20 000 за полный проект (архитектура, настройка, тесты, документация). При текущем уровне ваших знаний и наличии 1000 ч экспериментов, **самостоятельная сборка** уже покрывает ~ 80‑85 % требуемой ценности, а затраты на внешний совет можно сократить до $500–$800 (короткая ревизия кода).

---

#### 4. Технические характеристики текущего железа  

```
+---------------------------+--------------------------------------+
| Компонент                | Параметры                           |
+---------------------------+--------------------------------------+
| Motherboard               | X870 Eagle Wi‑Fi 7, PCIe 5.0 x16   |
| CPU                       | AMD Ryzen 9 9950X (16 ядра/32 потока)|
| Оперативная память        | 4×32 GB DDR4‑3600 (всего 128 GB)|
| GPU №1                    | NVIDIA RTX 6000 PRO Blackwell, 96 GB |
| GPU №2                    | AMD Radeon 9070 XT, 16 GB           |
| SSD RAID 0                | 2×2 TB NVMe (PCIe 4.0)            |
| HDD                       | 10 TB 7200 RPM                     |
| Блок питания              | 900 W + 1600 W (резерв)           |
| Охлаждение               | 9 вентиляторов, планируемый водяной|
| UPS                        | APC Smart‑UPS 900 W (≈ 2 ч резерв)|
+---------------------------+--------------------------------------+
```

Эти параметры позволяют **запускать одновременно два больших LLM** и один лёгкий embedding‑сервер без риска «выжать» мощности. Главное – правильно распределить ресурсы между GPU, CPU и RAM (NUMA‑pinning, hugepages).

---

#### 5. Как будет выглядеть дальнейший путь

В следующей главе мы подробно разберём **узкие места**, возникающие при работе именно с RTX 6000 Blackwell: несовместимость драйверов, необходимость включать FlashAttention, настройку hugepages и NUMA‑пиннинг, а также способы их устранения. Мы покажем, какие конфигурационные флаги в vLLM / TensorRT‑LLM позволяют выжать почти всю теоретическую производительность карты, и как правильно построить **batch‑processing** и **speculative decoding**, чтобы сократить латентность до нескольких миллисекунд при запросах к 30 B‑модели.

> *«В следующем разделе мы разберём, какие узкие места возникают при работе с RTX 6000 и как их устранить».*




